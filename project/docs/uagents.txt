<page>
  <title>Agents - uAgents Framework docs</title>
  <url>https://uagents.fetch.ai</url>
  <content>Introduction[](#introduction)
-----------------------------

The uAgents Framework is a python library designed to facilitate the development of Agents. Agents in a multi-Agent system can communicate with any, and all agents in the system to solve problems, execute tasks and transact.

‚ÑπÔ∏è

Head over to the [uagents package](https://pypi.org/project/uagents/) to download it and start developing your Agents!

Current version of the uAgents package is .

### Getting into Agents[](#getting-into-agents)

Agents are programs designed to operate freely and communicate with whomever they‚Äôre programmed to. Agents can connect, search, and transact in order to create dynamic markets, and they can be programmed to interact both within their local network or with other agents across all networks. Because they‚Äôre siloed, and decentralized they can safely accomplish particular activities and objectives without requiring human participation. We have a very simple guide in our documentation that gets you started on building an Agent to be part [of the Network](https://uagents.fetch.ai/docs/getting-started/create).

At the simplest level, and agent would work as follows:

Agents come online, they register (or not) and then send and receive messages.

Using the above workflow as reference, many Agent can come together to become multi-Agents workflows, where single Agents call one another to complete a task. That can create a chain of Agents relying on responses from other Agents. Agents that you design could be programmed to contact known Agents, whereas in a dynamic marketplace you may need an agent that you haven‚Äôt created, searching and interacting with that Agent may be the more optimal strategy.

Get to know more about: [registering](https://network.fetch.ai/docs/introduction/almanac/register-in-almanac), [searching](https://network.fetch.ai/docs/introduction/almanac/introduction) and [communication](https://uagents.fetch.ai/docs/guides/communication).

A simple Agent using the `uagents` library could be:

    from uagents import Agent, Context, Model
     
    agent = Agent(name="concept", seed="secret_seed_phrase_concept", endpoint="127.0.0.1", port="8001")
     
    class Message(Model):
        message : str
     
     
    @agent.on_message(model=Message)
    async def print_message(ctx: Context, msg : Message):
        ctx.logger.info(f"Message received: {msg.message}")
     
    if __name__ == "__main__":
        agent.run()

This Agent defines its communication method as receiving any Object of `Class Message`, with a value for `message` of type `string`. You can see how this agent behaves, and how to extend this in our guides.

Agents can be inserted to existing systems with the ability to simplify the way we see complicated systems. As an example, supply chain management could deploy Agents using the uAgents Framework to improve operations at various stages. Demand forecasting, inventory control, logistics optimization, supplier relationships monitoring, quality control and risk mitigation in all areas can be done with their help. Agents could transform supply chain operations by increasing efficiency, reducing costs, improving accuracy and providing real-time visibility.

You can view the source code for an Agent that monitors inventory levels in [our examples](https://github.com/fetchai/uAgent-Examples/blob/main/3-applications/inventory-monitoring/src/main.py).

Agents thrive on IoT devices such as Raspberry Pi, and there are some great examples of multi-Agent simulations using Agents on Raspberry Pi available on [Github](https://github.com/Agents-Lab/sensor-agent).

#### LLMs[](#llms)

Agents can wrap and orchestrate LLMs to create personalized Agents for any task. With the rise of Large Language Models (LLMs) and AI-related products, autonomous intelligent Agents have become the link between these models and tools. They are revolutionizing the way we solve problems, make decisions and collaborate with each other.

Integrating LLMs into an Agent is relatively trivial, [we have a guide for that too](https://uagents.fetch.ai/docs/guides/langchain_agent)!

In this context, a standout example is **ASI:One Mini**, which is an LLM created by Fetch.ai. Unlike general-purpose models, ASI:One Mini is designed to connect directly with Agents that act as domain experts. This enables ASI:One to answer specialized questions, make real-world reservations, and serve as an intelligent gateway into an _organic_ multi-Agent ecosystem. Check out the [ASI:One Mini](https://docs.asi1.ai/docs) documentation for a better understanding, or head over to this [example](https://uagents.fetch.ai/docs/examples/asi-1) for a practical visualization.

### Getting started with Agent development![](#getting-started-with-agent-development)

Visit the [GitHub repository](https://github.com/fetchai/uAgents) to see the source code for Agents, and to keep up-to-date with any update made to the uAgents Framework.

From there, view the examples on uAgents repository, or start reading our guides, we‚Äôd recommend starting with [agent to agent communication](https://uagents.fetch.ai/docs/guides/communication).

### Agentverse[](#agentverse)

Fetch.ai has invested heavily into a toolset to help you build and deploy Agents with ease. Once you‚Äôre familiar with Agents and the uAgents Framework, check out [Agentverse](https://agentverse.ai/docs) to host your Agents in the cloud.</content>
</page>

<page>
  <title>Agents - uAgents Framework docs</title>
  <url>https://uagents.fetch.ai/docs</url>
  <content>Introduction[](#introduction)
-----------------------------

The uAgents Framework is a python library designed to facilitate the development of Agents. Agents in a multi-Agent system can communicate with any, and all agents in the system to solve problems, execute tasks and transact.

‚ÑπÔ∏è

Head over to the [uagents package](https://pypi.org/project/uagents/) to download it and start developing your Agents!

Current version of the uAgents package is .

### Getting into Agents[](#getting-into-agents)

Agents are programs designed to operate freely and communicate with whomever they‚Äôre programmed to. Agents can connect, search, and transact in order to create dynamic markets, and they can be programmed to interact both within their local network or with other agents across all networks. Because they‚Äôre siloed, and decentralized they can safely accomplish particular activities and objectives without requiring human participation. We have a very simple guide in our documentation that gets you started on building an Agent to be part [of the Network](https://uagents.fetch.ai/docs/getting-started/create).

At the simplest level, and agent would work as follows:

Agents come online, they register (or not) and then send and receive messages.

Using the above workflow as reference, many Agent can come together to become multi-Agents workflows, where single Agents call one another to complete a task. That can create a chain of Agents relying on responses from other Agents. Agents that you design could be programmed to contact known Agents, whereas in a dynamic marketplace you may need an agent that you haven‚Äôt created, searching and interacting with that Agent may be the more optimal strategy.

Get to know more about: [registering](https://network.fetch.ai/docs/introduction/almanac/register-in-almanac), [searching](https://network.fetch.ai/docs/introduction/almanac/introduction) and [communication](https://uagents.fetch.ai/docs/guides/communication).

A simple Agent using the `uagents` library could be:

    from uagents import Agent, Context, Model
     
    agent = Agent(name="concept", seed="secret_seed_phrase_concept", endpoint="127.0.0.1", port="8001")
     
    class Message(Model):
        message : str
     
     
    @agent.on_message(model=Message)
    async def print_message(ctx: Context, msg : Message):
        ctx.logger.info(f"Message received: {msg.message}")
     
    if __name__ == "__main__":
        agent.run()

This Agent defines its communication method as receiving any Object of `Class Message`, with a value for `message` of type `string`. You can see how this agent behaves, and how to extend this in our guides.

Agents can be inserted to existing systems with the ability to simplify the way we see complicated systems. As an example, supply chain management could deploy Agents using the uAgents Framework to improve operations at various stages. Demand forecasting, inventory control, logistics optimization, supplier relationships monitoring, quality control and risk mitigation in all areas can be done with their help. Agents could transform supply chain operations by increasing efficiency, reducing costs, improving accuracy and providing real-time visibility.

You can view the source code for an Agent that monitors inventory levels in [our examples](https://github.com/fetchai/uAgent-Examples/blob/main/3-applications/inventory-monitoring/src/main.py).

Agents thrive on IoT devices such as Raspberry Pi, and there are some great examples of multi-Agent simulations using Agents on Raspberry Pi available on [Github](https://github.com/Agents-Lab/sensor-agent).

#### LLMs[](#llms)

Agents can wrap and orchestrate LLMs to create personalized Agents for any task. With the rise of Large Language Models (LLMs) and AI-related products, autonomous intelligent Agents have become the link between these models and tools. They are revolutionizing the way we solve problems, make decisions and collaborate with each other.

Integrating LLMs into an Agent is relatively trivial, [we have a guide for that too](https://uagents.fetch.ai/docs/guides/langchain_agent)!

In this context, a standout example is **ASI:One Mini**, which is an LLM created by Fetch.ai. Unlike general-purpose models, ASI:One Mini is designed to connect directly with Agents that act as domain experts. This enables ASI:One to answer specialized questions, make real-world reservations, and serve as an intelligent gateway into an _organic_ multi-Agent ecosystem. Check out the [ASI:One Mini](https://docs.asi1.ai/docs) documentation for a better understanding, or head over to this [example](https://uagents.fetch.ai/docs/examples/asi-1) for a practical visualization.

### Getting started with Agent development![](#getting-started-with-agent-development)

Visit the [GitHub repository](https://github.com/fetchai/uAgents) to see the source code for Agents, and to keep up-to-date with any update made to the uAgents Framework.

From there, view the examples on uAgents repository, or start reading our guides, we‚Äôd recommend starting with [agent to agent communication](https://uagents.fetch.ai/docs/guides/communication).

### Agentverse[](#agentverse)

Fetch.ai has invested heavily into a toolset to help you build and deploy Agents with ease. Once you‚Äôre familiar with Agents and the uAgents Framework, check out [Agentverse](https://agentverse.ai/docs) to host your Agents in the cloud.</content>
</page>

<page>
  <title>Quick Start Guide for uAgents Framework docs</title>
  <url>https://uagents.fetch.ai/docs/quickstart</url>
  <content>This **Quickstart guide** walks you through the installation process of the **uAgents Framework** and helps to build a couple of Agents in a few steps.

You can find all supporting code files in our dedicated [GitHub repo](https://github.com/fetchai/uAgent-Examples/tree/main/5-documentation/guides/agents/quickstart).

Let‚Äôs get started!

Installation[](#installation)
-----------------------------

### System requirements[](#system-requirements)

*   **Python 3.8+**: it is a popular programming language.
*   **PIP**: it is Python package manager for installing libraries.
*   **Operating System**: _Windows_, _MacOS_ or _Ubuntu_.

### Installation steps[](#installation-steps)

1.  Let‚Äôs start and create a **Project Directory** for your Agent project. Open and type the following within your terminal:
    
        mkdir directory_name
        cd directory_name
    
2.  Proceed and install the **uAgents Framework** package:
    

### Troubleshooting[](#troubleshooting)

Sometimes you may face errors during installation. Here we list the most common reasons below:

**Problem on MacOS/Python 3.11**: Installing coincurve (17.0.0) fails.

#### Solution[](#solution)

Install the necessary tools:

    brew install automake autoconf libtool

Creating a simple Agent[](#creating-a-simple-agent)
---------------------------------------------------

Let‚Äôs create a very basic Agent to get started. Here below you can find the most basic Agent application; we want the Agent to perform a task periodically.

First of all, let‚Äôs create a new Python script for this project. Open terminal and type the following into it:

Then, open the `interval_task.py` file in a text editor of your choice and add the following code:

     
    from uagents import Agent, Context
     
    # Create an agent named Alice
    alice = Agent(name="alice", seed="YOUR NEW PHRASE", port=8000, endpoint=["http://localhost:8000/submit"])
     
    # Define a periodic task for Alice
    @alice.on_interval(period=2.0)
    async def say_hello(ctx: Context):
        ctx.logger.info(f'hello, my name is {alice.name}')
     
     
    # Run the agent
    if __name__ == "__main__":
        alice.run()
     

Be sure to update `seed` with a unique phrase; the seed will need to be wrapped in `"`.

#### Run Script[](#run-script)

Run the script to see the output:

**Expected Output**:

    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     hello, my name is alice
    INFO:     hello, my name is alice
    INFO:     hello, my name is alice

Message Handling Example[](#message-handling-example)
-----------------------------------------------------

Let‚Äôs now explore how Agents handle messages. Let‚Äôs set up a simple interaction between two Agents: the first will send a message to the second one at regular intervals, and the latter one will handle and log the received messages accordingly.

First, let‚Äôs create 2 new Python scripts, one for each Agent:

Open `SenderAgent.py` in your text editor and add the following code into it:

     
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    RECIPIENT_ADDRESS = (
        "test-agent://agent1qd8ymq4najh5wycvhvhcw3l5lmkgkvkrqevrs6wpp5ll0khfdq6v2cq6859"
    )
     
    SenderAgent = Agent(
        name="SenderAgent",
        port=8000,
        seed="SenderAgent secret phrase",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     
    print(SenderAgent.address)
     
     
    @SenderAgent.on_interval(period=2.0)
    async def send_message(ctx: Context):
        await ctx.send(RECIPIENT_ADDRESS, Message(message="Hi there. Let's start our conversation!"))
     
     
    @SenderAgent.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
     
    if __name__ == "__main__":
        SenderAgent.run()
     

Then, open `ReceiverAgent.py` in your text editor and add the following code into it:

     
    from uagents import Agent, Context, Model
     
     
    # NOTE: Run ReceiverAgent.py before running SenderAgent.py
     
     
    class Message(Model):
        message: str
     
     
    ReceiverAgent = Agent(
        name="ReceiverAgent",
        port=8001,
        seed="ReceiverAgent secret phrase",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    print(ReceiverAgent.address)
     
     
    @ReceiverAgent.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        # send the response
        await ctx.send(sender, Message(message="Cool! Let's get started!"))
     
     
    if __name__ == "__main__":
        ReceiverAgent.run()
     

Again, be sure to update `seed` with a unique phrase.

#### Run Script[](#run-script-1)

Open two terminal windows, each one for an Agent, and then run the scripts separately to see the Agents communicating:

**Expected Output**:

*   **SenderAgent**:
    
        agent1qdw67s95esk0zwn8qxf0ln22e8zah9rqfrqqa4qyda7mjtpf3hsw640wuwr
        INFO:     [SenderAgent]: Registering on almanac contract...
        INFO:     [SenderAgent]: Registering on almanac contract...complete
        INFO:     [SenderAgent]: Received message from agent1qd8ymq4najh5wycvhvhcw3l5lmkgkvkrqevrs6wpp5ll0khfdq6v2cq6859: Cool! Let's get started!
        INFO:     [SenderAgent]: Received message from agent1qd8ymq4najh5wycvhvhcw3l5lmkgkvkrqevrs6wpp5ll0khfdq6v2cq6859: Cool! Let's get started!
        INFO:     [SenderAgent]: Received message from agent1qd8ymq4najh5wycvhvhcw3l5lmkgkvkrqevrs6wpp5ll0khfdq6v2cq6859: Cool! Let's get started!
        
    
*   **ReceiverAgent**:
    
        agent1qd8ymq4najh5wycvhvhcw3l5lmkgkvkrqevrs6wpp5ll0khfdq6v2cq6859
        INFO:     [ReceiverAgent]: Registering on almanac contract...
        INFO:     [ReceiverAgent]: Registering on almanac contract...complete
        INFO:     [ReceiverAgent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
        INFO:     [ReceiverAgent]: Received message from agent1qdp9j2ev86k3h5acaayjm8tpx36zv4mjxn05pa2kwesspstzj697xy5vk2a: Hello there bob.
        INFO:     [ReceiverAgent]: Received message from agent1qdp9j2ev86k3h5acaayjm8tpx36zv4mjxn05pa2kwesspstzj697xy5vk2a: Hello there bob.
        INFO:     [ReceiverAgent]: Received message from agent1qdp9j2ev86k3h5acaayjm8tpx36zv4mjxn05pa2kwesspstzj697xy5vk2a: Hello there bob.
        
    

Reach out to the Team![](#reach-out-to-the-team)
------------------------------------------------

Excellent! You are now ready to start exploring the concepts and resources available to start developing your agents on the ASI Network! if you‚Äôre keen to skip the more code focused guides, the best next steps would be exploring how [Agents communicate with other Agents](https://uagents.fetch.ai/docs/guides/communication).

Note that our Team is available on [Discord](https://discord.gg/fetchai) for any additional inquiry.</content>
</page>

<page>
  <title>Installing the uAgents Framework docs</title>
  <url>https://uagents.fetch.ai/docs/getting-started/install</url>
  <content>System Requirements[](#system-requirements)
-------------------------------------------

Fetch.ai‚Äôs [uAgents](https://pypi.org/project/uagents/) Frameworks package is a Python library running on Ubuntu/Debian, MacOS, and Windows systems.

On your computer, you may need to install:

*   [Python](https://www.python.org/downloads/) 3.8+.
*   [PIP](https://pypi.org/project/pip/) - the Python package manager.
*   [uAgents library](https://pypi.org/project/uagents/)

Install with Pip[](#install-with-pip)
-------------------------------------

1.  Create a directory for your agents project: `mkdir directory_name`
    
2.  Install Fetch.ai `uagents` library: `pip install uagents`
    
3.  Check if installation was successful: `pip show uagents`
    

Install from source code[](#install-from-source-code)
-----------------------------------------------------

1.  Download the latest released version from Github and navigate to the agents directory:
    
        git clone https://github.com/fetchai/uAgents.git
        cd uAgents
    
2.  Install the required dependencies:
    
3.  Open the virtual environment:
    

Troubleshooting[](#troubleshooting)
-----------------------------------

It is possible that you may face issues during the installation process. Here, you can find common problems and their solutions.

üö´

**Problem (MacOS/Python 3.11)**: `Installing coincurve (17.0.0): Failed`

**Solution**: install the latest versions of `automake`, `autoconf`, and `libtool`: `brew install automake autoconf libtool`

For any other problems, please let us know by creating an [issue](https://github.com/fetchai/uAgents/issues).

Installation for Windows users[](#installation-for-windows-users)
-----------------------------------------------------------------

Installing the uagents framework on a Windows machine is a straightforward process. The `uagents` library is a Python package, so you‚Äôll need to have Python installed on your system before you can use it.

If you don‚Äôt already have Python installed on your Windows machine, visit the official Python website at [Python](https://www.python.org/downloads/windows/) and download the latest stable version of Python for Windows.

Run the downloaded installer executable file (e.g., python-3.x.x.exe).

During installation, make sure to check the box that says ‚ÄúAdd Python X.X to PATH.‚Äù This will automatically add Python to your system‚Äôs PATH variable, making it easier to use from the command line.

### Install uagents library using pip[](#install-uagents-library-using-pip)

Once you have Python installed and added to your PATH, follow these steps to install the uagents framework using pip:

1.  To install using PIP open your terminal. To ensure that PIP (Python‚Äôs package manager) is up-to-date, run the following command:
    
        python -m pip install --upgrade pip
    
2.  Now, you can install the `uagents` framework by running the following command:
    

PIP will download and install the `uagents` package and its dependencies. Wait for the process to complete. To verify the complete installation explore your terminal. As part of the installation you will see a message showcasing the completion of the installation as well as the exact version.

Installing other essential Python libraries[](#installing-other-essential-python-libraries)
-------------------------------------------------------------------------------------------

Development tools[](#development-tools)
---------------------------------------

#### Installing Homebrew[](#installing-homebrew)

**Homebrew** streamlines software installations on MacOS via the command line. To install and update Homebrew, execute the following commands:

    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

You can verify it [here](https://brew.sh/). Let‚Äôs then ensure Homebrew is updated:

‚ÑπÔ∏è

For more information on Homebrew explore their [website](https://brew.sh/).

#### Installing PyEnv[](#installing-pyenv)

Now, you need to install **PyEnv**. It is a simple tool to manage multiple versions of Python. Run:

Once you have installed PyEnv you can configure the shell environment:

    echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.zshrc
    echo 'command -v pyenv >/dev/null || export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.zshrc
    echo 'eval "$(pyenv init -)"' >> ~/.zshrc

‚ÑπÔ∏è

These commands configure your shell environment (specifically the **Zsh shell**) to work with PyEnv. These commands set up environment variables, modify the PATH, and initialize PyEnv so that you can easily manage and switch between different Python versions. You can verify all steps [here](https://github.com/pyenv/pyenv#installation).

You are now ready to **install Python** if you haven‚Äôt done it yet. You need to install a version of Python 3.8 or above (for this example, we use version 3.10):

You can get help or check a command insights by running:

Let‚Äôs now ensure the **global version of Python** you are working with is not the default one in the system. Run:

    pyenv global 3.10 # this sets the global interpreter
    pyenv versions # this verifies if it is set up correctly</content>
</page>

<page>
  <title>Creating your first agent docs</title>
  <url>https://uagents.fetch.ai/docs/getting-started/create</url>
  <content>Introduction[](#introduction)
-----------------------------

Once you‚Äôve [installed](https://uagents.fetch.ai/docs/getting-started/install) the uAgents Framework library it‚Äôs simple to get a minimal use case running.

The uAgents Framework simplifies Agents creation, and enables Agents communication, discovery, and publication on the Fetch.ai network. The Framework supports building Agents using anything from advanced Large Language Models (LLMs) to basic APIs.

Let‚Äôs start with a simple Agent that initializes and prints its name and address

The agent[](#the-agent)
-----------------------

1.  Let‚Äôs create a Python script for this task, and name it by running:
    
2.  We then need to import the `Agent` and `Context` classes from the `uagents` library, and then create an agent using the class `Agent`:
    
         
        from uagents import Agent, Context
         
        agent = Agent(name="alice", seed="secret_seed_phrase", port=8000, endpoint=["http://localhost:8000/submit"])
         
    
    It is optional but useful to include a `seed` parameter when creating an agent to set fixed [addresses](https://uagents.fetch.ai/docs/getting-started/address). Otherwise, random addresses will be generated every time you run the agent. Your address is kind of important, as this is how other agents will identify you.
    
3.  Let‚Äôs define a `say_hello()` function for our agent to print a message periodically saying `hello, my name is ...`:
    
         
        @agent.on_event("startup")
        async def introduce_agent(ctx: Context):
            ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
         
        if __name__ == "__main__":
            agent.run()
         
    
    The `.on_event("startup")` decorator defines a behavior for this agent when it is run. In this case, the agent will execute the `say_hello()` function when the agent starts. The `Context` object is a collection of data and functions related to the agent. In this case, we just use the agent‚Äôs `name`, `alice`. The agent executes the function and uses the `ctx.logger.info()` method to print the message.
    
4.  Save the script.
    
    The overall script should look as follows:
    
         
        from uagents import Agent, Context
         
        agent = Agent(name="alice", seed="secret_seed_phrase", port=8000, endpoint=["http://localhost:8000/submit"])
         
        @agent.on_event("startup")
        async def introduce_agent(ctx: Context):
            ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
         
        if __name__ == "__main__":
            agent.run()
         
    

#### Run your agent[](#run-your-agent)

Make sure to have activated your virtual environment correctly.

Run the script: `python first_agent.py`

The output would be:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qtu6wt5jphhmdjau0hdhc002ashzjnueqe89gvvuln8mawm3m0xrwmn9a76
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [alice]: Hello, I'm agent alice and my address is agent1qtu6wt5jphhmdjau0hdhc002ashzjnueqe89gvvuln8mawm3m0xrwmn9a76.

Extending the example[](#extending-the-example)
-----------------------------------------------

That‚Äôs not really a useful agent, so let‚Äôs extend this; with a simple agent that can respond to a question by utilising openai.

Go ahead and get your own [openai api key](https://platform.openai.com/api-keys) as we will need this to make a call to openai.

Create a new file

### Agent[](#agent)

Copy and paste the below example into `ai_agent.py`

    from pydantic import BaseModel, Field
    from uagents import Agent, Context, Protocol, Model
    from openai import OpenAI
     
    CHAT_MODEL = "gpt-4o-mini"
    OPENAI_API_KEY = ""
     
    agent = Agent(name="open_ai_agent",
                  seed="your seed value",
                  port=8000,
                  endpoint=["http://127.0.0.1:8000/submit"]
                  )
     
     
    class AIRequest(BaseModel):
        question: str = Field(
            description="The question that the user wants to have an answer for."
        )
     
     
    class AIResponse(BaseModel):
        answer: str = Field(
            description="The answer from AI agent to the user agent"
        )
     
     
    PROMPT_TEMPLATE = """
    Answer the following question:
    {question}
    """
     
    @agent.on_event("startup")
    async def print_address(ctx: Context):
        ctx.logger.info(agent.address)
     
     
    def query_openai_chat(prompt: str):
        client = OpenAI(
            api_key=OPENAI_API_KEY,  # This is the default and can be omitted
        )
     
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": prompt,
                }
            ],
            model="gpt-4o",
        )
        return (chat_completion.choices[0].message.content)
     
     
    @agent.on_message(model=AIRequest, replies=AIResponse)
    async def answer_question(ctx: Context, sender: str, msg: AIRequest):
        ctx.logger.info(f"Received question from {sender}: {msg.question}")
        prompt = PROMPT_TEMPLATE.format(question=msg.question)
        response = query_openai_chat(prompt)
        ctx.logger.info(f"Response: {response}")
        await ctx.send(
            sender, AIResponse(answer=response)
        )
     
    agent.run()

Run this with `python ai_agent.py`, you should see logs similar to the below:

    python uagents-create/ai.py
    INFO:     [open_ai_agent]: Starting agent with address: agent1qdpzrc02a8lnlzaahtdyy3wnaux64pqa22vykp59tx67jx2mmy3dzf249jk
    INFO:     [open_ai_agent]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)

Keep a note of the address output to log, as the client will need this address to contact this agent.

Next, let‚Äôs create an agent to message `open_ai_agent`:

### Client agent[](#client-agent)

Create a new file for `client.py`

and paste the following code:

    from uagents import Agent, Context, Field, Model, Protocol
    from pydantic import BaseModel, Field
     
    agent = Agent(name="simple test agent",
                  seed="your seed value alt",
                  port=8001,
                  endpoint=["http://127.0.0.1:8001/submit"]
                  )
     
    QUESTION = "Write the Javascript code to give me the sum from 1 to 10"
     
     
    class AIRequest(BaseModel):
        question: str = Field(
            description="The question that the user wants to have an answer for."
        )
     
     
    class AIResponse(BaseModel):
        answer: str = Field(
            description="The answer from AI agent to the user agent"
        )
     
     
    @agent.on_event("startup")
    async def ask_question(ctx: Context):
        ctx.logger.info(
            f"Asking AI agent to answer {QUESTION}"
        )
        await ctx.send(
            'THE OTHER AGENTS ADDR', AIRequest(question=QUESTION)
        )
     
     
    @agent.on_message(model=AIResponse)
    async def handle_data(ctx: Context, sender: str, data: AIResponse):
        ctx.logger.info(f"Got response from AI agent: {data.answer}")
     
    agent.run()

There‚Äôs a lot to unpack here, and we cover the components of these agents [_here_](https://uagents.fetch.ai/docs/guides/protocols), [_here_](https://uagents.fetch.ai/docs/getting-started/address) and [_here_](https://uagents.fetch.ai/docs/guides/handlers) in more detail. However, at a high level these two agents define the `AIRequest(Model)` and `AIResponse(Model)` message objects; by defining these both agents can understand and respond to these messages. Some functions have handlers defined. Handlers `@agent.on_message(model=AIRequest, replies=AIResponse)` tell the uAgents library to call these functions when a message of `AIRequest` is received. This allows us to create very structured dialogues between two agents. However it doesn‚Äôt need to be so structured, check out the [chat protocol](https://uagents.fetch.ai/docs/examples/asi-1) for loosely structured communication.

If you run these agents you should see something like the following:

### Output[](#output)

#### Agent logs[](#agent-logs)

    python uagents-create/ai.py
    INFO:     [open_ai_agent]: Starting agent with address: agent1qdpzrc02a8lnlzaahtdyy3wnaux64pqa22vykp59tx67jx2mmy3dzf249jk
    INFO:     [open_ai_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qdpzrc02a8lnlzaahtdyy3wnaux64pqa22vykp59tx67jx2mmy3dzf249jk
    INFO:     [open_ai_agent]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [open_ai_agent]: Received question from agent1qwzl46ku3r2en2m8st5y0nd4j68dahqj8n95eq5af6823mfw2h0z2yvqwpc: Write the Javascript code to give me the sum from 1 to 10
    INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:     [open_ai_agent]: Response: Certainly! You can calculate the sum of numbers from 1 to 10 in JavaScript using a loop or a mathematical formula. Here's how you can do it using a loop:
    ...
     

#### Client logs[](#client-logs)

    python uagents-create/client.py
    INFO:     [simple test agent]: Starting agent with address: agent1qwzl46ku3r2en2m8st5y0nd4j68dahqj8n95eq5af6823mfw2h0z2yvqwpc
    INFO:     [simple test agent]: Asking AI agent to answer Write the Javascript code to give me the sum from 1 to 10
    INFO:     [simple test agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qwzl46ku3r2en2m8st5y0nd4j68dahqj8n95eq5af6823mfw2h0z2yvqwpc
    INFO:     [simple test agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [simple test agent]: Got response from AI agent: Certainly! You can calculate the sum of numbers from 1 to 10 in JavaScript using a loop or a mathematical formula. Here's how you can do it using a loop:
     
     ...
     
     

With this, you‚Äôre ready to start building greater, grander agents. Take a look at the [storage](https://uagents.fetch.ai/docs/guides/storage) and [sending tokens](https://uagents.fetch.ai/docs/guides/send_tokens) guides, persistent data is useful and agents getting paid is awesome.</content>
</page>

<page>
  <title>Getting Started with FET Token for Agent development docs</title>
  <url>https://uagents.fetch.ai/docs/getting-started/tokens</url>
  <content>üí°Ô∏è

This is currently a work in progress and may be subject to further updates and revisions.

Introduction[](#introduction)
-----------------------------

The FET token was created to facilitate payments in an Agentic ecosystem, these are micro payments to one another which traditional currencies do not support.

Acquiring FET Tokens[](#acquiring-fet-tokens)
---------------------------------------------

Exchanges are the simplest way to get FET tokens.

Visit a trusted exchange such as Coinbase or Binance. You may need to create an account, which will involve you passing [KYC](https://www.gov.uk/government/publications/know-your-customer-guidance/know-your-customer-guidance-accessible-version). Once your account is enabled, you can buy FET token. You can buy this with most global currencies, just check on the exchange which currencies they accept.

Mainnet or testnet[](#mainnet-or-testnet)
-----------------------------------------

If you don‚Äôt want to use mainnet tokens, we support test environment transactions (testnet). This is really useful for developing agent before mainnet deployment.

By default, your agent will run in testnet, you‚Äôll see that in the log output when you run an agent:

     
    python client.py
    INFO:     [agent]: Starting agent with address: agent1qftyqsedg740hfyrjpf3nlm2saf3z02sra7dn64yqqc7jktlfpg8us8us23
    INFO:     [agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [uagents.registration]: Registration on Almanac API successful
    WARNING:  [uagents.registration]: I do not have enough funds to register on Almanac contract
    INFO:     [uagents.registration]: Adding testnet funds to fetch1aatyrgyv0dcjna072fdaadsx6sennxlws3gp4w
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [uagents.registration]: Registering on almanac contract...complete
     

When your agent starts it will try and register to the Almanac, if the agent has not funds to do so, they are given to the agent.

However, if you want your agent to be part of the mainnet, you must update your agent init to include `network`:

    agent = Agent(name="mainnet_agent",
                  seed="",
                  port=8001,
                  endpoint=["http://127.0.0.1:8001/submit"],
                  network="mainnet"
                  )
     

Your logs for an agent like the above would be:

    python example.py
    INFO:     [example]: Starting agent with address: agent1qftyqsedg740hfyrjpf3nlm2saf3z02sra7dn64yqqc7jktlfpg8us8us23
    INFO:     [example]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [uagents.registration]: Registration on Almanac API successful
    WARNING:  [uagents.registration]: I do not have enough funds to register on Almanac contract
    INFO:     [uagents.registration]: Send funds to wallet address: fetch1aatyrgyv0dcjna072fdaadsx6sennxlws3gp4w
    WARNING:  [uagents.registration]: Failed to register on Almanac contract due to insufficient funds

To give your agent tokens checkout [How to transfer tokens to your Agents](https://uagents.fetch.ai/docs/getting-started/tokens#how-to-transfer-tokens-to-your-agents).

Storing FET[](#storing-fet)
---------------------------

Ideally you would be sending this FET to your agent to transact on the network. However, if you‚Äôd like greatersecurity or accessibility.

For short-term storage goals, the ASI Wallet is an excellent choice; it provides direct functionalities for daily activities such as staking and interacting with Agents.

For long-term storage goals, you can enhance security by integrating your ASI Wallet with a hardware wallet like Ledger, offering robust protection for your assets. Follow this guide [here](https://network.fetch.ai/docs/guides/asi-wallet/asi-wallet-hardware-connection-guide) if you wish to set up the ASI Alliance extension wallet with a Ledger hardware wallet.

How to transfer tokens to your Agents[](#how-to-transfer-tokens-to-your-agents)
-------------------------------------------------------------------------------

You can download and use the uAgents library to create autonomous Agents capable of interacting with other Agents in a decentralized environment. Check out this guide [here](https://uagents.fetch.ai/docs/getting-started/install) to get started with Agents development.

In order to get your Agent up and running within the Fetch.ai ecosystem, you will need to retrieve the Agent‚Äôs address and fund it with FET tokens to make it correctly register within the network.

‚ÑπÔ∏è

When creating your account, it is crucial to securely store your [seed phrase](https://uagents.fetch.ai/docs/getting-started/seed). The seed phrase is essential for accessing your Agent‚Äôs identity and controlling any funds it holds. Treat it with the highest level of security to prevent unauthorized access!

### Getting your Agent address to send tokens to your Agent[](#getting-your-agent-address-to-send-tokens-to-your-agent)

The following Python script demonstrates how to create and initialize an Agent using the `uagents` and `cosmpy` libraries, to connect it to the Fetch.ai Mainnet, and retrieve its address and balance information:

agent\_address\_and\_balance.py

    from uagents import Agent, Context
    import cosmpy
     
    from cosmpy.aerial.client import LedgerClient, NetworkConfig
     
    agent = Agent(name="alice", seed="", port=8000, test=False,  endpoint=["http://localhost:8000/submit"])
     
    @agent.on_event("startup")
    async def introduce_agent(ctx: Context):
        ctx.logger.info(f"ASI network address:{agent.wallet.address()}")
        ledger_client = LedgerClient(NetworkConfig.fetch_mainnet())
        address: str = agent.wallet.address()
        balances = ledger_client.query_bank_all_balances(address)
        ctx.logger.info(f"Balance of addr: {balances}")
     
    if __name__ == "__main__":
        agent.run()
     

**You must update the seed value, and store it safely. Losing this value will lose you your tokens.**

In the code example above an Agent named `alice` is initialized with a specified `name`, `port`, `endpoint`, and `seed` parameters. When the Agent starts up, it logs the wallet address and queries the balance using the `LedgerClient` connected to the Fetch.ai Mainnet. Finally, the script runs the Agent, which processes the `startup` event and retrieves the balance, allowing the Agent to interact with the Fetch.ai network.

Once you run the above Agent script, you will see your Agent address and balance printed out. You will see something similar to the following output:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qdxdrwqek4pt9xt8kggcxus0zm54d4vgdznrs6y5acn26paphervwfj7pdd
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [alice]: ASI network address:fetch1ujr7wyuvza7uwnkr3usv53hjlwjvu8s7l06vzf
    INFO:     [alice]: Balance of addr: []

You can now use this address to transfer your purchased FET tokens from the exchange to this Agent‚Äôs address. This should be as simple as withdrawing native FET, by selecting the Fetch.ai Mainnet network when withdrawing. Some exchanges do not support Native FET, and you will need to use the [token bridge](https://token-bridge.fetch.ai/), luckily we have [a guide for that too](https://network.fetch.ai/docs/guides/network/how-to-convert-fet-to-and-from-erc20).</content>
</page>

<page>
  <title>Seed phrases docs</title>
  <url>https://uagents.fetch.ai/docs/getting-started/seed</url>
  <content>_If you‚Äôre new to cryptography‚Ä¶_

Imagine you have a treasure chest full of your code, but instead of a key, it has a secret password to open it. This password is made up of any characters you choose. This ‚Äúpassword‚Äù is your seed phrase, when you create one make it really complicated.

If you remember your seed phrase, you can open your treasure chest anytime, anywhere, even if you lose the chest. In our case, our chest is our agent identity. However, if someone else learns your seed phrase, they can impersonate your agent! Not just impersonate, but they would also have access to the wallet of the agent. So, it‚Äôs super important to keep the seed phrase safe, like hiding it in a secret place or writing it down where no one can find it. Never tell anyone your seed phrase unless you really, really trust them!

uAgents creates an address for your agent cryptographically with your defined seed phrase, this all happens out of view in the uAgents library [view the src](https://github.com/fetchai/uAgents/blob/3a76aa0f364fcd6464562f495d722fe80568a24b/python/src/uagents/agent.py#L425).

To define your seed phrase, enter your unique phrase as the value to `seed`, see below:

    sigmar = Agent(name="demo", seed="demo oehfourfuueuje73773 kjsjss9jshshs recovery phrase", port=8000, endpoint=["http://localhost:8000/submit"])

Now, any agent that uses the seed `demo oehfourfuueuje73773 kjsjss9jshshs recovery phrase` will take control of that agent‚Äôs identity.

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Agents address docs</title>
  <url>https://uagents.fetch.ai/docs/getting-started/address</url>
  <content>Introduction[](#introduction)
-----------------------------

Agents within the Fetch Ecosystem are characterized by different addresses. These can allow the agent to perform different actions, including sending messages or interacting with the [Almanac contract](https://network.fetch.ai/docs/introduction/almanac/introduction).

It is possible to distinguish between two different types of addresses:

*   `uAgent address`: this address identifies the agent within the Fetch Network. It‚Äôs similar to a username within a chat platform, allowing other agents to discover and communicate with that specific agent by querying that agent‚Äôs information from the Almanac contract.
    
*   `Fetch network address`: this address is linked to the agent‚Äôs wallet on the Fetch.ai network. It is essential to perform multiple functionalities like holding cryptocurrency, interacting with the [Fetch Ledger](https://network.fetch.ai/docs/introduction/ledger/ledger-intro) and performing secure transactions. This address is needed to register an agent to the [Almanac](https://network.fetch.ai/docs/introduction/almanac/introduction) contract. Note, you must ensure the agents has enough funds available to perform operations in the Fetch Network, however this is all done automatically and no funds are currently required.
    

If you want to retrieve the address of an agent, you can either use the `print()` function and specify which of the above addresses you wish to print out, or by calling the `.address()` or `.wallet.address()` methods using the `agent` object to retrieve specific information.

Let‚Äôs now check how these ways of retrieving addresses look like!

Print uAgent address[](#print-uagent-address)
---------------------------------------------

You can print the `uAgent address` related to your Agent in the following way:

1.  First of all, create a Python script and name it:
    
        echo. > uagent_address.py
    
2.  We then need to import the `Agent` class from the `uagents` library to create an Agent, `alice`. Then, using the `print()` function, we will print the related `uAgent address`. Importantly, remember that the `seed` parameter is used, when creating an Agent, to set fixed addresses, otherwise a random address will be generated every time you run the Agent:
    
         
        from uagents import Agent
         
        agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
         
        print("uAgent address: ", agent.address)
         
        if __name__ == "__main__":
            agent.run()
         
    
3.  Save the script.
    

The output would be as follows:

    uAgent address:  agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)

Print Fetch network address[](#print-fetch-network-address)
-----------------------------------------------------------

You can print the `Fetch network address` related to your agent in the following way:

1.  Let‚Äôs create a Python script, and name it:
    
2.  As before, we first need to import the `Agent` class from the `uagents` library to create an Agent, `alice`. Then, using the `print()` function, we will print the related `Fetch Network address`:
    
         
        from uagents import Agent
         
        agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
         
        print("Fetch network address: ", agent.wallet.address())
         
        if __name__ == "__main__":
            agent.run()
         
    
3.  Save the script.
    

The output would be as follows:

    Fetch network address:  fetch1454hu0n9eszzg8p7mvan3ep7484jxl5mkf9phg
    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)

Print agent name and address using `name` and `address` methods[](#print-agent-name-and-address-using-name-and-address-methods)
-------------------------------------------------------------------------------------------------------------------------------

In this guide, we aim at showing how to create an agent being able to say hello and printing its `name` and `address` using the `uagents` library tools. Indeed, it is possible to retrieve the `name` and `address` of any agent directly from the `agent` object representing the agent you create and initialize. More specifically, we refer to the following methods:

*   `.name()`: this returns the provided name of the agent, if specified, otherwise, if the agent‚Äôs name is not explicitly set, then it will use the first ten characters of the agent‚Äôs address as its name.
    
*   `.address()`: this returns the unique address of the agent in the form `agent1...`. This address is essential for other agents to interact with your agent.
    

**Let‚Äôs get started and use the `agent` object to make our agent print its name and address!**

### Walk-through[](#walk-through)

1.  First of all, you need to create a Python script and name it:
    
2.  We then need to import the necessary classes `Agent` and `Context` from the `uagents` library, and then create an instance of the `Agent` class, `alice`. Below you can see the `agent` object being initialized:
    
         
        from uagents import Agent, Context
         
        agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
         
    
3.  We would then need to assign the agent the behavior to be executed. In this case, `agent` could send a message when it is being run saying hello and printing its `name` and `address` using the `agent` object:
    
         
        @agent.on_event("startup")
        async def introduce_agent(ctx: Context):
            ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
         
        if __name__ == "__main__":
            agent.run()
         
    
    This `introduce_agent()` function takes a single argument `ctx` of type `Context`. The message is printed out using the `ctx.logger.info()` method, and includes the agent‚Äôs name obtained from attribute `name` and retrieved using `agent.name()` method. The same for the agent‚Äôs address, which is obtained from attribute `address` and retrieved using `agent.address()` method.
    
4.  Save the script.
    

The overall script should look as follows:

     
    from uagents import Agent, Context
     
    agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
     
    @agent.on_event("startup")
    async def introduce_agent(ctx: Context):
        ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
     
    if __name__ == "__main__":
        agent.run()
     

### Run the script[](#run-the-script)

On your terminal, run the script: `python my_agent.py`

The output should be as follows:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Hello, I'm agent alice and my address is agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t.
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)</content>
</page>

<page>
  <title>Communicating with other agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/communication</url>
  <content>Introduction[](#introduction)
-----------------------------

Communication is an essential feature within any agents network. Communication allows agents to work together, exchange information, and forms an organic marketplace. In this guide, we will explore two methods of communication between agents:

*   **Local communication**.
*   **Remote communication** via the [Almanac Contract](https://network.fetch.ai/docs/introduction/almanac/introduction).

Let‚Äôs start with **local communication**. This is the first step you would need to undertake to familiarize yourself with the code syntax we will be using in the **remote communication** section.

Imports needed[](#imports-needed)
---------------------------------

Agents: Local Communication[](#agents-local-communication)
----------------------------------------------------------

### Walk-through[](#walk-through)

The first step to better understand how agents communicate is to introduce how 2 agents perform a local communication. Let‚Äôs consider a basic example in which two agents say hello to each other.

First of all, let‚Äôs create a Python script for the agent1 for this task:

Let‚Äôs create a Python script for the agent2 for this task:

    echo. > agent_slaanesh.py

### Agent 1: Sigmar[](#agent-1-sigmar)

#### 1\. Define the Message Model[](#1-define-the-message-model)

This defines a simple message structure using the Model class from uAgents. The message field is a string that will be exchanged between agents. This ensures that both agents can communicate using a predefined format.

    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     

#### 2\. Create Sigmar Agent[](#2-create-sigmar-agent)

Here, the **Sigmar agent** is initialized with a unique name and seed (recovery phrase) to establish its identity. It runs on **port 8000** and listens for messages at the specified endpoint. This setup enables the agent to send and receive messages in a local environment.

    sigmar = Agent(name="sigmar", seed="sigmar recovery phrase", port=8000, endpoint=["http://localhost:8000/submit"])

#### 3\. Sigmar Sends a Message Every 3 Seconds[](#3-sigmar-sends-a-message-every-3-seconds)

A periodic function is defined, which executes every 3 seconds. It sends a message, **‚Äúhello there sigmar‚Äù**, to the Slaanesh agent using its unique address. This ensures that communication is continuously initiated from Sigmar without requiring any manual input.

    SLAANESH_ADDRESS = < SLAANESH ADDRESS >
     
    @sigmar.on_interval(period=3.0)
    async def send_message(ctx: Context): 
        await ctx.send(SLAANESH_ADDRESS, Message(message="hello there sigmar"))
     

#### 4\. Handle Incoming Messages[](#4-handle-incoming-messages)

This function triggers whenever **Slaanesh** receives a message matching the `Message` model. It logs the sender‚Äôs address and message content, then replies with **‚Äúhello there slaanesh‚Äù** to the sender. This ensures a two-way communication flow between the agents.

    @sigmar.on_message(model=Message)
    async def sigmar_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     

#### 5\. Start the Agent[](#5-start-the-agent)

The agent is started using `sigmar.run()`, making it continuously run and process messages. This ensures that the agent remains active and responsive to incoming communications.

    if __name__ == "__main__":
        sigmar.run()

### Agent 2: Slaanesh[](#agent-2-slaanesh)

#### 1\. Define the Message Model[](#1-define-the-message-model-1)

The same message structure is defined for **Slaanesh**, ensuring compatibility with **Sigmar**. This consistency allows both agents to understand the messages they exchange.

    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     

#### 2\. Create Slaanesh Agent[](#2-create-slaanesh-agent)

The **Slaanesh** agent is initialized with its own name and seed for identity. It runs on **port 8001** and listens for messages at its specified endpoint. This setup enables Slaanesh to receive messages from Sigmar and respond appropriately.

    slaanesh = Agent(name="slaanesh", seed="slaanesh recovery phrase", port=8001, endpoint=["http://localhost:8001/submit"])
     

#### 3\. Handle Incoming Messages & Reply[](#3-handle-incoming-messages--reply)

This function triggers whenever **Slaanesh** receives a message matching the `Message` model. It logs the sender‚Äôs address and message content, then replies with **‚Äúhello there slaanesh‚Äù** to the sender. This ensures a two-way communication flow between the agents.

    @slaanesh.on_message(model=Message)
    async def slaanesh_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
        await ctx.send(sender, Message(message="hello there slaanesh"))
     

#### 4\. Start the Agent[](#4-start-the-agent)

The agent is started using `slaanesh.run()`, making it continuously run and process messages. This keeps the agent active and ready to communicate with Sigmar whenever it receives a message.

    if __name__ == "__main__":
        slaanesh.run()

### Complete Script for Both Agents[](#complete-script-for-both-agents)

These two scripts together create an autonomous request-response loop between two local agents, continuously exchanging messages. To ensure smooth communication between Sigmar and Slaanesh, you must start the Slaanesh agent first before running Sigmar.

    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    sigmar = Agent(name="sigmar", seed="sigmar recovery phrase", port=8000, endpoint=["http://localhost:8000/submit"])
    SLAANESH_ADDRESS = < SLAANESH ADDRESS >
     
    @sigmar.on_interval(period=3.0)
    async def send_message(ctx: Context):
        await ctx.send(SLAANESH_ADDRESS, Message(message="hello there slaanesh"))
     
    @sigmar.on_message(model=Message)
    async def sigmar_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
    if __name__ == "__main__":
        sigmar.run()

    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    slaanesh = Agent(name="slaanesh", seed="slaanesh recovery phrase", port=8001, endpoint=["http://localhost:8001/submit"])
     
    @slaanesh.on_message(model=Message)
    async def slaanesh_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
        await ctx.send(sender, Message(message="hello there sigmar"))
     
    if __name__ == "__main__":
        slaanesh.run()

### Steps to Run the Agents in Order:[](#steps-to-run-the-agents-in-order)

1.  Start Slaanesh first in one terminal window:

2.  Then start Sigmar in another terminal window:

The output would be:

for agent `agent_slaanesh.py`

    INFO:     [slaanesh]: Starting agent with address: agent1qddw8cfn685e3p082lcn9dxe63yrqf03s77puv4d0as8a4j7c84s572juzj
    INFO:     [slaanesh]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qddw8cfn685e3p082lcn9dxe63yrqf03s77puv4d0as8a4j7c84s572juzj
    INFO:     [slaanesh]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Almanac contract registration is up to date!
    INFO:     [slaanesh]: Received message from agent1qdtmapxwfljj2xwz8yqpljd75tmnxjjdmrta86q68aqf5r9d7nw7kqyt40p: hello there sigmar
    INFO:     [slaanesh]: Received message from agent1qdtmapxwfljj2xwz8yqpljd75tmnxjjdmrta86q68aqf5r9d7nw7kqyt40p: hello there sigmar

for agent `agent_sigmar.py`

    INFO:     [sigmar]: Starting agent with address: agent1qdtmapxwfljj2xwz8yqpljd75tmnxjjdmrta86q68aqf5r9d7nw7kqyt40p
    INFO:     [sigmar]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qdtmapxwfljj2xwz8yqpljd75tmnxjjdmrta86q68aqf5r9d7nw7kqyt40p
    INFO:     [sigmar]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Almanac contract registration is up to date!
    INFO:     [sigmar]: Received message from agent1qddw8cfn685e3p082lcn9dxe63yrqf03s77puv4d0as8a4j7c84s572juzj: hello there slaanesh
    INFO:     [sigmar]: Received message from agent1qddw8cfn685e3p082lcn9dxe63yrqf03s77puv4d0as8a4j7c84s572juzj: hello there slaanesh

However, these agents can only communicate with each other on their local network.

Agents Remote Communication: the Almanac Contract[](#agents-remote-communication-the-almanac-contract)
------------------------------------------------------------------------------------------------------

An agent must register to the [Almanac contract](https://network.fetch.ai/docs/introduction/almanac/introduction) to communicate, to search for other agents or be found. Agents can query this contract to retrieve an HTTP endpoint for a recipient agent. [Registration in the Almanac](https://network.fetch.ai/docs/introduction/almanac/register-in-almanac) requires paying a small fee, so make sure to have enough funds to allow for this. You can query the Almanac now, by using the search feature on [Agentverse](https://agentverse.ai/).

Whenever an agent registers in the Almanac, it must specify the service [endpoints](https://network.fetch.ai/docs/introduction/almanac/endpoints) alongside a weight parameter for each endpoint provided. Agents trying to communicate with your agent will choose the service endpoints using a weighted random selection.

Here, we show you how to create two agents and make them remotely communicate by registering and using the Almanac Contract.

### Walk-through[](#walk-through-1)

The first step would be to create two different Python scripts for this task, each one representing a remote agent:

Slaanesh:

    echo. > remote_agents_slaanesh.py

Sigmar:

    echo. > remote_agents_sigmar.py

Let‚Äôs start by defining the script for **sigmar**.

#### Sigmar[](#sigmar)

1.  In `remote_agents_sigmar.py` script, we would need to import the necessary classes from the `uagents` (`Agent`, `Context`, and `Model`). We then need to define the message structure for messages to be exchanged between agents using the class `Model`, as well as the `RECIPIENT_ADDRESS` (slaanesh‚Äôs address). Note that if you don‚Äôt know slaanesh‚Äôs address yet, you can use `print(slaanesh.address)` after defining agent `slaanesh` to get this information. This is the address towards which `sigmar` will send messages:

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    RECIPIENT_ADDRESS = "agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum"
     
     

2.  Let‚Äôs now create our agent, `sigmar`, by providing `name`, `seed`, `port`, and `endpoint`:

     
    sigmar = Agent(
        name="sigmar",
        port=8000,
        seed="sigmar secret phrase",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     

3.  We are ready to define `sigmar`‚Äôs behaviors. Let‚Äôs start with a function for `sigmar` to send messages:

     
    @sigmar.on_interval(period=2.0)
    async def send_message(ctx: Context):
        await ctx.send(RECIPIENT_ADDRESS, Message(message="hello there slaanesh"))
     
     

Here, the `.on_interval()` decorator schedules the `send_message()` function to be run every 2 seconds. Inside the function, there is an asynchronous call indicated by the `ctx.send()` method. This call sends a message with the content `"hello there slaanesh"` to the `RECIPIENT_ADDRESS`.

4.  We then need to define a function for `sigmar` to handle incoming messages from other agents:

     
    @sigmar.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
    if __name__ == "__main__":
        sigmar.run()
     

Here, we have used the `.on_message()` decorator to register the `message_handler()` coroutine function as a handler for incoming messages of type `Message`.

The `message_handler()` function takes three arguments: `ctx`, `sender`, and `msg`. Inside this function, we call the `ctx.logger.info()` method to log information about the received message, including the sender and message content.

5.  We can now save the script.

The overall script for sigmar agent should be looking as follows:

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    RECIPIENT_ADDRESS = "agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum"
     
    sigmar = Agent(
        name="sigmar",
        port=8000,
        seed="sigmar secret phrase",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     
    @sigmar.on_interval(period=2.0)
    async def send_message(ctx: Context):
        await ctx.send(RECIPIENT_ADDRESS, Message(message="hello there slaanesh"))
     
    @sigmar.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
    if __name__ == "__main__":
        sigmar.run()
     

Remember that you need to provide the `name`, `seed`, `port`, `endpoint` and `RECIPIENT_ADDRESS` parameters to correctly run this code.

We can now proceed by writing the script for agent `slaanesh`.

#### Slaanesh[](#slaanesh)

1.  In `remote_agents_slaanesh.py` script, import the necessary classes from the `uagents`. Then, define the message structure for messages to be exchanged between the agents using the `Model` class, as well as our second uAgent, `slaanesh`, by providing `name`, `seed`, `port`, and `endpoint`:

remote\_agents\_slaanesh.py

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    slaanesh = Agent(
        name="slaanesh",
        port=8001,
        seed="slaanesh secret phrase",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
     

2.  Let‚Äôs now define a function for `slaanesh` to handle incoming messages and answering back to the sender:

remote\_agents\_slaanesh.py

     
    @slaanesh.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        await ctx.send(sender, Message(message="hello there sigmar"))
     
    if __name__ == "__main__":
        slaanesh.run()
     

Here, we have defined an asynchronous `message_handler()` function for slaanesh to handle incoming messages from other uAgents. The function is decorated with `.on_message()`, and it is triggered whenever a message of type `Message` is received by `slaanesh`. When a message is received, the handler function logs the sender‚Äôs address and the content of the message. It then sends a response back to the sender using the `ctx.send()` with a new message. The response message contains the `Message` data model with a `"hello there sigmar"` message.

3.  Save the script.

The overall script for `slaanesh` should be looking as follows:

remote\_agents\_slaanesh.py

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    slaanesh = Agent(
        name="slaanesh",
        port=8001,
        seed="slaanesh secret phrase",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    @slaanesh.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        await ctx.send(sender, Message(message="hello there sigmar"))
     
    if __name__ == "__main__":
        slaanesh.run()
     

Remember that you need to provide the `name`, `seed`, `port` and `endpoint` parameters to correctly run this code.

#### Run the scripts[](#run-the-scripts)

In different terminal windows, first run `slaanesh` and then `sigmar`. They will register automatically in the Almanac contract using their funds. The received messages will print out in each terminal:

Terminal 1: `python remote_agents_slaanesh.py`

Terminal 2: `python remote_agents_sigmar.py`

The output will depend on the terminal:

*   **Sigmar**:
    
        INFO:     [sigmar]: Registration on Almanac API successful
        INFO:     [sigmar]: Registering on almanac contract...
        INFO:     [sigmar]: Registering on almanac contract...complete
        INFO:     [sigmar]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qvwqu6a0km09mq4f6j6kmke9smswmgcergmml9a54av9449rqtmmxy4qwe6
        INFO:     [sigmar]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
        INFO:     [sigmar]: Received message from agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum: hello there sigmar
        INFO:     [sigmar]: Received message from agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum: hello there sigmar
        INFO:     [sigmar]: Received message from agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum: hello there sigmar
    
*   **Slaanesh**:
    
        INFO:     [slaanesh]: Registration on Almanac API successful
        INFO:     [slaanesh]: Registering on almanac contract...
        INFO:     [slaanesh]: Registering on almanac contract...complete
        INFO:     [slaanesh]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qvm7v76zs6w2x90xvq99yc5xh7c2thjtm44zc09me556zxnra627gkf4zum
        INFO:     [slaanesh]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
        INFO:     [slaanesh]: Received message from agent1qvwqu6a0km09mq4f6j6kmke9smswmgcergmml9a54av9449rqtmmxy4qwe6: hello there slaanesh
        INFO:     [slaanesh]: Received message from agent1qvwqu6a0km09mq4f6j6kmke9smswmgcergmml9a54av9449rqtmmxy4qwe6: hello there slaanesh
        INFO:     [slaanesh]: Received message from agent1qvwqu6a0km09mq4f6j6kmke9smswmgcergmml9a54av9449rqtmmxy4qwe6: hello there slaanesh
    

### Before we go on‚Ä¶[](#before-we-go-on)

As we touched on before in [Register in Almanac](https://network.fetch.ai/docs/introduction/almanac/register-in-almanac), when the agent uses `.run()` function this tells the `uagents` library to register the agent to the Almanac. It‚Äôs simple, agents initialize themselves, and register to a service which acts as a search engine for agents (the Almanac) then, when agents receive messages they can respond.

Conclusion[](#conclusion)
-------------------------

In this guide, we explored two different methods of communication for Agents using the `uagents` library:

*   **Local communication**.
*   **Remote communication** via the Almanac Contract.

For _local communication_, we learned how to use the `uagents` library to create two agents, `sigmar` and `slaanesh`, and enable them to exchange messages with one another. We defined the message structure using the `Model` class and implemented message handlers for both agents. By running the script we observed their real-time message exchange.

Next, we delved into _remote communication_, which facilitates interaction between agents through the Almanac Contract. This method requires registering the agents in the Almanac Contract and querying for **HTTP endpoints** for communication. By running the scripts separately, we could observe the real-time messages exchange, fostering a decentralized network of interacting agents.

With this, we suspect you‚Äôre ready to start building agents, as part of multi-agent system the Almanac allows; awesome. If you want to go further though, take a look at the [message verification](https://uagents.fetch.ai/docs/guides/msg_verification) and [sending tokens](https://uagents.fetch.ai/docs/guides/send_tokens), after-all you do want to be sure you are speaking to whom you think you are, and agents getting paid is awesome.</content>
</page>

<page>
  <title>Agents protocols docs</title>
  <url>https://uagents.fetch.ai/docs/guides/protocols</url>
  <content>`protocols` represent message types and handlers, protocols are used to facilitate communication and interaction between agents in the Framework.

A `protocol` is built similar to an agent, but it has no identity and cannot be run. Protocols only contains the message types and handlers that define some components of an agent‚Äôs functionality.

They‚Äôre a simple way of adding additional Message types and the handlers for them. For example if you have an agent that primarily responds to a single handler, you could extend that agent with an additional protocol to respond to _n_ more message types.

Let‚Äôs use a _simple restaurant table booking request_ as an example to better understand what a protocol means and how to build one:

1.  Let‚Äôs start by creating a folder for our **protocols**. Then, let‚Äôs create Python script within it, and name it:
    
    `mkdir protocols`
    
    and
    
2.  We import from `uagents` library the necessary classes `Context`, `Model`, and `Protocol`. Then, need to define the type of messages that the handler will receive and send:
    
        from uagents import Context, Model, Protocol
         
        class BookTableRequest(Model):
            table_number: int
         
        class BookTableResponse(Model):
            success: bool
    
    We use the `Model` class from `uagents` library to define `BookTableRequest` and `BookTableResponse` classes for setting up the structure of messages to be exchanged between your agents. The `BookTableRequest` class represents a request to book a table, containing the desired table number, while the `BookTableResponse` class represents the response to that request, indicating whether the booking was successful.
    
3.  Now, we would need to define the booking protocol as `book_proto` and also define the desired logic to determine if the `BookTableResponse` will be successful or not:
    
        book_proto = Protocol()
         
        @book_proto.on_message(model=BookTableRequest, replies={BookTableResponse})
        async def handle_book_request(ctx: Context, sender: str, msg: BookTableRequest):
            if ctx.storage.has(str(msg.table_number)):
                success = False
            else:
                success = True
                ctx.storage.set(str(msg.table_number), sender)
         
            # send the response
            await ctx.send(sender, BookTableResponse(success=success))
    
4.  We can then import our booking protocol from into the script we create for our agent, in the following way:
    
        from protocols.book import book_proto
    
5.  If your agent is called `restaurant` you can include the protocol in this way:
    
        restaurant.include(book_proto)
    

For a better understanding of these concepts, consider having a look at the [Agents storage](https://uagents.fetch.ai/docs/guides/storage) and [Exchange protocol](https://uagents.fetch.ai/docs/guides/exchange_protocol) resources. Also, check out the [Agents: broadcast](https://uagents.fetch.ai/docs/guides/broadcast) guide for an additional implementation of protocols in Agents communication.

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Exchange protocol docs</title>
  <url>https://uagents.fetch.ai/docs/guides/exchange_protocol</url>
  <content>Overview[](#overview)
---------------------

The **Exchange protocol** is a protocol designed as part of the uAgents Framework. It defines a standardized method for communication between agents within the Agents ecosystem.

The Exchange protocol enables agents to exchange **messages** using a **JSON-based format**, which are structured as key-value pairs following the JSON standard. Messages can contain various types of information and are used to convey data and instructions between Agents.

Within the protocol, **envelopes** facilitate communication by encapsulating messages. Envelopes serve as containers for the messages and include additional metadata.

In this protocol, agents can send **messages** enclosed in **envelopes**, which are then encoded and sent via HTTP to the [endpoints](https://network.fetch.ai/docs/introduction/almanac/endpoints) of other agents.

By adhering to the Agents Exchange Protocol, Agents within the ASI Network can communicate with each other using a standardized and interoperable method.

‚ÑπÔ∏è

The protocol establishes a common format and structure for messages, enabling seamless interaction and integration between different agents and services.

We break down each of these concepts in more detail below.

Core concepts[](#core-concepts)
-------------------------------

### Messages[](#messages)

Messages consist of key-value pairs following the standard JSON format.

Here are a few examples:

    { "name": "alice", "age": 26, "languages": ["English", "Japanese", "Arabic"] }

    { "item": "pretzel", "bid": { "amount": 120, "denomination": "GBP" } }

Once messages are created, these are enclosed in envelopes containing some important metadata.

### Envelopes[](#envelopes)

Envelopes have the following form and are quite similar to blockchain transactions:

    @dataclass
    class Envelope(BaseModel):
        version: int                     # Envelope version
        sender: str:                     # Bech32-encoded public address of the sender
        target: str:                     # Bech32-encoded public address of the target recipient
        session: UUID4                   # UUID of the session
        schema_digest: str               # Digest of the schema used for the payload
        protocol_digest: Optional[str]   # Optional protocol digest for custom protocols
        payload: Optional[str]           # JSON payload encoded as a base64 string
        expires: Optional[int]           # Unix timestamp in seconds indicating expiration
        nonce: Optional[int]             # Optional nonce
        signature: Optional[str]         # Bech32-encoded signature

### Semantics[](#semantics)

*   The `sender` field exposes the address of the sender of the message.
*   The `target` field exposes the address of the recipient of the message.
*   The `protocol` contains the unique schema digest string for the message.
*   The `payload` field exposes the payload of the protocol. Its JSON representation should be a base64 encoded string.
*   The `expires` field contains the Unix timestamp in seconds at which the message is no longer valid.
*   The `signature` field contains the signature that is used to authenticate that the message has been sent from the `sender` agent.

Envelopes are then JSON encoded and sent to endpoints of other agents or services.

### Endpoints[](#endpoints)

The protocol supports only one standardized endpoint: `HTTP 1.1 POST /submit`, and expects data which is broadly JSON compatible.

‚ÑπÔ∏è

The protocol currently supports MIME content type `application/json`.</content>
</page>

<page>
  <title>Agent Handlers docs</title>
  <url>https://uagents.fetch.ai/docs/guides/handlers</url>
  <content>Introduction[](#introduction)
-----------------------------

Within the uAgents Framework, functions can be decorated with handlers, to only be triggered on a condition caught by the uAgents library.

Below, we show how to use the following different event handlers:

1.  **Interval tasks**: `.on_interval()`
2.  **Handle messages**: `.on_message()`
3.  **Answer queries**: `.on_query()`
4.  **Triggered by event**: `on_event()`

Creating an interval task with `on_interval()` handler[](#creating-an-interval-task-with-on_interval-handler)
-------------------------------------------------------------------------------------------------------------

Sometimes an agent will need to perform a task periodically. To do this we can use the `on_interval()` decorator which periodically repeats a given function for the agent. For instance, an agent could send a message every 2 seconds to another agent.

**Let‚Äôs get started and create our first interval task!**

Imports needed[](#imports-needed)
---------------------------------

### Walk-through[](#walk-through)

1.  Let‚Äôs create a Python script for this task, and name it:
    
2.  Then import the necessary classes from `uagents` library, `Agent` and `Context`, and create our agent:
    

     
    from uagents import Agent, Context
     
    agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://localhost:8000/submit"])
     

3.  Create a function to handle the startup event, which will introduce the agent:

     
    @agent.on_event("startup")
    async def introduce_agent(ctx: Context):
        ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
     

4.  We can now define our agent‚Äôs interval behavior. We want our agent to log a message every 2 seconds using the `on_interval` decorator:

     
    @agent.on_interval(period=2.0)
    async def say_hello(ctx: Context):
        ctx.logger.info("Hello!")
     
    if __name__ == "__main__":
        agent.run()
     

The output will be printed out using the `ctx.logger.info()` method.

5.  Save the script.

The overall script should look as follows:

     
    from uagents import Agent, Context
     
    agent = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://localhost:8000/submit"])
     
    @agent.on_event("startup")
    async def introduce_agent(ctx: Context):
        ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
     
    @agent.on_interval(period=2.0)
    async def say_hello(ctx: Context):
        ctx.logger.info("Hello!")
     
    if __name__ == "__main__":
        agent.run()
     

### Run the script[](#run-the-script)

Run the script: `python interval_task.py`

The output should be as follows:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [alice]: Hello, I'm agent alice and my address is agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t.
    INFO:     [alice]: Hello!
    INFO:     [alice]: Hello!
    INFO:     [alice]: Hello!

Handle messages using the `on_message()` handler[](#handle-messages-using-the-on_message-handler)
-------------------------------------------------------------------------------------------------

We now showcase a scenario where three agents, named `alice`, `bob`, and `charles`, use a custom [protocol](https://uagents.fetch.ai/docs/guides/protocols) to communicate. In the example, Alice and Bob support the protocol, whereas Charles attempts to send broadcast messages to all agents using the protocol. Agents use the `on_message()` handler which allows them to handle messages matching specific data models.

**Let‚Äôs get started!**

### Walk-through[](#walk-through-1)

1.  First of all, let‚Äôs create a Python script for this task, and name it:
    
2.  We then need to import the `Agent`, `Bureau`, `Context`, `Model`, and `Protocol` classes from the `uagents` library. Then, let‚Äôs create the 3 different agents using the class `Agent`. Each agent is initialized with a unique name and a seed phrase for wallet recovery.
    

     
    from uagents import Agent, Bureau, Context, Model, Protocol
     
    # create agents
    # alice and bob will support the protocol
    # charles will try to reach all agents supporting the protocol
    alice = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob recovery phrase", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
    charles = Agent(name="charles", seed="charles recovery phrase", port=8002, endpoint=["http://127.0.0.1:8002/submit"])
     

It is optional but useful to include a `seed` parameter when creating an agent to set fixed [addresses](https://uagents.fetch.ai/docs/getting-started/address). Otherwise, random addresses will be generated every time you run the agent.

3.  Let‚Äôs then define the message data models to specify the type of messages being handled and exchanged by the agents. We define a `BroadcastExampleRequest` and a `BroadcastExampleResponse` data models. Finally, create a `protocol` named `proto` with version `1.0`:

     
    class BroadcastExampleRequest(Model):
        pass
     
     
    class BroadcastExampleResponse(Model):
        text: str
     
     
    # define protocol
    proto = Protocol(name="proto", version="1.0")
     

4.  Let‚Äôs now define a message handler function for incoming messages of type `BroadcastExampleRequest` in the protocol:

     
    @proto.on_message(model=BroadcastExampleRequest, replies=BroadcastExampleResponse)
    async def handle_request(ctx: Context, sender: str, _msg: BroadcastExampleRequest):
        await ctx.send(
            sender, BroadcastExampleResponse(text=f"Hello from {ctx.agent.name}")
        )
     

Here we defined a `handle_request()` function which is used whenever a request is received. This sends a response back to the sender. This function is decorated with the `.on_message()` decorator indicating that this function is triggered whenever a message of type `BroadcastExampleRequest` is received. The function sends a response containing a greeting message with the name of the agent that sent the request in the first place.

5.  Now, we need to include the `protocol` into the agents. Specifically, the protocol is included in both `alice` and `bob` agents. This means they will follow the rules defined in the protocol when communicating:

     
    alice.include(proto)
    bob.include(proto)
     

‚ÑπÔ∏è

After the first registration in the [Almanac](https://network.fetch.ai/docs/introduction/almanac/introduction) smart contract, it will take about 5 minutes before the agents can be found through the protocol.

6.  It is now time to define the behavior and function of `charles` agent:

     
     @charles.on_interval(period=5)
     async def say_hello(ctx: Context):
         status_list = await ctx.broadcast(proto.digest, message=BroadcastExampleRequest())
         ctx.logger.info(f"Trying to contact {len(status_list)} agents.")
     
     
     @charles.on_message(model=BroadcastExampleResponse)
     async def handle_response(ctx: Context, sender: str, msg: BroadcastExampleResponse):
         ctx.logger.info(f"Received response from {sender}: {msg.text}")
     

In the first part, we use the `.on_interval()` decorator to define an interval behavior for this agent when the script is being run. In this case, the agent will execute the `say_hello()` function every 5 seconds. The `Context` object is a collection of data and functions related to the agent. Inside the `say_hello()` function, the agent uses the `ctx.broadcast()` method to send a broadcast message. The message is of type `BroadcastExampleRequest()` and it is being sent using the protocol‚Äôs digest (`proto.digest`).

Then, we defined a `.on_message()` decorator which decorates `handle_response()` function. This function handles all incoming messages of type `BroadcastExampleResponse` from other agents. When a response is received, it logs the information. Inside the `handle_response()` function, the agent logs an informational message using `ctx.logger.info()` method to print the sender and the content of the message. The message includes the sender‚Äôs name and the text content of the response message.

7.  We are now ready to set up a `Bureau` object for agents to be run together at the same time, and we add `alice`, `bob`, and `charles` to it using the `bureau.add()` method:

     
    bureau = Bureau(port=8000, endpoint="http://localhost:8000/submit")
    bureau.add(alice)
    bureau.add(bob)
    bureau.add(charles)
     
    if __name__ == "__main__":
        bureau.run()
     

The bureau is assigned to listen on `port=8000` and specifies an `endpoint` at `"http://localhost:8000/submit"` for submitting data.

8.  Save the script.

The overall script should look as follows:

     
    from uagents import Agent, Bureau, Context, Model, Protocol
     
    # create agents
    # alice and bob will support the protocol
    # charles will try to reach all agents supporting the protocol
    alice = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob recovery phrase", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
    charles = Agent(name="charles", seed="charles recovery phrase", port=8002, endpoint=["http://127.0.0.1:8002/submit"])
     
     
    class BroadcastExampleRequest(Model):
        pass
     
     
    class BroadcastExampleResponse(Model):
        text: str
     
     
    # define protocol
    proto = Protocol(name="proto", version="1.0")
     
     
    @proto.on_message(model=BroadcastExampleRequest, replies=BroadcastExampleResponse)
    async def handle_request(ctx: Context, sender: str, _msg: BroadcastExampleRequest):
        await ctx.send(
            sender, BroadcastExampleResponse(text=f"Hello from {ctx.agent.name}")
        )
     
     
    # include protocol
    # Note: after the first registration on the almanac smart contract, it will
    # take about 5 minutes before the agents can be found through the protocol
    alice.include(proto)
    bob.include(proto)
     
     
    # let charles send the message to all agents supporting the protocol
    @charles.on_interval(period=5)
    async def say_hello(ctx: Context):
        status_list = await ctx.broadcast(proto.digest, message=BroadcastExampleRequest())
        ctx.logger.info(f"Trying to contact {len(status_list)} agents.")
     
     
    @charles.on_message(model=BroadcastExampleResponse)
    async def handle_response(ctx: Context, sender: str, msg: BroadcastExampleResponse):
        ctx.logger.info(f"Received response from {sender}: {msg.text}")
     
     
    bureau = Bureau(port=8000, endpoint="http://localhost:8000/submit")
    bureau.add(alice)
    bureau.add(bob)
    bureau.add(charles)
     
    if __name__ == "__main__":
        bureau.run()
     

### Run the script[](#run-the-script-1)

Make sure to have activated your virtual environment correctly.

Run the script: `python broadcast.py`

The output would be:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [  bob]: Registration on Almanac API successful
    INFO:     [  bob]: Registering on almanac contract...
    INFO:     [  bob]: Registering on almanac contract...complete
    INFO:     [charles]: Registration on Almanac API successful
    INFO:     [charles]: Registration on Almanac API successful
    INFO:     [charles]: Registering on almanac contract...
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [charles]: Trying to contact 2 agents.
    INFO:     [charles]: Received response from agent1q0mau8vkmg78xx0sh8cyl4tpl4ktx94pqp2e94cylu6haugt2hd7j9vequ7: Hello from bob
    INFO:     [charles]: Received response from agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t: Hello from alice

Answer queries with `on_query()` handler[](#answer-queries-with-on_query-handler)
---------------------------------------------------------------------------------

The `on_query()` handler is for incoming queries that match a specified `Model`. This decorator enables the agent to respond to queries in an event-driven manner.

### Walk-through[](#walk-through-2)

#### Agent‚Äôs script[](#agents-script)

For the Agent, the script sets up an Agent to handle incoming queries. It defines two models: `TestRequest` and `Response`. Upon startup, it logs the Agent‚Äôs details. The core functionality lies in the `query_handler`, decorated with `@agent.on_query()`, which processes received queries and sends back a predefined response. This demonstrates creating responsive agents within the `uagents` Framework, showcasing how they can interact with other agents or functions in an asynchronous, event-driven architecture.

     
    from uagents import Agent, Context, Model
     
    class TestRequest(Model):
        message: str
     
    class Response(Model):
        text: str
     
    # Initialize the agent with its configuration.
    agent = Agent(
        name="your_agent_name_here",
        seed="your_agent_seed_here",
        port=8001,
        endpoint="http://localhost:8001/submit",
    )
     
    @agent.on_event("startup")
    async def startup(ctx: Context):
        ctx.logger.info(f"Starting up {agent.name}")
        ctx.logger.info(f"With address: {agent.address}")
        ctx.logger.info(f"And wallet address: {agent.wallet.address()}")
     
    # Decorator to handle incoming queries.
    @agent.on_query(model=TestRequest, replies={Response})
    async def query_handler(ctx: Context, sender: str, _query: TestRequest):
        ctx.logger.info("Query received")
        try:
            # do something here
            await ctx.send(sender, Response(text="success"))
        except Exception:
            await ctx.send(sender, Response(text="fail"))
     
    # Main execution block to run the agent.
    if __name__ == "__main__":
        agent.run()
     

The agent is created using the `Agent` class from `uagents` library. You can initialize it by providing it with a `name`, `seed`, `port`, and `endpoint`. It defines an `on_event()` handler for the `startup` event, where it logs information about the agent‚Äôs initialization. It defines an `on_query()` handler for handling queries of type `TestRequest`. Upon receiving a query, it processes it and sends back a `Response`. The agent is then set to run.

#### Proxy[](#proxy)

The proxy is implemented using `FastAPI`. It sets up two routes: `"/"` for a simple root message and `"/endpoint"` for receiving requests. When a `POST` request is made to `"/endpoint"` with a JSON payload containing a `TestRequest`, it triggers the `make_agent_call` function. Inside `make_agent_call`, it calls `agent_query` to communicate with the agent. The agent receives the query, processes it, and sends back a response. The proxy receives the response from the agent and sends back a success message along with the response text.

Let‚Äôs explore the Proxy code script step-by-step:

1.  First of all navigate to directory where you want to create your project.
    
2.  Create a Python script name `on_query.py` by running:
    
3.  We need to import `json`, `fastapi`, `uagent`‚Äôs `Model` and `query`. Then we would need to define the query format using the `TestRequest` class as a subclass of `Model`:
    

     
    import json
     
    from fastapi import FastAPI, Request
    from uagents import Model
    from uagents.query import query
    from uagents.envelope import Envelope
     
    AGENT_ADDRESS = "agent1qt6ehs6kqdgtrsduuzslqnrzwkrcn3z0cfvwsdj22s27kvatrxu8sy3vag0"
     
    class TestRequest(Model):
        message: str
     

4.  Create `agent_query()` function to send query to agent and decode the response received.

     
    async def agent_query(req):
        response = await query(destination=AGENT_ADDRESS, message=req, timeout=15)
        if isinstance(response, Envelope):
            data = json.loads(response.decode_payload())
            return data["text"]
        return response
     

5.  Initialize a `FastAPI` app:

6.  Define a root endpoint to test the server:

     
    @app.get("/")
    def read_root():
        return "Hello from the Agent controller"
     

7.  Define an endpoint to make agent calls:

     
    @app.post("/endpoint")
    async def make_agent_call(req: Request):
        model = TestRequest.parse_obj(await req.json())
        try:
            res = await agent_query(model)
            return f"successful call - agent response: {res}"
        except Exception:
            return "unsuccessful agent call"
     

8.  Save the script. Remember that you need to provide the `AGENT_ADDRESS` parameter to correctly run this code.

The overall script should look as follows:

     
    import json
     
    from fastapi import FastAPI, Request
    from uagents import Model
    from uagents.query import query
    from uagents.envelope import Envelope
     
    AGENT_ADDRESS = "agent1qt6ehs6kqdgtrsduuzslqnrzwkrcn3z0cfvwsdj22s27kvatrxu8sy3vag0"
     
    class TestRequest(Model):
        message: str
     
    async def agent_query(req):
        response = await query(destination=AGENT_ADDRESS, message=req, timeout=15)
        if isinstance(response, Envelope):
            data = json.loads(response.decode_payload())
            return data["text"]
        return response
     
     
    app = FastAPI()
     
    @app.get("/")
    def read_root():
        return "Hello from the Agent controller"
     
    @app.post("/endpoint")
    async def make_agent_call(req: Request):
        model = TestRequest.parse_obj(await req.json())
        try:
            res = await agent_query(model)
            return f"successful call - agent response: {res}"
        except Exception:
            return "unsuccessful agent call"
     

#### Run the example[](#run-the-example)

In separate terminals:

1.  Run the **FastAPI proxy**: `uvicorn proxy:app`
    
2.  Run the **agent**: `python agent.py`
    
3.  Query the agent via the proxy: `curl -d '{"message": "test"}' -H "Content-Type: application/json" -X POST http://localhost:8000/endpoint`
    

Catching events with `on_event()` handler[](#catching-events-with--on_event-handler)
------------------------------------------------------------------------------------

During startup, and shutdown there are two events that are caught by the uAgents library, `startup` and `shutdown`.

Here‚Äôs an example:

### on\_event(‚Äústartup‚Äù)[](#on_eventstartup)

        @agent.on_event("startup")
        async def introduce_agent(ctx: Context):
            ctx.logger.info(f"Hello, I'm agent {agent.name} and my address is {agent.address}.")
            ...
     

### on\_event(‚Äúshutdown‚Äù)[](#on_eventshutdown)

        @agent.on_event("shutdown")
        async def introduce_agent(ctx: Context):
            ctx.logger.info(f"Hello, I'm agent {agent.name} and I am shutting down")
            ...</content>
</page>

<page>
  <title>Public and private agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/public_private_agents</url>
  <content>Defining public and private agents[](#defining-public-and-private-agents)
-------------------------------------------------------------------------

There are two ways in which an Agent can be classified as public: they define an endpoint and/or, they publish their manifests:

     
        agent = Agent(
            name="demo agent",
            seed=SEED,
            endpoint=["http://127.0.0.1:8000/submit"],
        )
        agent.include(new_protocol, publish_manifest=True)
        agent.run()
     

Private Agents can be private in two ways: either by hiding a protocol they use from public and/or by not defining an endpoint:

     
        agent = Agent(
            name="private demo agent",
            seed=SEED,
        )
     
        agent.include(new_protocol, publish_manifest=False)
        agent.run()
     

You would need to share the IP of the private Agent you‚Äôre running to the other Agent you‚Äôre communicating with.

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Hosted, Local, Mailbox and Proxy Agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/types</url>
  <content>Agents operate in various environments depending on how they are created and deployed.

Understanding the difference between Hosted, Local, Mailbox and Proxy Agents helps developers choose the right setup for their needs.

Local Agents[](#local-agents)
-----------------------------

Local Agents run on your machine or infrastructure, providing complete control over their environment, configuration, and execution. Unlike hosted Agents, they handle real-time events, messages, and tasks continuously, making them ideal for persistent state and direct access to local resources. Local Agents integrate with any Python package or custom module, supporting advanced capabilities like machine learning and data processing. They maintain persistent state across function executions, unlike hosted Agents, where state resets after each call. Setting up a Local Agent requires a Python environment, dependencies, and running the Agent script. They can operate continuously or within Docker containers for scalability and isolation.

Local Agents are perfect for high-performance, real-time applications requiring deep customization, resource management, and direct integration with local functions. Head over to the following resource for a better understanding of Agents and their applications:

Hosted Agents[](#hosted-agents)
-------------------------------

[Hosted Agents](https://docs.agentverse.ai/docs/quickstart) are cloud-based Agents managed within the [Agentverse](https://agentverse.ai/),enabling developers to deploy and manage Agents without handling infrastructure. These Agents function as lightweight, efficient tasks, resetting global variables after each call. To maintain state across calls, developers must use Agent Storage for stateful behavior.

Developers can start with blank scripts or use customizable templates for common use cases like retrieving stock prices or finding nearby restaurants. Hosted Agents are highly accessible, requiring no local dependencies, and include an `agent.py` file from which you can develop them straightforwardly. For a better reference to these topics, check out the following resources:

Mailbox Agents[](#mailbox-agents)
---------------------------------

The [Agentverse Mailbox feature](https://uagents.fetch.ai/docs/agentverse/mailbox) makes Agents a hybrid between Hosted and Local types. This because Local Agents may not always be online all the time due to network outages, being behind a firewall, or intentionally going offline for resource management. To manage such scenarios, the **Mailbox** feature in Agentverse allows Agents to receive messages while they are offline with ease. Once the Agent comes back online, it can retrieve these messages from its mailbox.

**Local Agents can use a Mailbox to ensure that no messages are lost when they are temporarily disconnected from the network**; the Mailbox acts as a message buffer, storing communications until the Agent comes back online and ready to process them. Indeed, this feature enables interaction with other Agents or functions without the Agent being online continuously.

In order to set up a mailbox for a local Agent, you first need to create and configure the local Agent. For instance, consider the following basic Agent:

     
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    SEED_PHRASE = "put_your_seed_phrase_here"
     
    # Now your agent is ready to join the agentverse!
    agent = Agent(
        name="alice",
        port=8000,
        mailbox=True
    )
     
    # Copy the address shown below
    print(f"Your agent's address is: {agent.address}")
     
    if __name__ == "__main__":
        agent.run()
     

Once you run this Agent, you will be able to see a link in your terminal output redirecting you towards the [Local Agent Inspector](https://uagents.fetch.ai/docs/agentverse/inspector) for this specific Agent on the [Agentverse](https://agentverse.ai/docs).

By clicking the **Connect** button and then choosing **Mailbox** you will be guided into correctly setting up a mailbox for your local Agent. To test your Mailbox setup, you can create another Agent (on Agentverse for instance) that sends messages to the Mailbox while the first Agent is offline. When the first Agent comes back online, it will retrieve and process the stored messages.

For a complete example, check out this [guide](https://docs.agentverse.ai/docs/uAgents/mailbox).

Proxy Agents[](#proxy-agents)
-----------------------------

A Proxy serves as a bridge between your Agent and the Agentverse, allowing the Agent to publish interaction data without needing a Mailbox. This setup is particularly beneficial for Agents requiring continuous operation and visibility in the [Agentverse Marketplace](https://docs.agentverse.ai/docs/marketplace).

Consider the following basic Agent with a proxy:

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    # Initialize the agent
    agent = Agent(
        name="alice",
        seed="your_agent_seed_phrase",
        proxy=True
    )
     
    # Display the agent's address
    print(f"Your agent's address is: {agent.address}")
     
    if __name__ == "__main__":
        agent.run()
     

Run the Agent and access the Agent Inspector using the terminal output. Log in to the Agentverse and configure the Proxy connection by providing the public URL or IP address of your Agent. Verify and finalize the setup. Using a Proxy ensures that Agents remain discoverable and can interact with others in the Agentverse, enhancing engagement and visibility in the Marketplace.

For a complete overview of the Proxy setup, check out this [guide](https://uagents.fetch.ai/docs/agentverse/proxy).</content>
</page>

<page>
  <title>Bureau docs</title>
  <url>https://uagents.fetch.ai/docs/guides/bureau</url>
  <content>Introduction[](#introduction)
-----------------------------

The `Bureau` allows multiple agents to operate together within a shared environment. It manages the lifecycle of agents, including their communication, task handling, and external integrations. The Bureau simplifies the process of running agents in a collaborative and coordinated fashion, whether they need to exchange messages internally or interact with external systems.

Let‚Äôs get started!

Walk-through[](#walk-through)
-----------------------------

This walk-through will guide you through the process of setting up and running Agents using the Bureau, demonstrating its key functionalities, including agent management, message handling, and external communication via endpoints.

### Step 1: Setting Up Agents[](#step-1-setting-up-agents)

To begin, you need to create and define your Agents. Each Agent will have specific tasks and behaviors that can be scheduled or triggered by messages.

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
    agent_a = Agent(name="agent_a", seed="agent_a recovery phrase")
    agent_b = Agent(name="agent_b", seed="agent_b recovery phrase")
     

### Step 2: Defining Agent Behavior[](#step-2-defining-agent-behavior)

Next, define the behavior of each Agent, such as sending and receiving messages. This is done using decorators like `on_interval` to perform scheduled tasks and `on_message` to respond to incoming messages. Check out the [Agent Handlers](https://uagents.fetch.ai/docs/guides/handlers) for additional information on Agent Handlers and their usage.

     
    @agent_a.on_interval(period=3.0)
    async def send_message(ctx: Context):
        await ctx.send(agent_b.address, Message(message="Hello from agent_a"))
     
    # Handle received messages in agent_a
    @agent_a.on_message(model=Message)
    async def agent_a_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
    # Handle received messages in agent_b
    @agent_b.on_message(model=Message)
    async def agent_b_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
        await ctx.send(agent_a.address, Message(message="Reply from agent_b"))
     

### Step 3: Creating the Bureau[](#step-3-creating-the-bureau)

Once the Agents are set up, you can create a Bureau instance to manage them. The Bureau is responsible for running the Agents, handling communication, and orchestrating tasks.

#### Arguments the Bureau Takes:[](#arguments-the-bureau-takes)

The Bureau can be customized through a few important arguments when instantiated:

*   `agents` (Optional\[List\[Agent\]\]): A list of Agents to be managed by the Bureau. If you don‚Äôt add Agents during initialization, you can always add them later using the `add()` method.
    
*   `port` (Optional\[int\]): The port number on which the Bureau‚Äôs ASGI server will run. This is crucial if your Agents need to expose REST APIs for external communication. The default port is `8000`, but you can specify any available port.
    
*   `endpoint` (Optional\[Union\[str, List\[str\], Dict\[str, dict\]\]\]): Configuration for the Agent endpoints. You can specify how Agents communicate with external systems via REST. This could be a string, a list of strings, or a dictionary defining more complex configurations. If you want Agents external to the bureau to be able to communicate with the Agents within the Bureau this must be defined.
    
*   `loop` (Optional\[asyncio.AbstractEventLoop\]): The event loop used for managing asynchronous tasks. The Bureau creates one by default if none is provided.
    
*   `log_level` (Optional\[Union\[int, str\]\]): Sets the logging level, such as `INFO`, `DEBUG`, or `ERROR` to control the verbosity of execution logs.
    

    from uagents import Bureau
     
    bureau = Bureau()
     
    or 
    # Initialize the Bureau, optionally specifying port, agents, and other configurations
    bureau = Bureau(port=8000, agents=[agent_a, agent_b], endpoint="http://localhost:8000/submit")
     
    bureau.add(agent_a)
    bureau.add(agent_b)
     

### Step 4: Running the Bureau[](#step-4-running-the-bureau)

After adding your Agents, it‚Äôs time to run the Bureau. The Bureau will ensure that the Agents communicate seamlessly and handle tasks like message delivery and API management if necessary.

     
    if __name__ == "__main__":
        bureau.run()
     

Step 5: Message Handling and Communication

In this setup, `agent_a` sends a message to `agent_b` every 3 seconds. When `agent_b` receives the message, it replies to `agent_a`.

The Bureau handles the coordination and message passing between the Agents. You‚Äôll see logs indicating the messages sent and received by each Agent.

The overall script for this example should look as follows:

    from uagents import Agent, Bureau, Context, Model
     
    class Message(Model):
        message: str
     
    agent_a = Agent(name="agent_a", seed="agent_a recovery phrase")
    agent_b = Agent(name="agent_b", seed="agent_b recovery phrase")
     
    @agent_a.on_interval(period=3.0)
    async def send_message(ctx: Context):
        await ctx.send(agent_b.address, Message(message="Hello from agent_a"))
     
    @agent_a.on_message(model=Message)
    async def agent_a_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
    @agent_b.on_message(model=Message)
    async def agent_b_message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
        await ctx.send(agent_a.address, Message(message="Reply from agent_b"))
     
    bureau = Bureau()
     
    # if we want our bureau agents to receive messages from external agents:
    # bureau = Bureau(port=8000, agents=[agent_a, agent_b], endpoint="http://localhost:8000/submit")
     
    bureau.add(agent_a)
    bureau.add(agent_b)
     
    if __name__ == "__main__":
        bureau.run()
     

We are now ready to run the script: `python agent-bureau.py`

The output would be:

    WARNING:  [agent_a]: No endpoints provided. Skipping registration: Agent won't be reachable.
    WARNING:  [agent_b]: No endpoints provided. Skipping registration: Agent won't be reachable.
    INFO:     [agent_b]: Received message from agent1q2n33nmfscfscnz49a9e6nj4054d7r46v7x7522g4zh798tcwgs5q855p6q: Hello from agent_a
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [agent_a]: Received message from agent1q07ypwau2gv0y005m0ltycx7vpt3hpajsvvnltpu50wpgk87zzkmwc005ga: Reply from agent_b
    INFO:     [agent_b]: Received message from agent1q2n33nmfscfscnz49a9e6nj4054d7r46v7x7522g4zh798tcwgs5q855p6q: Hello from agent_a
    INFO:     [agent_a]: Received message from agent1q07ypwau2gv0y005m0ltycx7vpt3hpajsvvnltpu50wpgk87zzkmwc005ga: Reply from agent_b
    INFO:     [agent_b]: Received message from agent1q2n33nmfscfscnz49a9e6nj4054d7r46v7x7522g4zh798tcwgs5q855p6q: Hello from agent_a
    INFO:     [agent_a]: Received message from agent1q07ypwau2gv0y005m0ltycx7vpt3hpajsvvnltpu50wpgk87zzkmwc005ga: Reply from agent_b</content>
</page>

<page>
  <title>Synchronous Communication docs</title>
  <url>https://uagents.fetch.ai/docs/guides/send_receive</url>
  <content>Overview[](#overview)
---------------------

uAgents often send their messages in a ‚Äúfire and forget‚Äù manner, not they are forgetting, but they‚Äôre not blocked by no response. This isn‚Äôt always useful as sometimes your agents can only _do something_ with an extra piece of information. `send_and_receive()` allows you to send a message and effectively block the handler until you get a response.

The additional positive of this is that by using `send_and_receive()` you are possibly reducing how many handlers you would need to implement when compared with just using `send()` calls.

The example below shows three agents that are messaging each other with `send_and_receive()` and `send()`.

    from uagents import Agent, Bureau, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    alice = Agent(name="alice")
    bob = Agent(name="bob")
    clyde = Agent(name="clyde")
     
     
    @alice.on_interval(period=5.0)
    async def send_message(ctx: Context):
        msg = Message(message="Hey Bob, how's Clyde?")
        reply, status = await ctx.send_and_receive(bob.address, msg, response_type=Message)
        if isinstance(reply, Message):
            ctx.logger.info(f"Received awaited response from bob: {reply.message}")
        else:
            ctx.logger.info(f"Failed to receive response from bob: {status}")
     
     
    @bob.on_message(model=Message)
    async def handle_message_and_reply(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message: {msg.message}")
        new_msg = Message(message="How are you, Clyde?")
        reply, status = await ctx.send_and_receive(
            clyde.address, new_msg, response_type=Message
        )
        if isinstance(reply, Message):
            ctx.logger.info(f"Received awaited response from clyde: {reply.message}")
            await ctx.send(sender, Message(message="Clyde is doing alright!"))
        else:
            ctx.logger.info(f"Failed to receive response from clyde: {status}")
     
     
    @clyde.on_message(model=Message)
    async def handle_message(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
        await ctx.send(sender, Message(message="I'm doing alright!"))
     
     
    bureau = Bureau([alice, bob, clyde])
     
    if __name__ == "__main__":
        bureau.run()

### Expected output[](#expected-output)

Run the example script: `python main.py`

By running the above script, you should be able to see something similar within the terminal output:

    INFO:     [alice]: Starting agent with address: agent1qwmt0al3dd334n4f4rs3dw496n02cjackcxfg8l3vfl5m0pf7k5nqamf6rx
    INFO:     [  bob]: Starting agent with address: agent1qd7uqtycfr00xkhlpqatvkjdcgfrtf0xh93fncaqa8pf6upvn9jdjcuwzjh
    INFO:     [clyde]: Starting agent with address: agent1qvnf3qvc7y24gekpmtd8ar2lpskw8jnc5zzakgcjtku3u798e8lg2vugkgv
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [  bob]: Received message: Hey Bob, how's Clyde?
    INFO:     [clyde]: Received message from agent1qd7uqtycfr00xkhlpqatvkjdcgfrtf0xh93fncaqa8pf6upvn9jdjcuwzjh: How are you, Clyde?
    INFO:     [  bob]: Received awaited response from clyde: I'm doing alright!
    INFO:     [alice]: Received awaited response from bob: Clyde is doing alright!

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Using agents storage function docs</title>
  <url>https://uagents.fetch.ai/docs/guides/storage</url>
  <content>Introduction[](#introduction)
-----------------------------

Agents will need to store data for later use, uAgents has an inbuilt function to store data to json file, this is done with `ctx.storage`. Data is stored in `key:value` format. `ctx` object‚Äôs `storage` attribute has different function like `get` and `set` to use agent‚Äôs storage.

Overview[](#overview)
---------------------

We can store simple integers like :

    ctx.storage.set("Messages_sent", 1)

Or strings:

    ctx.storage.set("Passkey", "#-eiwfwrign")

Complex data can also be stored:

    Record1 = {"name":ctx.name, "address":ctx.address}
    ctx.storage.set("Record1", Record1)

We can access these values like so:

    ctx.logger.info(ctx.storage.get("Record1"))
    ctx.logger.info(ctx.storage.get("Messages_sent"))
    ctx.logger.info(ctx.storage.get("Passkey"))

Expected Output:

    INFO:     [Receiver]: {"name": "Receiver", "address": "agent1qdlcar9glcm6f9rpzway3xqaw4clfltxdhtwflxrjz3ahy98ep5dx7xy6x7"}
    INFO:     [Receiver]: 2
    INFO:     [Receiver]: "#-eiwfwrign"

Locally, this will be stored as a json file:

    {
    "Messages_sent" : 2,
    "Record1" : {"name" : "Receiver", "address" : "agent1qdlcar9glcm6f9rpzway3xqaw4clfltxdhtwflxrjz3ahy98ep5dx7xy6x7"},
    "Passkey" : "#-eiwfwrign"
    }

Generally, any object that is compatible with pydantic Models will be fine with uAgents.

Walk-through[](#walk-through)
-----------------------------

In this walk-through, we want to show how storage functions are called and how to use them. We want to create an agent which gets a value from the storage (starting from 0) every second. Then prints it, and puts the new value back into the storage but increased by 1 unit.

1.  To start let‚Äôs create a Python script and name it `storage.py`, we can do this in terminal with the following command:
    
2.  Then, we need to open the script in the text editor of choice and import the necessary classes, `Agent` and `Context`, from the `uagents` library.
    
3.  Let‚Äôs then create an agent named `alice` which logs a message every second using the `.on_interval()` decorator, indicating the current count. The `on_interval()` function takes a `Context` object as a parameter: the `Context` object contains a `storage` attribute, which is used to store and retrieve data between method calls:
    

     
    from uagents import Agent, Context
     
    alice = Agent(name="alice", seed="alice recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
     
    @alice.on_interval(period=1.0)
    async def on_interval(ctx: Context):
        current_count = ctx.storage.get("count") or 0
     
        ctx.logger.info(f"My count is: {current_count}")
     
        ctx.storage.set("count", current_count + 1)
     
    if __name__ == "__main__":
        alice.run()
     

Here, the `on_interval()` function retrieves the current count from the storage attribute using the `ctx.storage.get()` method. It prints the `current_count` value, and then increments it by `1`, and stores the updated count back to the storage attribute using the `ctx.storage.set()` method. The current count is then logged using the `ctx.logger.info()` method.

4.  Save the script.

Run the script[](#run-the-script)
---------------------------------

On your terminal, make sure you activated the virtual environment.

Run the script: `python storage.py`

The output should look as follows:

    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qww3ju3h6kfcuqf54gkghvt2pqe8qp97a7nzm2vp8plfxflc0epzcjsv79t
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)    
    INFO:     [alice]: My count is: 0
    INFO:     [alice]: My count is: 1
    INFO:     [alice]: My count is: 2
    INFO:     [alice]: My count is: 3
    ...</content>
</page>

<page>
  <title>Search with Agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/search</url>
  <content>Search by API[](#search-by-api)
-------------------------------

This article covers how to use the `uagents` library to search for agents based on user queries. It demonstrates how an AI-powered search agent processes the query and retrieves relevant agents, returning the results in a structured workflow.

Explanation of the `ai` Function[](#explanation-of-the-ai-function)
-------------------------------------------------------------------

The `ai` function is responsible for interacting with search API to retrieve search results. Here‚Äôs how it works:

    def ai(
        query: str,
        protocol: Optional[
            str
        ] = "proto:a03398ea81d7aaaf67e72940937676eae0d019f8e1d8b5efbadfef9fd2e98bb2",
    ) -> dict:
        url = "https://agentverse.ai/v1/search/agents"
        headers = {
            "Content-Type": "application/json",
        }
     
        data = {
            "search_text": query,
            "sort": "relevancy",
            "filters": {
                "protocol_digest": [protocol],
            },
            "direction": "asc",
            "offset": 0,
            "limit": 10,
        }
     
        try:
            response = httpx.post(url, json=data, headers=headers, timeout=10.0)
            return {"ais": response.json().get("agents", [])}
        except httpx.RequestError as exc:
            return {"ais": [], "error": f"{exc}"}

### Parameters[](#parameters)

*   `query`: A string representing the user‚Äôs search query.
*   `protocol` (optional): A string representing the protocol digest used to filter search results. Default is a sample protocol string.

### Implementation[](#implementation)

1.  API Endpoint and Headers:
    *   The function sends a POST request to `https://agentverse.ai/v1/search/agents`.
2.  Request Data:
    *   `search_text`: The user‚Äôs query.
    *   `filters`: Filters results based on the provided protocol digest.
    *   `direction`: Determines the order of results (ascending by default).
    *   `offset` and `limit`: Pagination parameters for the results.
3.  Error Handling:
    *   If the API call fails, the function catches the exception and returns an error message.

### Return Value[](#return-value)

The function returns a dictionary containing the search results or an error message if the request fails.

Agent Mechanism[](#agent-mechanism)
-----------------------------------

### Overview[](#overview)

Two agents, `query_agent` and `search_agent`, coordinate to handle user queries and responses.

### Workflow[](#workflow)

1.  Startup Event:
    *   `query_agent` sends the user-provided query to `search_agent` upon startup.
2.  Message Handling:
    *   `search_agent` receives the query, processes it using the `ai` function, and sends back the search results.
    *   `query_agent` receives and logs the response.

### Code Details[](#code-details)

#### Query Agent[](#query-agent)

*   Handles user input and initiates communication with the search agent.
*   Logs startup and response events.

#### Search Agent[](#search-agent)

*   Processes the query using the `ai` function.
*   Sends the results back to the `query_agent`.

     
    from uagents import Agent, Bureau, Context, Model
    from typing import Optional, Dict
    import httpx
     
    class Query(Model):
        message: str
     
    class Response(Model):
        response: Dict
     
    def ai(
        query: str,
        protocol: Optional[
            str
        ] = "proto:a03398ea81d7aaaf67e72940937676eae0d019f8e1d8b5efbadfef9fd2e98bb2",
    ) -> dict:
        url = "https://agentverse.ai/v1/search/agents"
        headers = {
            "Content-Type": "application/json",
        }
     
        data = {
            "search_text": query,
            "sort": "relevancy",
            "filters": {
                "protocol_digest": [protocol],
            },
            "direction": "asc",
            "offset": 0,
            "limit": 10,
        }
     
        try:
            response = httpx.post(url, json=data, headers=headers, timeout=10.0)
            return {"ais": response.json().get("agents", [])}
        except httpx.RequestError as exc:
            return {"ais": [], "error": f"{exc}"}
     
    query_agent = Agent(name="query_agent", seed="query_agent recovery phrase")
    search_agent = Agent(name="search_agent", seed="search_agent recovery phrase")
     
    user_query = input("Enter your query: ")
     
    @query_agent.on_event("startup")
    async def send_message(ctx: Context):
        ctx.logger.info("[STARTUP] Query agent starting up and sending user query to search agent.")
        await ctx.send(search_agent.address, Query(message=user_query))
     
    @search_agent.on_message(model=Query)
    async def search_message_handler(ctx: Context, sender: str, msg: Query):
        ctx.logger.info(f"[RECEIVED] Query received from {sender}. Message: '{msg.message}'")
        results = ai(msg.message)
        ctx.logger.info("[PROCESSING] Searching completed. Sending response back to the query agent.")
        await ctx.send(query_agent.address, Response(response=results))
     
    @query_agent.on_message(model=Response)
    async def response_message_handler(ctx: Context, sender: str, msg: Response):
        ctx.logger.info(f"[RECEIVED] Response received from search agent {sender}. Response: {msg.response}")
     
    bureau = Bureau()
    bureau.add(query_agent)
    bureau.add(search_agent)
     
    if __name__ == "__main__":
        bureau.run()
     

### Running the Example[](#running-the-example)

#### Setup the poetry environment[](#setup-the-poetry-environment)

1.  Create a Virtual Environment:
    
2.  Install Dependencies:
    

#### Run the example[](#run-the-example)

1.  Save the script as `search_agents.py`.
2.  Run the script:
3.  Enter a query when prompted.
4.  Observe the interaction in the logs as the query is processed and results are returned.

### Expected Output[](#expected-output)

    Enter your query: i want to buy a macbook
    INFO:     [query_agent]: Starting agent with address: agent1qdpstehd8x39n3jr0mas3adcy9d7rh4ss8wtw6euch0mq04tqu66kpfcu3q
    INFO:     [query_agent]: [STARTUP] Query agent starting up and sending user query to search agent.
    INFO:     [search_agent]: Starting agent with address: agent1qgj8y2mswcc4jm275tsnq948fa7aqe8d9v0jd78h0nx9ak6v3fnxj6m6pkj
    INFO:     [search_agent]: [RECEIVED] Query received from agent1qdpstehd8x39n3jr0mas3adcy9d7rh4ss8wtw6euch0mq04tqu66kpfcu3q. Message: 'i want to buy a macbook'
    INFO:httpx:HTTP Request: POST https://agentverse.ai/v1/search/agents "HTTP/1.1 200 OK"
    INFO:     [search_agent]: [PROCESSING] Searching completed. Sending response back to the query agent.
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [query_agent]: [RECEIVED] Response received from search agent agent1qgj8y2mswcc4jm275tsnq948fa7aqe8d9v0jd78h0nx9ak6v3fnxj6m6pkj. Response: {
        'ais': [
            {
                'address': 'agent1qwpd8cy9ymhjyuj4x2k75dv69vlxquk0xtwhmw09khv8jdkszw32y7rfd99',
                'name': 'tarot-agent',
                'readme': '\n        <description>My AI\'s description of capabilities and offerings</description>\n        <use_cases>\n            <use_case>My AI returns your Tarot reading</use_case>\n        </use_cases>\n        <payload_requirements>\n        <description>The requirements your AI has for requests</description>\n        <payload>\n            <requirement>\n                <parameter>Date of birth</parameter>\n                <description>I need your date of birth</description>\n            </requirement>\n             <requirement>\n                <parameter>gender</parameter>\n                <description>I need your gender</description>\n            </requirement>\n        </payload>\n        </payload_requirements>\n        ',
                'protocols': [
                    {
                        'name': '',
                        'version': '',
                        'digest': 'proto:a03398ea81d7aaaf67e72940937676eae0d019f8e1d8b5efbadfef9fd2e98bb2'
                    }
                ],
                'avatar_href': None,
                'total_interactions': 0,
                'recent_interactions': 0,
                'rating': None,
                'status': 'active',
                'type': 'local',
                'category': 'community',
                'featured': False,
                'geo_location': None,
                'last_updated': '2025-01-07T09:29:23Z',
                'created_at': '2024-12-09T16:18:18Z'
             },...more]
    }</content>
</page>

<page>
  <title>Broadcast docs</title>
  <url>https://uagents.fetch.ai/docs/guides/broadcast</url>
  <content>Introduction to `ctx.broadcast()`[](#introduction-to-ctxbroadcast)
------------------------------------------------------------------

The `ctx.broadcast()` function is used within an agent to send a message to all other agents that support a specific protocol. It is a powerful method when you want to communicate with multiple agents at once without knowing their addresses beforehand. This is especially useful in systems where many agents may be participating in the same protocol, and you want to notify or query all of them simultaneously.

Let‚Äôs get started!

Bureau Walk-through[](#bureau-walk-through)
-------------------------------------------

### Overview[](#overview)

In this guide, we will create a multi-agent broadcast system using the `uagents` library. Three agents will be initialized: Ethan, Olivia, and Liam. Ethan and Olivia will support a defined communication protocol, while Liam will broadcast a message to all agents supporting this protocol and handle their responses. We‚Äôll use `ctx.broadcast` to manage communication between agents and demonstrate the structure of message handling within the context of the `uagents` framework.

### Step 1: Import Classes and Initialize Agents[](#step-1-import-classes-and-initialize-agents)

    from uagents import Agent, Bureau, Context, Model, Protocol
     
    ethan = Agent(name="ethan", seed="ethan recovery phrase")
    olivia = Agent(name="olivia", seed="olivia recovery phrase")
    liam = Agent(name="liam", seed="liam recovery phrase")
     

In this step, we import the core classes needed to define agents, protocols, and message handling. We then initialize three agents: Ethan, Olivia, and Liam, each with unique seed phrases, ensuring fixed addresses for their identities.

### Step 2: Define Message Models[](#step-2-define-message-models)

    class BroadcastExampleRequest(Model):
        pass
     
    class BroadcastExampleResponse(Model):
        text: str
     

We define two message models:

*   `BroadcastExampleRequest`: This model represents a request message (empty for now).
*   `BroadcastExampleResponse`: This model holds a response message containing a text field.

### Step 3: Define a Communication Protocol[](#step-3-define-a-communication-protocol)

    proto = Protocol(name="proto", version="1.0")
     

A protocol named proto with version 1.0 is defined. This protocol will govern communication between agents that support it.

### Step 5: Message Handler for Broadcast Requests[](#step-5-message-handler-for-broadcast-requests)

     
    @proto.on_message(model=BroadcastExampleRequest, replies=BroadcastExampleResponse)
    async def handle_request(ctx: Context, sender: str, _msg: BroadcastExampleRequest):
        await ctx.send(
            sender, BroadcastExampleResponse(text=f"Hello from {ctx.agent.name}")
        )
     

This function handles incoming `BroadcastExampleRequest` messages. When an agent (e.g., Ethan or Olivia) receives a request, it replies with a `BroadcastExampleResponse`, sending a message containing its own name.

### Step 6: Include the Protocol in Agents[](#step-6-include-the-protocol-in-agents)

    ethan.include(proto)
    olivia.include(proto)
     

We include the protocol in Ethan and Olivia. This allows them to participate in communication governed by the `proto` protocol.

### Step 7: Liam‚Äôs Behavior - Broadcasting and Handling Responses[](#step-7-liams-behavior---broadcasting-and-handling-responses)

    @liam.on_interval(period=5)
    async def say_hello(ctx: Context):
        status_list = await ctx.broadcast(proto.digest, message=BroadcastExampleRequest())
        ctx.logger.info(f"Trying to contact {len(status_list)} agents.")
     

The `say_hello` function is executed by Liam every 5 seconds (using `on_interval`). Liam sends a `BroadcastExampleRequest` message to all agents supporting the `proto` protocol via `ctx.broadcast`. The `proto.digest` is used to identify the protocol.

    @liam.on_message(model=BroadcastExampleResponse)
    async def handle_response(ctx: Context, sender: str, msg: BroadcastExampleResponse):
        ctx.logger.info(f"Received response from {sender}: {msg.text}")
     

When Liam receives a BroadcastExampleResponse, the handle\_response function logs the sender and the content of the message.

### Step 8: Run the Bureau[](#step-8-run-the-bureau)

    bureau = Bureau(port=8000, endpoint="http://localhost:8000/submit")
    bureau.add(ethan)
    bureau.add(olivia)
    bureau.add(liam)
     
    if __name__ == "__main__":
        bureau.run()
     

Explanation of ctx.broadcast[](#explanation-of-ctxbroadcast)
------------------------------------------------------------

The broadcast() method in the Context class allows an agent to send a message to multiple agents that support a specific protocol. Here‚Äôs a detailed look at its usage:

`status_list = await ctx.broadcast(proto.digest, message=BroadcastExampleRequest())`

*   `proto.digest`: This is a unique identifier for the protocol that the message will be sent under. Only agents supporting this protocol will receive the broadcast.
*   `message`: The message being broadcast, in this case, a BroadcastExampleRequest.
*   `status_list`: This is a list of statuses returned by the broadcast, indicating which agents were successfully contacted.

By calling broadcast, Liam attempts to contact all agents supporting the proto protocol. This communication is asynchronous and can target multiple agents concurrently.

The overall script for this example should look as follows:

    from uagents import Agent, Bureau, Context, Model, Protocol
     
    ethan = Agent(name="ethan", seed="ethan recovery phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    olivia = Agent(name="olivia", seed="olivia recovery phrase", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
    liam = Agent(name="liam", seed="liam recovery phrase", port=8002, endpoint=["http://127.0.0.1:8002/submit"])
     
    class BroadcastExampleRequest(Model):
        pass
     
    class BroadcastExampleResponse(Model):
        text: str
     
    proto = Protocol(name="proto", version="1.0")
     
    @proto.on_message(model=BroadcastExampleRequest, replies=BroadcastExampleResponse)
    async def handle_request(ctx: Context, sender: str, _msg: BroadcastExampleRequest):
        await ctx.send(
            sender, BroadcastExampleResponse(text=f"Hello from {ctx.agent.name}")
        )
     
    ethan.include(proto)
    olivia.include(proto)
     
    @liam.on_interval(period=5)
    async def say_hello(ctx: Context):
        status_list = await ctx.broadcast(proto.digest, message=BroadcastExampleRequest())
        ctx.logger.info(f"Trying to contact {len(status_list)} agents.")
     
    @liam.on_message(model=BroadcastExampleResponse)
    async def handle_response(ctx: Context, sender: str, msg: BroadcastExampleResponse):
        ctx.logger.info(f"Received response from {sender}: {msg.text}")
     
    bureau = Bureau(port=8000, endpoint="http://localhost:8000/submit")
    bureau.add(ethan)
    bureau.add(olivia)
    bureau.add(liam)
     
    if __name__ == "__main__":
        bureau.run()
     

We are now ready to run the script: `python broadcast-agent.py`

The output would be:

    INFO:     [ethan]: Registration on Almanac API successful
    INFO:     [ethan]: Registering on almanac contract...
    INFO:     [ethan]: Registering on almanac contract...complete
    INFO:     [olivia]: Registration on Almanac API successful
    INFO:     [olivia]: Registering on almanac contract...
    INFO:     [olivia]: Registering on almanac contract...complete
    INFO:     [ liam]: Registration on Almanac API successful
    INFO:     [ liam]: Registering on almanac contract...
    INFO:     [ liam]: Registering on almanac contract...complete
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [ liam]: Trying to contact 2 agents.
    INFO:     [ liam]: Received response from agent1q2hdqe8hxa6g0awspktktgc5furywq5jur5q9whh9hzyffxsm9ka6c2dmhz: Hello from olivia
    INFO:     [ liam]: Received response from agent1qff9zl5cehj2z68zef7q68uw76jjslh2r8xda93avayedqajzjwwyce8pt9: Hello from ethan</content>
</page>

<page>
  <title>Options for running your Agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/run_local_agents</url>
  <content>Run a local Agent with an endpoint[](#run-a-local-agent-with-an-endpoint)
-------------------------------------------------------------------------

In some scenarios, you may want to run an agent on your own hardware or infrastructure; luckily this is very easy to do on any system that support Python 3.10.

This system is pretty simple, as to get you started as quickly as possible. We‚Äôre going to run this Agent on any device you‚Äôd like, in this scenario we‚Äôre running on a VM, but you could run this on your laptop, raspberry pi or tweak for Agentverse.

Imports needed[](#imports-needed)
---------------------------------

### The Agent[](#the-agent)

Consider the following Agent:

     
    from uagents import Agent, Context, Protocol, Model
    import random
    from uagents import Field
    import sys
     
    agent = Agent(
        name="dungeonsanddragonsdiceroll",
        port=6145,
        seed="RANDOM STRINGS",
        endpoint=["http://YOUR_IP:6145/submit"],
    )
     
     
    @agent.on_event("startup")
    async def hi(ctx: Context):
        ctx.logger.info(agent.address)
     
     
    class Request(Model):
        dice_sides: int = Field(description="How many sides does your dice need?")
     
    class Response(Model):
        text: str = Field(description="Text response for dice roll")
     
     
     
    dice_roll_protocol = Protocol("DungeonsAndDragonsDiceRoll")
     
     
    @dice_roll_protocol.on_message(model=Request, replies={Response})
    async def roll_dice(ctx: Context, sender: str, msg: Request):
        result = str(random.randint(1, msg.dice_sides))
        message = f"Dice roll result: {result}"
        await ctx.send(
            sender, Response(message=message)
        )
     
     
    agent.include(dice_roll_protocol, publish_manifest=True)
     
    agent.run()
     

To correctly run this code, you must provide the `name`, `seed`, `port`, and `endpoint` parameters. Ensure the Agent has sufficient funds to register with the Almanac contract.

The Agent must run on infrastructure that allows opening a `port`. In this example, we use port `6145` and an `endpoint`.

The Agent is initialized with an endpoint and a port to receive messages and allow other Agents to communicate with it. The `protocol`, defines the Request Model, with a single variable of `dice sides` with a type of `int`. The agent responds with the Response Model, which returns the response as a string.

The `on_message()` function processes incoming messages and returns a random number between 1 and the specified `dice_sides` from the message.

Finally, `.run()` starts the Agent.

We can now run our Agent with the following command: `python agent_endpoint.py`

**Expected output**:

    INFO:     [dungeonsanddragonsdiceroll]: Manifest published successfully: DungeonsAndDragonsDiceRoll
    INFO:     [dungeonsanddragonsdiceroll]: Registration on Almanac API successful
    INFO:     [dungeonsanddragonsdiceroll]: Registering on almanac contract...
    INFO:     [dungeonsanddragonsdiceroll]: Registering on almanac contract...complete
    INFO:     [dungeonsanddragonsdiceroll]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A6145&address=agent1qvwk0ntr38yyghccrg530hnnm88r5uske4hdcalsa7gqp7sjgx42k4mp62r
    INFO:     [dungeonsanddragonsdiceroll]: Starting server on http://0.0.0.0:6145 (Press CTRL+C to quit)

Running an Agent with Docker[](#running-an-agent-with-docker)
-------------------------------------------------------------

This example shows how to run an agent using the uAgents library inside a Docker container with Docker Compose. It walks you through setting up everything you need so you can easily build and run the agent.

Project Structure[](#project-structure)
---------------------------------------

    .agent_with_docker
    ‚îú‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ poetry.lock
    ‚îú‚îÄ‚îÄ pyproject.toml
    ‚îú‚îÄ‚îÄ README.md
    ‚îî‚îÄ‚îÄ src
        ‚îî‚îÄ‚îÄ agent.py

Agent with Docker[](#agent-with-docker)
---------------------------------------

### `agent.py`[](#agentpy)

This example demonstrates a simple agent-based communication system using the uAgents library. The `data_sender` agent sends a `DataPacket` message to the `data_receiver` agent every 4 seconds. Upon receiving the message, `data_receiver` logs it and sends an acknowledgment back to data\_sender. Both agents log the messages they receive. The agents are running with Docker Compose using Docker.

     
     
    from uagents import Agent, Bureau, Context, Model
     
     
    class DataPacket(Model):
        message: str
     
     
    data_sender = Agent(name="data_sender", seed="data_sender recovery phrase")
    data_receiver = Agent(name="data_receiver", seed="data_receiver recovery phrase")
     
     
    @data_sender.on_interval(period=4.0)
    async def send_data_packet(ctx: Context):
        """
        Event handler that gets triggered at regular intervals (every 4 seconds).
     
        Args:
        ctx (Context): The context in which the event is triggered.
     
        Returns:
        None: This function does not return any value but sends a DataPacket message from data_sender to data_receiver at intervals of (every 4 seconds).
        """
        await ctx.send(
            data_receiver.address, DataPacket(message="Initiating data transfer")
        )
     
     
    @data_sender.on_message(model=DataPacket)
    async def data_sender_message_handler(ctx: Context, sender: str, msg: DataPacket):
        """
        Event handler that gets triggered when data_sender receives a DataPacket message.
     
        Args:
        ctx (Context): The context in which the event is triggered.
        sender (str): The address of the sender.
        msg (DataPacket): The message received.
     
        Returns:
        None: This function does not return any value but logs the received message.
        """
        ctx.logger.info(f"Data Sender received a message from {sender}: {msg.message}")
     
     
    @data_receiver.on_message(model=DataPacket)
    async def data_receiver_message_handler(ctx: Context, sender: str, msg: DataPacket):
        """
        Event handler that gets triggered when data_receiver receives a DataPacket message.
     
        Args:
        ctx (Context): The context in which the event is triggered.
        sender (str): The address of the sender.
        msg (DataPacket): The message received.
     
        Returns:
        None: This function does not return any value but logs the received message and sends an acknowledgment back to data_sender.
        """
        ctx.logger.info(f"Data Receiver received a message from {sender}: {msg.message}")
        await ctx.send(
            data_sender.address, DataPacket(message="Acknowledging data transfer")
        )
     
     
    bureau = Bureau()
    bureau.add(data_sender)
    bureau.add(data_receiver)
     
    if __name__ == "__main__":
        bureau.run()
     

### Dockerfile[](#dockerfile)

This Dockerfile sets up a Python environment with Poetry for dependency management. It installs necessary system packages, sets up the working directory, installs dependencies specified in `pyproject.toml`, and runs `agent.py` using Poetry. The application listens on port 8000.

     
    FROM python:3.12-slim
    ENV PATH="$PATH:/root/.local/bin"
    RUN apt-get update && \
        apt-get install -y curl gcc && \
        curl -sSL https://install.python-poetry.org/ | python3 -
    WORKDIR /app
    ADD pyproject.toml poetry.lock /app/
    RUN poetry install
    ADD . /app
    EXPOSE 8000
    ENTRYPOINT ["poetry", "run"]
    CMD ["python", "agent.py"]
     

Poetry Dependencies[](#poetry-dependencies)
-------------------------------------------

    [tool.poetry.dependencies]
    python = "^3.10"
    uagents = { version = "^0.13.0", python = ">=3.10,<3.13" }

Run[](#run)
-----------

*   Navigate to the root Folder of the Example.
*   Run `docker build -t agent . && docker run -it agent`</content>
</page>

<page>
  <title>Dialogues docs</title>
  <url>https://uagents.fetch.ai/docs/guides/dialogues</url>
  <content>Overview[](#overview)
---------------------

Dialogues are structured and optimized way for agents to communicate. It provides an approach for agents to communicate with each other with consistent message pattern, allowing for multi-message sessions, state tracking, and parallel conversations.

Understanding Dialogues[](#understanding-dialogues)
---------------------------------------------------

Dialogues can be taken as super-powered Protocols, It provides more robust structure for communication between agents. Protocol define interaction patterns but lack state enforcement, leaving developers to manage all possible messaging cases. Dialogues address this by offering predefined patterns and clear state management.

Difference between Dialogues and Protocols[](#difference-between-dialogues-and-protocols)
-----------------------------------------------------------------------------------------

*   **Protocols :** Protocols provide full flexibility to interactions between agents. Developers are responsible for ensuring communication is working correctly by defining right data models and message handlers.
    
*   **Dialogues :** Dialogues add a more rigid structure to communication with enforced state transitions, multi-session state tracking and reusable complex communication patterns. Technically speaking, Dialogues are represented by a directed graph where nodes are the states and edges the messages (message handlers) of a well-defined communication flow.
    

Communication Patterns[](#communication-patterns)
-------------------------------------------------

Communication patterns in dialogues define a general graph-based structure for interactions. They describe every possible flow and branch in the communication process, providing a clear entry, transition and exit point. Patterns are message-agnostic and can be instantiated with various message models as specific Dialogues, adapting to different use cases while maintaining consistent principles.

Application and Core Developers[](#application-and-core-developers)
-------------------------------------------------------------------

The distinction between communication patterns and Dialogues supports two typical development scenarios with uagents:

*   **Application Developers:** Have clear business requirements and are looking to implement concrete use cases with agents as quickly and as easily as possible. They don‚Äôt want to waste time for creating the necessary building blocks or defining fundamental yet complex processes. Patterns help streamline their workflow, taking the burden of designing communication structures off them.
    
*   **Core Developers:** Improve the infrastructure for agent ecosystems by carefully defining and hardening relevant building blocks, needing full flexibility and power to lay the groundwork for application developers such as defining sound and complete communication patterns that can be reused for various use cases following the same principle.
    

How to use dialogues[](#how-to-use-dialogues)
---------------------------------------------

As explained above dialogues can be used by developers with different requirements. There are different ways in which dialogues can be used but before checking that lets understand what does `stateful communication` means in agent communication ecosystem.

### Stateful Communication[](#stateful-communication)

Dialogues support stateful communication which allows agents to access past messages and state status, perform parallel conversations/sessions and also it enforces the sequence of message exchanges. This overall structure and feature of dialogue helps maintain context, improves irrefutability and allows agents to resume conversation from any point of time.

There are different ways in which dialogues can be used as listed below:

### API for Dialogues[](#api-for-dialogues)

Some API keys exposed to application developers in dialogues include:

*   **start\_dialogue:** Initiates a dialogue, offering a more explicit way to start communication compared to protocols.
    
*   **get\_conversation:** Provides access to past messages, useful for handling complex scenarios and multiple parallel dialogues.
    
*   **reject\_session:** This is the transition for when the dialogue is rejected.
    

### Customization and Predefined Behaviors[](#customization-and-predefined-behaviors)

Dialogues allow for customization by adding or overwriting message handlers. Predefined behaviors make it easier for application developers to work with dialogues, handling standard interactions while enabling specific customization for unique use-cases.

#### Sample for creating message handler[](#sample-for-creating-message-handler)

##### Defining dialogue class[](#defining-dialogue-class)

    from uagents.experimental.dialogues import Dialogue, Edge, Node
     
    class ChitChatDialogueMessage(Model):
        text: str
     
    # Defining dialogues class
    class ChitChatDialogue(Dialogue):
        def __init__(self, version: str | None = None, agent_address: str | None = None) -> None:
            super().__init__(
                name="ChitChatDialogue",
                version=version,
                agent_address=agent_address,
                nodes=[ node1, node2, node3],
                edges=[ init_session, start_dialogue, cont_dialogue, end_session],
            )
     
        def on_continue_dialogue(self):
            return super()._on_state_transition(
                cont_dialogue.name,
                ChitChatDialogueMessage,
            )

##### Instantiate dialogues and defining continue dialogue handler[](#instantiate-dialogues-and-defining-continue-dialogue-handler)

    from dialogues.hardcoded_chitchat import (ChitChatDialogue,ChitChatDialogueMessage)
     
    # Instantiate the dialogues
    chitchat_dialogue = ChitChatDialogue(
        version="0.1",
        agent_address=<agent's address>,
    )
     
    @chitchat_dialogue.on_continue_dialogue()
    async def continue_chitchat(
        ctx: Context,
        sender: str,
        msg: ChitChatDialogueMessage,
    ):
        ctx.logger.info(f"Returning: {msg.text}")
        await ctx.send(sender, ChitChatDialogueMessage(text=msg.text))

Conclusions[](#conclusions)
---------------------------

This guide explains the purpose and key aspects of dialogues, drawing on developer comments and feedback. It discusses communication patterns, stateful communication, API highlights, and customization to guide both application and core developers.

‚ÑπÔ∏è

This guide is part of an experimental feature under heavy development. Backward compatibility is not guaranteed, and updates may cause breaking changes. Each update might introduce significant changes in behavior or functionality.</content>
</page>

<page>
  <title>Wallet messaging with Agents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/wallet_messaging</url>
  <content>This guide explains how to use the `uagents` library to enable wallet-to-wallet messaging between two Agents: `Alice` and `Bob`.

Walk-through[](#walk-through)
-----------------------------

We begin by importing needed packages and the by defining the Agents `Alice` and `Bob`, by defining a `name`, `seed` and `enable_wallet_messaging` parameters. Here, `enable_wallet_messaging=True` ensures the Agents can send and receive wallet messages.

    from uagents import Agent, Bureau, Context
    from uagents.wallet_messaging import WalletMessage
     
    # Define recovery phrases (seeds) for Alice and Bob
    ALICE_SEED = "alice dorado recovery phrase"
    BOB_SEED = "bob dorado recovery phrase"
     
    # Initialize agents with wallet messaging enabled
    alice = Agent(name="alice", seed=ALICE_SEED, enable_wallet_messaging=True)
    bob = Agent(name="bob", seed=BOB_SEED, enable_wallet_messaging=True)

We then go on and define the Agents‚Äô handlers. Alice listens for incoming wallet messages using the `.on_wallet_message()` handler. When she receives a message, it logs it and sends a reply back to the sender:

    @alice.on_wallet_message()
    async def reply(ctx: Context, msg: WalletMessage):
        ctx.logger.info(f"Got wallet message: {msg.text}")
        await ctx.send_wallet_message(msg.sender, "hey, thanks for the message")

Bob sends a message to Alice every 5 seconds using the `.on_interval()` handler. Also, Bob listens for incoming wallet messages, just like Alice. This ensures Bob can receive and log messages from other Agents:

    @bob.on_interval(period=5)
    async def send_message(ctx: Context):
        ctx.logger.info("Sending message...")
        await ctx.send_wallet_message(alice.address, "hello")
     
     
    @bob.on_wallet_message()
    async def wallet_reply(ctx: Context, msg: WalletMessage):
        ctx.logger.info(f"Got wallet message: {msg.text}")
     

Finally, both Alice and Bob are added to a Bureau, which runs the Agents concurrently:

    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
    bureau.run()
     

    from uagents import Agent, Bureau, Context
    from uagents.wallet_messaging import WalletMessage
     
    ALICE_SEED = "alice dorado recovery phrase"
    BOB_SEED = "bob dorado recovery phrase"
     
    alice = Agent(name="alice", seed=ALICE_SEED, enable_wallet_messaging=True)
    bob = Agent(name="bob", seed=BOB_SEED, enable_wallet_messaging=True)
     
     
    @alice.on_wallet_message()
    async def reply(ctx: Context, msg: WalletMessage):
        ctx.logger.info(f"Got wallet message: {msg.text}")
        await ctx.send_wallet_message(msg.sender, "hey, thanks for the message")
     
     
    @bob.on_interval(period=5)
    async def send_message(ctx: Context):
        ctx.logger.info("Sending message...")
        await ctx.send_wallet_message(alice.address, "hello")
     
     
    @bob.on_wallet_message()
    async def wallet_reply(ctx: Context, msg: WalletMessage):
        ctx.logger.info(f"Got wallet message: {msg.text}")
     
     
    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
    bureau.run()

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Agent Asynchronous Loops docs</title>
  <url>https://uagents.fetch.ai/docs/guides/async_loops</url>
  <content>Introduction[](#introduction)
-----------------------------

Agents need to communicate, perform tasks, and respond to events simultaneously and independently within any decentralized system. This guide shows how to create asynchronous agents that operate in parallel, enabling them to handle their own workflows while still interacting with other agents or external processes.

By using **asynchronous loops** and attaching agents to **external event loops**, you can build agents that manage tasks simultaneously, send periodic updates, and process incoming messages in real-time. This approach is particularly useful when working with distributed systems, where agents must collaborate or handle multiple simultaneous operations without interruptions.

Walk-through[](#walk-through)
-----------------------------

The following scripts show how to define agents, manage their life-cycle and attach them to external asynchronous loops.

### Script 1[](#script-1)

The first script depicts how to **attach an agent to an external event loop** and allow it to run _simultaneously_ with other asynchronous tasks.

First of all, let‚Äôs create a Python script:

    echo. > external_loop_attach.py

Now, paste the below code into it:

    import asyncio
    import contextlib
     
    from uagents import Agent, Bureau, Context
     
    loop = asyncio.get_event_loop()
     
    agent = Agent(
        name="looper",
        seed="<YOUR_SEED>",
        port=8001,
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    bureau = Bureau(
        agents=[agent],
    )
     
     
    @agent.on_event("startup")
    async def startup(ctx: Context):
        ctx.logger.info(">>> Looper is starting up.")
     
     
    @agent.on_event("shutdown")
    async def shutdown(ctx: Context):
        ctx.logger.info(">>> Looper is shutting down.")
     
     
    async def coro():
        while True:
            print("doing hard work...")
            await asyncio.sleep(1)
     
     
    if __name__ == "__main__":
        print("Attaching the agent or bureau to the external loop...")
        loop.create_task(coro())
     
        # > when attaching the agent to the external loop
        loop.create_task(agent.run_async())
     
        # > when attaching a bureau to the external loop
        # loop.create_task(bureau.run_async())
     
        with contextlib.suppress(KeyboardInterrupt):
            loop.run_forever()

This script demonstrates using an agent with an external event loop. We begin by importing the necessary libraries; we then proceed and instantiate an Agent named `looper` with a `seed` (`<YOUR_SEED>`). Then, we create a `bureau` to manage the Agent.

The `startup()` function, marked with the `.on_event("startup")` decorator, logs a message when the Agent starts, while the `shutdown()` function logs a message when the Agent shuts down.

A `coro()` function simulates a long-running task that prints `"Doing hard work..."` every second. This task runs independently, highlighting the Agent‚Äôs ability to handle multiple simultaneous tasks. Both the Agent and the external task (`coro`) are attached to the event loop using `loop.create_task()`, allowing them to execute simultaneously.

In the `__main__` block, a message indicates the process of attaching tasks to the event loop. The `loop.create_task(coro())` schedules the `coro` task, and `loop.create_task(agent.run_async())` schedules the Agent‚Äôs operations, enabling both to run without blocking other tasks.

Finally, a context manager suppresses `KeyboardInterrupt` exceptions (which are typically raised when the user presses `Ctrl+C` to stop the program) thus ensuring the program shuts down gracefully without errors or tracebacks.

### Script 2[](#script-2)

The goal of the second script is to create an agent that runs tasks inside an external event loop. The agent can execute certain actions (e.g., print messages or respond to events) while simultaneously performing a separate background task.

Let‚Äôs start by creating a Python script:

    echo. > external_loop_run.py

Then, let‚Äôs paste the below code into it:

    import asyncio
     
    from uagents import Agent, Bureau, Context
     
    loop = asyncio.get_event_loop()
     
    agent = Agent(
        name="looper",
        seed="<YOUR_SEED>",
        loop=loop,
        port = 8000,
        endpoint = ["http://127.0.0.1:8000/submit"],
    )
     
    bureau = Bureau(
        agents=[agent],
        loop=loop,
    )
     
     
    @agent.on_event("startup")
    async def startup(ctx: Context):
        ctx.logger.info(">>> Looper is starting up.")
     
     
    @agent.on_event("shutdown")
    async def shutdown(ctx: Context):
        ctx.logger.info(">>> Looper is shutting down.")
     
     
    async def coro():
        while True:
            print("doing hard work...")
            await asyncio.sleep(1)
     
     
    if __name__ == "__main__":
        print("Starting the external loop from the agent or bureau...")
        loop.create_task(coro())
     
        # > when starting the external loop from the agent
        agent.run()
     
        # > when starting the external loop from the bureau
        # bureau.run()

We start by importing the required libraries to correctly run this script. We then create an asynchronous event loop using `asyncio.get_event_loop()`. This loop is used to handle all asynchronous operations, such as the agent‚Äôs actions and background tasks.

We proceed and create an agent called `looper` using the `Agent` class. The agent takes three parameters: `name`, `seed`, and `loop`. Remember to provide a `seed` for your agent otherwise a random address will be generated every time you run the agent. We then create a `bureau` object using the `Bureau` class. The `bureau` is created with a single agent, `looper`.

We can then define our agent functions to handle the agent‚Äôs lifecycle events:

1.  `startup()`: This function runs when the agent is started. It logs a message to indicate that the agent has been started up.
2.  `shutdown()`: This function runs when the agent is shut down. It logs a message to indicate that the agent has been stopped.

In the next step, we define the `coro()` function; As before, this function defines an infinite loop where the agent performs a task (`"doing hard work..."`) every second. This simulates a long-running background task. The `await asyncio.sleep(1)` pauses execution for one second between each iteration, allowing other tasks to run during that time.

Finally, in the `__main__` block, we define a message to be printed indicating that the external event loop is being started. The `loop.create_task(coro())` schedules the `coro()` coroutine to run in the background, simultaneously with the agent‚Äôs operations.

Expected Output[](#expected-output)
-----------------------------------

We are now ready to run the scripts.

The output should be similar to the following:

*   Script 1:
    
        Attaching the agent or bureau to the external loop...
        
    
*   Script 2:
    
        Starting the external loop from the agent or bureau...
        INFO:     [looper]: >>> Looper is starting up.
        INFO:     [looper]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qwep424538eh7fcruqcnx8la3q3tgl4tgksrcdtahqs7dqgs4rewsx4jefu
        INFO:     [looper]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
        doing hard work...
        doing hard work...
        doing hard work...
        doing hard work...
        doing hard work...</content>
</page>

<page>
  <title>Local Wallet docs</title>
  <url>https://uagents.fetch.ai/docs/guides/localwallet</url>
  <content>Overview[](#overview)
---------------------

To transact with fet on the Fetch.ai ledger, you will need to manage your wallet with you agent. We use the Cosmpy library for ledger actions, coupled with in library support for Cosmpy in uAgents.

Imports needed[](#imports-needed)
---------------------------------

Understanding your wallet[](#understanding-your-wallet)
-------------------------------------------------------

Wallets allow individuals to manage, store and transact across blockchain networks. Wallets are composed of a public and private key pair. The private key is a unique and secret cryptographic code that provides ownership and control over the wallet and allows individuals to authorize transactions signing. The public address is a cryptographic identifier that allows individuals to receive and view transactions.

Changes to the state of a network are achieved by broadcasting transactions. To accomplish this, we can use CosmPy in a straightforward way to create and manage private keys and addresses. In this guide, you will learn how to both generate a new private key and recover a previously generated one.

The examples below outlines how to achieve both of these operations.

Generating a new private key[](#generating-a-new-private-key)
-------------------------------------------------------------

First of all, import the needed modules and then use the PrivateKey class to create your `private_key`:

    # Import necessary classes
    from cosmpy.aerial.wallet import LocalWallet
    from cosmpy.crypto.keypairs import PrivateKey
     
    # Creating a random private key
    private_key = PrivateKey()

Recover an existing private key[](#recover-an-existing-private-key)
-------------------------------------------------------------------

Let‚Äôs start by extracting the private key and convert it into a base64 encoded string. You can do this on macOS or Linux for the Fetch.ai network using the FetchD CL.

An example is provided in the code snippet below:

    # Extract the private key and convert it into a base64 encoded string
    fetchd keys export mykeyname --unsafe --unarmored-hex | xxd -r -p | base64

Once you have extracted and converted the key into a base64 encoded string you can recover to an existing private key by following along the provided example below:

    # Import necessary classes
    from cosmpy.aerial.wallet import LocalWallet
    from cosmpy.crypto.keypairs import PrivateKey
     
    # Recovering an existing private key
    private_key = PrivateKey('<base64 encoded private key>') # Here is where you provide the base64 encoded private key string

The `PrivateKey` object is one of CosmPy‚Äôs low level primitives. This is why it is generally paired with a `Wallet` object. You can now create a local wallet using the `LocalWallet` class from the CosmPy library and initialize it with the `private_key` you generated or recovered earlier. The `LocalWallet` class is used to manage a local wallet associated with a private key for interacting with the Cosmos blockchain.

With this wallet object, you can perform various operations, such as generating the corresponding public address associated with the private key and signing transactions. You can also query useful information such as the address from the wallet directly. The example below showcases how to achieve both of these outlined operations:

    wallet = LocalWallet(private_key)
    print(wallet.address()) # will print the address for the wallet

From mnemonic[](#from-mnemonic)
-------------------------------

You can also use an account‚Äôs mnemonic phrase to get the associated private key. The example provided below showcases how to achieve that:

    from cosmpy.aerial.wallet import LocalWallet
     
    mnemonic = "person knife december tail tortoise jewel warm when worry limit reward memory piece cool sphere kitchen knee embody soft own victory sauce silly page"
     
    wallet = LocalWallet.from_mnemonic(mnemonic)

An Agent that checks for a transaction, and sends funds[](#an-agent-that-checks-for-a-transaction-and-sends-funds)
------------------------------------------------------------------------------------------------------------------

A simple agent that creates, or loads in a wallet, then validates a transaction has been received.

     
    from cosmpy.aerial.wallet import LocalWallet
    from cosmpy.aerial.client import LedgerClient, NetworkConfig
    from cosmpy.crypto.keypairs import PrivateKey
    from uagents import Agent, Context, Model
    from uagents.network import get_faucet, wait_for_tx_to_complete
     
    mainnet_ledger = LedgerClient(NetworkConfig.fetchai_mainnet())
     
     
    class RequestWithTX(Model):
        message: str
        tx_hash: str
     
     
    class DataResponse(Model):
        message: str
     
     
    class PaymentError(Model):
        message: str
        tx_hash: str
     
     
    DataSellingAgent = Agent(
        name="DataSellingAgent",
        seed="dwefwegferdwdwedgko4o430490349jf340-jffjweiopfnw",
        port=8001,
        endpoint=["http://localhost:8001/submit"],
    )
     
    print(DataSellingAgent.address)
     
    AMOUNT = 1
    DENOM = "afet"
    DATA_TO_SELL = "..."
     
    ## at first you may want to generate a wallet
    my_wallet = LocalWallet.generate()
    ## or open one from a seed you've set
    # my_wallet = LocalWallet.from_unsafe_seed("registration test wallet")
    # pk = my_wallet._private_key
    ## or from a pk you already have
    # wallet = LocalWallet(PrivateKey("T7w1yHq1QIcQiSqV27YSwk+i1i+Y4JMKhkpawCQIh6s="))
     
    ...
     
     
    @DataSellingAgent.on_message(model=RequestWithTX)
    async def message_handler(ctx: Context, sender: str, msg: RequestWithTX):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        mainnet_ledger.query_tx(msg.tx_hash)
        tx_resp = await wait_for_tx_to_complete(msg.tx_hash, mainnet_ledger)
     
        coin_received = tx_resp.events["coin_received"]
        if (
                coin_received["receiver"] == str(my_wallet.address)
                and coin_received["amount"] == f"{AMOUNT}{DENOM}"
        ):
            ctx.logger.info(f"Transaction was successful: {coin_received}")
            await ctx.send(sender, DataResponse(message=DATA_TO_SELL))
     
        else:
            await ctx.send(sender, PaymentError(message="Incorrect tx", tx_hash=msg.tx_hash))
     
     
    if __name__ == "__main__":
        DataSellingAgent.run()
     

The output for the above would be:

    agent1qtqdeme8s6fu2zdwdw72eacpxms3jg8dxctc7v4gvw0hlmlahayw5mqmt68
    INFO:     [DataSellingAgent]: Registration on Almanac API successful
    INFO:     [DataSellingAgent]: Registering on almanac contract...
    INFO:     [DataSellingAgent]: Registering on almanac contract...complete
    INFO:     [DataSellingAgent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qtqdeme8s6fu2zdwdw72eacpxms3jg8dxctc7v4gvw0hlmlahayw5mqmt68
    INFO:     [DataSellingAgent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)

Validating a transaction with Cosmpy and uAgents is really easy, and to test the above agent you just need to replicate the `Models` and send a `RequestWithTX` in any function in another agent:

    @DataBuyingAgent.on_event("startup")
    async def introduce_agent(ctx: Context):
        ctx.logger.info("Starting DataBuyingAgent...")
        await ctx.send(agent_address, RequestWithTX(message="buy",  tx_hash="D165966A6B9269EHHHHH7C8F659F1CDA871C8CD83F9102DD35A437211F3DE0CF"))</content>
</page>

<page>
  <title>How to use agents to verify messages docs</title>
  <url>https://uagents.fetch.ai/docs/guides/msg_verification</url>
  <content>Introduction[](#introduction)
-----------------------------

The emergence of decentralized technologies has introduced new possibilities for secure communication and data exchange. In this guide, we will delve into the process of setting up a scenario where two Agents communicate with each other, employing cryptographic methods to verify the messages exchanged between them. We will showcase how to create a secure messaging environment using Agents, where messages are not only exchanged but also signed and verified to prevent unauthorized access and tampering.

Imports needed[](#imports-needed)
---------------------------------

Walk-through[](#walk-through)
-----------------------------

1.  First of all, you need to navigate towards the directory you created for your project.
    
2.  In here, let‚Äôs create a Python script for this task and name it:
    
        echo. > message_verification.py
    
3.  We now need to import the necessary classes from `uagents` (`Agent`, `Bureau`, `Context`, and `Model`), `uagents.crypto` (`Identity`) and `hashlib`. Then we would need to define the messages format using the `Message` class as a subclass of `Model`:
    

     
    import hashlib
    from uagents import Agent, Bureau, Context, Model
    from uagents.crypto import Identity
     
     
    class Message(Model):
        message: str
        digest: str
        signature: str

The message format has three attributes:

*   `message`: a string representing the message text.
*   `digest`: a string representing the SHA-256 hash of the message.
*   `signature`: a string representing the digital signature of the hash using the sender‚Äôs private key.

4.  Let‚Äôs now define an `encode()` function used to generate the digest for each message before it is signed:

     
    def encode(message: str) -> bytes:
        hasher = hashlib.sha256()
        hasher.update(message.encode())
        return hasher.digest()
     

This function is used to hash a string message using the SHA-256 algorithm and return the resulting digest as bytes.

5.  We can now proceed and create our agents using the `Agent` class:

     
    alice = Agent(name="alice", seed="alice recovery password", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob recovery password", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
     

6.  Let‚Äôs now define a `send_message()` function for `alice` to send messages to `bob`:

     
    @alice.on_interval(period=3.0)
    async def send_message(ctx: Context):
        msg = "hello there bob"
        digest = encode(msg)
     
        await ctx.send(
            bob.address,
            Message(message=msg, digest=digest.hex(), signature=alice.sign_digest(digest)),
        )
     

This function is decorated using the `.on_interval()` decorator, which indicates that the function is called periodically every `3.0` seconds to send messages to `bob`‚Äôs address. It takes in a single argument `ctx`. The function first creates a message, `msg`, and computes its digest using the `encode` function. The message is then sent to `bob` using the `ctx.send()` method, along with the `digest` and a `signature` of the digest using the `alice.sign_digest()` function.

7.  Let‚Äôs then define an `alice_rx_message()` function used to receive and process messages sent by `bob`:

     
    @alice.on_message(model=Message)
    async def alice_rx_message(ctx: Context, sender: str, msg: Message):
        assert Identity.verify_digest(
            sender, bytes.fromhex(msg.digest), msg.signature
        ), "couldn't verify bob's message"
     
        ctx.logger.info("Bob's message verified!")
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     

This function is decorated using the `.on_message()`, indicating that the function is triggered when a message is being received of type `Message`. The function takes in three arguments: `ctx`, `sender`, and `msg`.

The function first verifies the authenticity of the message using the `Identity.verify_digest()` function. If the message cannot be verified, the function raises an assertion error. Assuming the message is verified, the function logs a message indicating that the message was verified and another message indicating the contents of the message.

8.  We can now define a `bob_rx_message()` function used by `bob` to receive and process messages sent by `alice`:

     
    @bob.on_message(model=Message)
    async def bob_rx_message(ctx: Context, sender: str, msg: Message):
        assert Identity.verify_digest(
            sender, bytes.fromhex(msg.digest), msg.signature
        ), "couldn't verify alice's message"
     
        ctx.logger.info("Alice's message verified!")
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        msg = "hello there alice"
        digest = encode(msg)
     
        await ctx.send(
            alice.address,
            Message(message=msg, digest=digest.hex(), signature=bob.sign_digest(digest)),
        )
     

This function is decorated using the `.on_message()` decorator, indicating that the function is triggered when a message is being received of type `Message`. It takes in three arguments: `ctx`, `sender`, and `msg`.

The function first verifies the authenticity of the message using the `Identity.verify_digest()` function. If the message cannot be verified, the function raises an assertion error. On the other hand, if the message is verified, the function logs a message indicating that the message was verified and another message indicating the contents of the message using the `ctx.logger.info()` method. It then creates a response message, `msg`, and computes its digest using the `encode()` function. The response message is then sent to `alice` using the `ctx.send()` method.

9.  We can now create a `bureau` object from the `Bureau` class and then add both agents to it so for them to be run together.

     
    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
     
    if __name__ == "__main__":
        bureau.run()
     

10.  Save the script.

The overall script should look as follows:

     
    import hashlib
    from uagents import Agent, Bureau, Context, Model
    from uagents.crypto import Identity
     
     
    class Message(Model):
        message: str
        digest: str
        signature: str
     
     
    def encode(message: str) -> bytes:
        hasher = hashlib.sha256()
        hasher.update(message.encode())
        return hasher.digest()
     
     
    alice = Agent(name="alice", seed="alice recovery password", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob recovery password", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
     
     
    @alice.on_interval(period=3.0)
    async def send_message(ctx: Context):
        msg = "hello there bob"
        digest = encode(msg)
     
        await ctx.send(
            bob.address,
            Message(message=msg, digest=digest.hex(), signature=alice.sign_digest(digest)),
        )
     
     
    @alice.on_message(model=Message)
    async def alice_rx_message(ctx: Context, sender: str, msg: Message):
        assert Identity.verify_digest(
            sender, bytes.fromhex(msg.digest), msg.signature
        ), "couldn't verify bob's message"
     
        ctx.logger.info("Bob's message verified!")
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
     
    @bob.on_message(model=Message)
    async def bob_rx_message(ctx: Context, sender: str, msg: Message):
        assert Identity.verify_digest(
            sender, bytes.fromhex(msg.digest), msg.signature
        ), "couldn't verify alice's message"
     
        ctx.logger.info("Alice's message verified!")
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        msg = "hello there alice"
        digest = encode(msg)
     
        await ctx.send(
            alice.address,
            Message(message=msg, digest=digest.hex(), signature=bob.sign_digest(digest)),
        )
     
     
    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
     
    if __name__ == "__main__":
        bureau.run()
     

Run your script[](#run-your-script)
-----------------------------------

On your terminal, make sure to have activated your virtual environment.

Run the script: `python message_verification.py`.

The output should be as follows:

    WARNING:  [alice]: No endpoints provided. Skipping registration: Agent won't be reachable.
    WARNING:  [  bob]: No endpoints provided. Skipping registration: Agent won't be reachable.
    [  bob]: Alice's message verified!
    [  bob]: Received message from agent1qf5gfqm48k9acegez3sg82ney2aa6l5fvpwh3n3z0ajh0nam3ssgwnn5me7: hello there bob
    [alice]: Bob's message verified!
    [alice]: Received message from agent1qvjjle8dlf22ff7zsh6wr3gl8tdepzygftdxpc2vn8539ngt962a709c90s: hello there alice</content>
</page>

<page>
  <title>How to add custom REST endpoints to your Agent docs</title>
  <url>https://uagents.fetch.ai/docs/guides/rest_endpoints</url>
  <content>Introduction[](#introduction)
-----------------------------

uAgents now support custom REST endpoints using the `on_rest_get()` and `on_rest_post()` decorators, enabling them to handle HTTP GET and POST requests directly. With this addition, agents can define specific routes, create request and response models, and interact seamlessly with REST clients. This feature enhances the flexibility of agents, allowing them to communicate with external systems using standard web protocols while ensuring that all responses conform to predefined models. **Please note that this feature is only available at the ‚Äòagent level‚Äô, meaning that you cannot add REST endpoints to uAgents `protocols`!**

The usage is similar to a message handler in that you define:

*   A custom endpoint in string format, e.g. `"/my_rest_endpoint"`;
*   A Request Model (inheriting from `uagents.models`) for `POST` endpoints;
*   A Response Model for `GET` endpoints.

The difference to a message handler is that you actually have to invoke `return` for the value to be returned to the REST client. The format can either be `Dict[str, Any]` or the `Model` itself but either way the output will be validated against the predefined response model.

Usage[](#usage)
---------------

To use the new REST API feature in your agent, follow these steps to define custom `GET` and `POST` routes, run the Agent, and query the endpoints.

For querying the Agent you have to make sure that:

*   You use the correct REST method (‚ÄúGET‚Äù or ‚ÄúPOST‚Äù).
*   You address the Agent endpoint together with its route e.g `http://localhost:8000/custom_route`.

### Define Custom GET and POST Routes[](#define-custom-get-and-post-routes)

#### GET request example[](#get-request-example)

Use the `@on_rest_get()` decorator to define a custom GET endpoint. You will need to specify the endpoint route and the response model.

    @agent.on_rest_get("/custom_get_route", Response)
    async def handle_get(ctx: Context) -> Dict[str, Any]:
        return {
            "field": <value>,
        }
     

#### POST request example[](#post-request-example)

Use the `@on_rest_post()` decorator to define a custom POST endpoint. You need to provide both a request model (for input) and a response model (for output).

    @agent.on_rest_post("/custom_post_route", Request, Response)
    async def handle_post(ctx: Context, req: Request) -> Response:
        ctx.logger.info(req)
        return Response(...)

### Example of custom GET and POST Routes[](#example-of-custom-get-and-post-routes)

     
    import time
    from typing import Any, Dict
     
    from uagents import Agent, Context, Model
     
    class Request(Model):
        text: str
     
    class Response(Model):
        timestamp: int
        text: str
        agent_address: str
     
    # You can also use empty models to represent empty request/response bodies
    class EmptyMessage(Model):
        pass
     
    agent = Agent(name="Rest API", seed="your_seed_phrase", port=8000, endpoint=["http://localhost:8000/submit"])
     
    @agent.on_rest_get("/rest/get", Response)
    async def handle_get(ctx: Context) -> Dict[str, Any]:
        ctx.logger.info("Received GET request")
        return {
            "timestamp": int(time.time()),
            "text": "Hello from the GET handler!",
            "agent_address": ctx.agent.address,
        }
     
    @agent.on_rest_post("/rest/post", Request, Response)
    async def handle_post(ctx: Context, req: Request) -> Response:
        ctx.logger.info("Received POST request")
        return Response(
            text=f"Received: {req.text}",
            agent_address=ctx.agent.address,
            timestamp=int(time.time()),
        )
     
    if __name__ == "__main__":
        agent.run()
     

Run the example[](#run-the-example)
-----------------------------------

1.  Run the agent: `python agent.py`
    
2.  Query the agent directly through your predefined interfaces:
    
        curl -d '{"text": "test"}' -H "Content-Type: application/json" -X POST http://localhost:8000/rest/post
    

### Expected output[](#expected-output)

*   Curl Response:
    
        {"timestamp": 1725610956, "text": "Received: test", "agent_address": "agent1q2qavahvzm2yw237g2cq40pe8p590ppysclaffp2dd0gtk9evtxag7c8djd"}
    
*   Agent Logs:
    
        WARNING:  [Rest API]: No endpoints provided. Skipping registration: Agent won't be reachable.
        INFO:     [Rest API]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
        INFO:     [Rest API]: Received POST request
    

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Agents Name Service docs</title>
  <url>https://uagents.fetch.ai/docs/guides/name_service</url>
  <content>Introduction[](#introduction)
-----------------------------

This file can be run on any platform supporting Python, with the necessary install permissions. This example shows how to set up the Agents Name Service contract using the `uagents` and `cosmpy` Python libraries. The **Fetch.ai Name Service Smart Contract** aims at enhancing the usability and accessibility of the Fetch.ai blockchain by providing a decentralized, secure, and user-friendly way to manage names for various digital entities. Indeed, the Name Service Smart Contract acts similarly to a phonebook for the Fetch.ai blockchain; It assigns memorable names (i.e., domains) to blockchain addresses, making it easier to find and interact with other agents and resources on the network. Imagine it as a way to give user-friendly names to complex wallet addresses.

In this guide we set up a communication line between two agents, Alice and Bob, where Alice sends a message to Bob every 5 seconds by first constructing Bob‚Äôs address using a predefined domain (example.agent) and Bob‚Äôs name (bob-0).

In turn, Bob is coded to listen for incoming messages and log them. On startup, Bob registers its name on a blockchain network using a name service contract. This ensures that Alice can address messages to Bob correctly.

**Let‚Äôs get started!**

Walk-through[](#walk-through)
-----------------------------

First of all, we need to create 2 Python scripts for our two agents using the following commands within your terminal:

Bob:

Alice:

### Bob[](#bob)

Let‚Äôs start with the first agent of this example, Bob.

1.  First of all, we import the required libraries and modules:

     
    from cosmpy.aerial.wallet import LocalWallet
    from uagents import Agent, Context, Model
    from uagents.network import get_faucet, get_name_service_contract
     

*   `LocalWallet`: From the `cosmpy.aerial.wallet` module, this is used to create and manage wallets for blockchain interactions.
*   `Agent`, `Context`, `Model`: From the `uagents` module, these are used to define the agent, its context, and the message model.
*   `get_faucet`: From the `uagents.network` module, this function is used to get a faucet for funding wallets.
*   `get_name_service_contract`: From the `uagents.network` module, this function is used to get the contract for registering agent names on the network.

2.  We then define the Message model defining the structure of messages that Bob will be able to handle:

     
    class Message(Model):
        message: str
     

We have defined a `Message` data model which contains a single attribute `message` of type string.

3.  We then need to initialize the agent:

     
    bob = Agent(
        name="bob-0",
        seed="agent bob-0 secret phrase",
        port=8001,
        endpoint=["http://localhost:8001/submit"],
    )
     

We have created an agent named `bob-0` with a specified `seed`. The agent listens on port `8001` and has an `endpoint` for receiving messages.

4.  We are now ready to set up the **Wallet**, **Name Service Contract**, and **Faucet**:

     
    my_wallet = LocalWallet.from_unsafe_seed("registration test wallet")
    name_service_contract = get_name_service_contract(test=True)
    faucet = get_faucet()
     
    DOMAIN = "example.agent"
     
    faucet.get_wealth(my_wallet.address())
     

We first create a wallet from a seed phrase and this wallet is used for interacting with the Fetch.ai blockchain. We then proceed and define the Name Service Contract. It retrieves the name service contract to register the agent‚Äôs name on the blockchain. The `test=True` parameter indicates this is a `test` setup. Then, we define the faucet used to fund the wallet with test tokens. We then define the domain for the agent‚Äôs name registration and finally proceed to request funds from the faucet to ensure the agent‚Äôs wallet has sufficient funds to operate. Remember that you need to provide the `name`, `seed`, `port`, `endpoint` and `DOMAIN` parameters to correctly run this code!

5.  We continue and define Bob‚Äôs functions. We start with a register\_agent\_name function which registers Bob‚Äôs name within the blockchain using the agent‚Äôs wallet, address, name and domain parameters:

     
    @bob.on_event("startup")
    async def register_agent_name(ctx: Context):
        await name_service_contract.register(
            bob.ledger, my_wallet, bob.address, bob.name, DOMAIN
        )
     

Here, we defined the `register_agent_name` function. It registers the agent‚Äôs name on the blockchain when the agent is initialized. The function uses the name service contract to register `bob-0.example.agent` agent using the `my_wallet` wallet. **It is important that you provide only lower case letters for your agent‚Äôs `name` and `DOMAIN` parameters as otherwise you will face issues the moment you run your agent**.

6.  We now define a `message_handler` function for Bob to handle incoming messages:

     
    @bob.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
     
    if __name__ == "__main__":
        bob.run()
     

Here we defined a function handling incoming messages of type `Message`. It logs the sender‚Äôs address and the message content.

7.  Finally, we save and run the script.

The overall script for this example should look as follows:

     
    from cosmpy.aerial.wallet import LocalWallet
    from uagents import Agent, Context, Model
    from uagents.network import get_faucet, get_name_service_contract
     
     
    # NOTE: Run sender_agent.py before running receiver_agent.py
     
     
    class Message(Model):
        message: str
     
     
    bob = Agent(
        name="bob-0",
        seed="agent bob-0 secret phrase",
        port=8001,
        endpoint=["http://localhost:8001/submit"],
    )
     
    my_wallet = LocalWallet.from_unsafe_seed("registration test wallet")
    name_service_contract = get_name_service_contract(test=True)
    faucet = get_faucet()
     
    DOMAIN = "example.agent"
     
    faucet.get_wealth(my_wallet.address())
     
     
    @bob.on_event("startup")
    async def register_agent_name(ctx: Context):
        await name_service_contract.register(
            bob.ledger, my_wallet, bob.address, bob.name, DOMAIN
        )
     
     
    @bob.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
     
    if __name__ == "__main__":
        bob.run()
     

### Alice[](#alice)

Let‚Äôs now define the code for our second agent, Alice.

1.  First of all, we import the required libraries and modules:

     
    from uagents import Agent, Context, Model
     

2.  Let‚Äôs then define the message data model similarly to what we did for Bob:

     
    class Message(Model):
        message: str
     

3.  We proceed and initialize the agent:

     
    alice = Agent(
        name="alice-0",
        seed="agent alice-0 secret phrase",
        port=8000,
        endpoint=["http://localhost:8000/submit"],
    )
     

We initialize an agent named `alice-0` with a specified `seed`. The agent listens on port `8000` and has an `endpoint` for submitting messages.

4.  We then need to define the domain of the agent. The `DOMAIN` specifies the domain for the agent communication. This domain is used to construct the full address of Bob:

     
        message: str
     
     
    alice = Agent(
        name="alice-0",
        seed="agent alice-0 secret phrase",
        port=8000,
        endpoint=["http://localhost:8000/submit"],
    )
     
    DOMAIN = "example.agent"
     

5.  Finally, we define the functions and behaviors for Alice:

     
    @alice.on_interval(period=5)
    async def alice_interval_handler(ctx: Context):
        bob_name = "bob-0" + "." + DOMAIN
        ctx.logger.info(f"Sending message to {bob_name}...")
        await ctx.send(bob_name, Message(message="Hello there bob."))
     
     
    if __name__ == "__main__":
        alice.run()
     

This `alice_interval_handler()` function runs at regular intervals of 5 seconds to send messages. The handler constructs Bob‚Äôs address using the domain and sends a message to Bob. It combines `bob-0` name with the `DOMAIN` to form `bob-0.example.agent`. The agent logs the action and sends a message with the content ‚ÄúHello there bob.‚Äù to Bob agent.

Remember that you need to provide the `name`, `seed`, `port`, `endpoint` and `DOMAIN` parameters to correctly run this code! **Additionally, it is important that you provide only lower case letters for your agent‚Äôs `name` and `DOMAIN` parameters as otherwise you will face issues the moment you run your agent**.

The overall script for this example should look as follows:

     
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    alice = Agent(
        name="alice-0",
        seed="agent alice-0 secret phrase",
        port=8000,
        endpoint=["http://localhost:8000/submit"],
    )
     
    DOMAIN = "example.agent"
     
     
    @alice.on_interval(period=5)
    async def alice_interval_handler(ctx: Context):
        bob_name = "bob-0" + "." + DOMAIN
        ctx.logger.info(f"Sending message to {bob_name}...")
        await ctx.send(bob_name, Message(message="Hello there bob."))
     
     
    if __name__ == "__main__":
        alice.run()
     

### Expected output[](#expected-output)

Within your terminal windows you should see something similar to the following:

1.  **Bob**:
    
        INFO:     [bob-0]: Registration on Almanac API successful
        INFO:     [bob-0]: Registering on almanac contract...
        INFO:     [bob-0]: Registering on almanac contract...complete
        INFO:     [network]: Registering name...
        INFO:     [network]: Registering name...complete
        INFO:     [bob-0]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qwep424538eh7fcruqcnx8la3q3tgl4tgksrcdtahqs7dqgs4rewsx4jefu
        INFO:     [bob-0]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
        INFO:     [bob-0]: Received message from agent1qwquu2d237gntfugrnwch38g8jkl76vdr05qjm4wyps6ap04fvt8vtzhpqw: Hello there bob.
        INFO:     [bob-0]: Received message from agent1qwquu2d237gntfugrnwch38g8jkl76vdr05qjm4wyps6ap04fvt8vtzhpqw: Hello there bob.
        INFO:     [bob-0]: Received message from agent1qwquu2d237gntfugrnwch38g8jkl76vdr05qjm4wyps6ap04fvt8vtzhpqw: Hello there bob.
        INFO:     [bob-0]: Received message from agent1qwquu2d237gntfugrnwch38g8jkl76vdr05qjm4wyps6ap04fvt8vtzhpqw: Hello there bob.
    
2.  **Alice**:
    
        INFO:     [alice-0]: Registration on Almanac API successful
        INFO:     [alice-0]: Registering on almanac contract...
        INFO:     [alice-0]: Registering on almanac contract...complete
        INFO:     [alice-0]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
        INFO:     [alice-0]: Sending message to bob-0.agent...
        INFO:     [alice-0]: Sending message to bob-0.agent...
        INFO:     [alice-0]: Sending message to bob-0.agent...</content>
</page>

<page>
  <title>Create an ASI:One compatible Agent using the chatprotocol docs</title>
  <url>https://uagents.fetch.ai/docs/examples/asi-1</url>
  <content>Introduction[](#introduction)
-----------------------------

[ASI:One](https://asi1.ai/) is an LLM created by Fetch.ai, unlike other LLMs ASI:One connects to Agents which act as domain experts allowing ASI:One to answer specialist questions, make reservations and become an access point to an ‚Äúorganic‚Äù multi-Agent ecosystem.

This guide is the preliminary step of getting your agents onto ASI:One by getting your agent online, active and using the chat protocol to enable you to communicate with your agent with [ASI:One chat](https://asi1.ai/chat).

Why be part of the knowledge base[](#why-be-part-of-the-knowledge-base)
-----------------------------------------------------------------------

By building agents to connect to ASI:One we extend the LLM‚Äôs knowledge base, but also create new opportunities for monetization. By building and integrating these Agents, you can be \*earning revenue based on your Agent‚Äôs usage while enhancing the capabilities of the LLM. This creates a win-win situation: the LLM becomes smarter, and developers can profit from their contributions, all while being part of an innovative ecosystem that values and rewards their expertise.

Alrighty, let‚Äôs get started!

Getting started[](#getting-started)
-----------------------------------

*   Head over to as1.ai, and [create an API key](https://docs.asi1.ai/docs/core/api-key).
*   Make sure you have [uAgents library installed](https://uagents.fetch.ai/docs/getting-started/install).
*   Sign up to [Agentverse](https://agentverse.ai/) so that you can create a [mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox) for your Agent.

Don‚Äôt fret, we explain these topics in this guide.

Chat protocol[](#chat-protocol)
-------------------------------

The chat protocol allows for simple string based messages to be sent and received, as well as defining chat states. It‚Äôs the expected communication format for ASI:One. You will import this as a dependency when you install uAgents.

It is imported like so:

`from uagents_core.contrib.protocols.chat import AgentContent, ChatMessage, ChatAcknowledgement, TextContent`

The most important thing to note about the chat protocol, is `ChatMessage(Model)`; this is the wrapper for each message we send, within this, there is a list of `AgentContent` which can be a number of models, most often you‚Äôll probably be using `TextContent`.

An example of this is a littler further down the page.

The Agent[](#the-agent)
-----------------------

We define a [local Agent](https://uagents.fetch.ai/docs/guides/types) with the following code:

    from datetime import datetime
    from uuid import uuid4
     
    from openai import OpenAI
    from uagents import Context, Protocol, Agent
    from uagents_core.contrib.protocols.chat import (
        ChatAcknowledgement,
        ChatMessage,
        EndSessionContent,
        TextContent,
        chat_protocol_spec,
    )
     
     
    ### Example Expert Assistant
     
    ## This chat example is a barebones example of how you can create a simple chat agent
    ## and connect to agentverse. In this example we will be prompting the ASI:One model to
    ## answer questions on a specific subject only. This acts as a simple placeholder for
    ## a more complete agentic system.
    ##
     
    # the subject that this assistant is an expert in
    subject_matter = "the sun"
     
    client = OpenAI(
        # By default, we are using the ASI:One LLM endpoint and model
        base_url='https://api.asi1.ai/v1',
     
        # You can get an ASI:One api key by creating an account at https://asi1.ai/dashboard/api-keys
        api_key='<YOUR_API_KEY>',
    )
     
    agent = Agent(
        name="ASI-agent",
        seed="agent_seedphrase",
        port=8001,
        mailbox=True,
        publish_agent_details=True,
    )
     
    # We create a new protocol which is compatible with the chat protocol spec. This ensures
    # compatibility between agents
    protocol = Protocol(spec=chat_protocol_spec)
     
     
    # We define the handler for the chat messages that are sent to your agent
    @protocol.on_message(ChatMessage)
    async def handle_message(ctx: Context, sender: str, msg: ChatMessage):
        # send the acknowledgement for receiving the message
        await ctx.send(
            sender,
            ChatAcknowledgement(timestamp=datetime.now(), acknowledged_msg_id=msg.msg_id),
        )
     
        # collect up all the text chunks
        text = ''
        for item in msg.content:
            if isinstance(item, TextContent):
                text += item.text
     
        # query the model based on the user question
        response = 'I am afraid something went wrong and I am unable to answer your question at the moment'
        try:
            r = client.chat.completions.create(
                model="asi1-mini",
                messages=[
                    {"role": "system", "content": f"""
            You are a helpful assistant who only answers questions about {subject_matter}. If the user asks 
            about any other topics, you should politely say that you do not know about them.
                    """},
                    {"role": "user", "content": text},
                ],
                max_tokens=2048,
            )
     
            response = str(r.choices[0].message.content)
        except:
            ctx.logger.exception('Error querying model')
     
        # send the response back to the user
        await ctx.send(sender, ChatMessage(
            timestamp=datetime.utcnow(),
            msg_id=uuid4(),
            content=[
                # we send the contents back in the chat message
                TextContent(type="text", text=response),
                # we also signal that the session is over, this also informs the user that we are not recording any of the
                # previous history of messages.
                EndSessionContent(type="end-session"),
            ]
        ))
     
     
    @protocol.on_message(ChatAcknowledgement)
    async def handle_ack(ctx: Context, sender: str, msg: ChatAcknowledgement):
        # we are not interested in the acknowledgements for this example, but they can be useful to
        # implement read receipts, for example.
        pass
     
     
    # attach the protocol to the agent
    agent.include(protocol, publish_manifest=True)
     
    if __name__ == "__main__":
        agent.run()
     

You can get an API Key for this example [here](https://docs.asi1.ai/docs/core/api-key).

This example sets up a simple expert assistant Agent using the uAgents Framework and connects it to the [ASI:One LLM](https://docs.asi1.ai/docs) via its API. The Agent, named `ASI-agent`, is configured to operate on `port=8001` with a [mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox) support and publishes its details for discovery onto the Agentverse. It uses the standardized chat protocol provided by `uagents_core.contrib.protocols.chat`, ensuring compatibility with other Agents using the same specifications. When it receives a `ChatMessage`, it acknowledges the message, extracts the user‚Äôs input, and forwards it to the ASI:One model hosted at `https://api.asi1.ai/v1`, using a predefined system prompt that restricts the assistant‚Äôs responses strictly to the topic of `"the moon"`. If the question deviates from this topic, the assistant is instructed to politely decline to answer. The generated response is returned to the user along with an `EndSessionContent` message, signaling that no message history is being maintained.

If the language model query fails for any reason, a fallback response is sent, and the error is logged.

We can start this Agent now. You should see something like this within your terminal output:

    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [ASI-agent]:  Mailbox access token acquired

### Enabling the mailbox[](#enabling-the-mailbox)

Let‚Äôs click the link for the [Agent inspector](https://uagents.fetch.ai/docs/agentverse/inspector); you should see a window like the below:

Click **connect** and in the modal select **Mailbox**.

You‚Äôll then see instructions to update your Agent to use the mailbox:

Now our Agent can receive messages from any Agent! You can read more about the mailbox [here](https://uagents.fetch.ai/docs/agentverse/mailbox).

You should now see the updated output in your terminal:

    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [ASI-agent]:  Mailbox access token acquired
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    INFO:     [mailbox]: Agent details updated in Agentverse

Alrighty, let‚Äôs chat with our Agent!

ASI:One Chat[](#asione-chat)
----------------------------

Now, you need to get an API Key. To do so, head over to ASI:One and create a new [API key](https://docs.asi1.ai/docs/core/api-key) and add it within the dedicated field in the above Agent‚Äôs code.

Once you do so, you will be able to start your Agent successfully. It will register in the Almanac and be accessible for queries.

Then, head over to [ASI:One chat](https://asi1.ai/chat). You will need to get in contact with the Agent we defined above. It is important that you provide detailed information about the Agent‚Äôs area of expertise within the README file so to improve the Agent‚Äôs discoverability across the Network and redirect queries matching your Agent‚Äôs subject of interest. Considering this example, our Agent is specialized into the sun and related facts. Thus, let‚Äôs type: ‚ÄúHi, can you connect me to an agent that specializes in the sun?‚Äù. Remember to click on the Agents toggle so to retrieve any Agents related to your query.

You will see some reasoning happening. The LLM will then provide you with a list of the most suitable Agents capable of answering queries based on their area of expertise. You should be able to see our Agent appearing in the results:

Click the **Chat with Agent** button. You will be automatically connected to the Agent. Remember that **_the Agent needs to be running_** otherwise you won‚Äôt be able to chat with it! If successful, you should get something similar to the following:

You can now start a conversation with your local Agent. Provide a query related to the Agent‚Äôs subject of expertise directly in the chat:

On your Agent‚Äôs terminal, you will see that the Agent has correctly received the Envelope with the query, will have it processed, and it will then send back the Envelope to the sender with the related answer to the query.

You should see something similar to the following in the terminal window:

    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    INFO:     [mailbox]: Agent details updated in Agentverse
    INFO:httpx:HTTP Request: POST https://api.asi1.ai/v1/chat/completions "HTTP/1.1 200 OK"

### Client Agent[](#client-agent)

Of course, you could also create a client to your Agent and skip ASI:One Chat, here‚Äôs an example of that too:

    from datetime import datetime
    from uuid import uuid4
    from uagents import Agent, Context, Protocol, Model
    from uagents_core.contrib.protocols.chat import AgentContent, ChatMessage, ChatAcknowledgement, TextContent
     
    AI_AGENT_ADDRESS = "agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf"
     
    agent = Agent(
        name="asi-agent",
        seed="hiweihvhieivhwehihiweivbw;ibv;rikbv;erv;rkkbv",
        port=8002,
        endpoint=["http://127.0.0.1:8002/submit"],
    )
     
     
    @agent.on_event("startup")
    async def send_message(ctx: Context):
        await ctx.send(AI_AGENT_ADDRESS, ChatMessage(
            timestamp=datetime.now(),
            msg_id=uuid4(),
            content=[TextContent(type="text", text="Give me facts about the sun")],
        ))
     
     
    @agent.on_message(ChatAcknowledgement)
    async def handle_ack(ctx: Context, sender: str, msg: ChatAcknowledgement):
        ctx.logger.info(f"Got an acknowledgement from {sender} for {msg.acknowledged_msg_id}")
     
     
    @agent.on_message(ChatMessage)
    async def handle_ack(ctx: Context, sender: str, msg: ChatMessage):
        ctx.logger.info(f"Received request from {sender} for {msg.content[0].text}")
     
    agent.run()

Let‚Äôs run the client like so `python client.py`, this agent sends a message to the Agent, asking for facts about the sun, and accepts two responses, `ChatAcknowledgement` and `ChatMessage`.

Next steps[](#next-steps)
-------------------------

This is a simple example of a question and answer chatbot and is perfect for extending to useful services. [ASI:One chat](https://asi1.ai/chat) is the first step in getting your Agents onto ASI:One, keep an eye on our [blog](https://fetch.ai/blog) for the future release date. Additionally, remember to check out the dedicated **ASI:One documentation** for additional information on the topic, which is available here: [ASI:One docs](https://docs.asi1.ai/docs).

What can you build with a dynamic chat protol, and an LLM?

For any additional questions, the Team is waiting for you on [Discord](https://discord.gg/fetchai) and [Telegram](https://t.me/fetch_ai) channels.

\* payments are planned to be released Q3 2025.</content>
</page>

<page>
  <title>How to use agents to send tokens docs</title>
  <url>https://uagents.fetch.ai/docs/guides/send_tokens</url>
  <content>Introduction[](#introduction)
-----------------------------

Within agent-based decentralized systems, efficient communication and secure data exchange are essential. In this guide, we will walk you through the process of setting up two AI Agents utilizing the `uagents` library to establish a dynamic workflow where one agent periodically sends payment requests to another, which in turn processes these requests, executes transactions, and provides transaction information back to sending agent.

Let‚Äôs get started!

Imports needed[](#imports-needed)
---------------------------------

Walk-through[](#walk-through)
-----------------------------

1.  First of all, create a Python script for this task, and name it:
    
        echo. > sending_tokens.py
    
2.  Then, import the necessary modules from `uagents`, `uagents.network`, and `uagents.setup`. Let‚Äôs then define two data models: `PaymentRequest` and `TransactionInfo`. We then need to set up the values for the `AMOUNT` and `DENOM` variables, which define the default amount and denomination for the payment requests:
    

     
    from uagents import Agent, Bureau, Context, Model
    from uagents.network import wait_for_tx_to_complete
    from uagents.setup import fund_agent_if_low
     
    class PaymentRequest(Model):
        wallet_address: str
        amount: int
        denom: str
     
    class TransactionInfo(Model):
        tx_hash: str
     
    AMOUNT = 100
    DENOM = "atestfet"
     

*   The `PaymentRequest` model represents a payment request which contains the `wallet_address`, `amount`, and `denom`.
    
*   The `TransactionInfo` model represents information about a transaction and contains a single attribute, `tx_hash`.
    

3.  Let‚Äôs now define our agents, `alice` and `bob`. Ensure they have enough funds in their wallets to carry out transactions:

     
    alice = Agent(name="alice", seed="alice secret phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob secret phrase", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
     
    fund_agent_if_low(bob.wallet.address(), min_balance=AMOUNT)
     

4.  We can now define our agents behaviour and functions:

     
    @alice.on_interval(period=10.0)
    async def request_funds(ctx: Context):
        await ctx.send(
            bob.address,
            PaymentRequest(
                wallet_address=str(alice.wallet.address()), amount=AMOUNT, denom=DENOM
            ),
        )
     

This defines an event handler for `alice` using the `.on_interval()` decorator. This event handler is triggered at regular intervals of `10.0` seconds in this case. The event handler function is named `request_funds()` and takes a `ctx` parameter of type `Context`. Within the function, `alice` sends a payment request message to `bob` by using the `ctx.send()` method. The `ctx.send()` method is called with the recipient address, `bob.address`, which specifies that the message should be sent to `bob`. The message is an instance of the `PaymentRequest()` model. It contains `alice`‚Äôs wallet address (`alice.wallet.address()`), the amount (`AMOUNT`), and the denomination (`DENOM`).

5.  We can now define a `confirm_transaction()` message handler for `alice` to handle incoming messages from `bob` of type `TransactionInfo`:

     
    @alice.on_message(model=TransactionInfo)
    async def confirm_transaction(ctx: Context, sender: str, msg: TransactionInfo):
        ctx.logger.info(f"Received transaction info from {sender}: {msg}")
        tx_resp = await wait_for_tx_to_complete(msg.tx_hash, ctx.ledger)
     
        coin_received = tx_resp.events["coin_received"]
        if (
                coin_received["receiver"] == str(alice.wallet.address())
                and coin_received["amount"] == f"{AMOUNT}{DENOM}"
        ):
            ctx.logger.info(f"Transaction was successful: {coin_received}")
     

The event handler function is named `confirm_transaction()` and takes three parameters: `ctx`, `sender`, and `msg`. Within the function, `alice` logs an informational message using the `ctx.logger.info()` method, indicating the receipt of transaction information from the sender agent, `bob`, and displaying the `msg` object. The `wait_for_tx_to_complete()` function is used to await the completion of the transaction specified by the `tx_hash` received in the message.

Once the transaction is completed, the code accesses the `coin_received` event from the transaction response using `tx_resp.events[\"coin_received\"]`. It checks if the receiver address matches `alice`‚Äôs wallet address (`alice.wallet.address()`) and if the amount received matches the expected amount (`AMOUNT + DENOM`).

If the conditions are met, `alice` logs another informational message indicating the success of the transaction and displaying the details of the received coins.

6.  Let‚Äôs now define an event handler for `bob`. This event handler is triggered when `bob` receives a message of type `PaymentRequest` from `alice`:

     
    @bob.on_message(model=PaymentRequest, replies=TransactionInfo)
    async def send_payment(ctx: Context, sender: str, msg: PaymentRequest):
        ctx.logger.info(f"Received payment request from {sender}: {msg}")
     
        # send the payment
        transaction = ctx.ledger.send_tokens(
            msg.wallet_address, msg.amount, msg.denom, bob.wallet
        )
     
        # send the tx hash so alice can confirm
        await ctx.send(alice.address, TransactionInfo(tx_hash=transaction.tx_hash))
     

The event handler function is named `send_payment()` and takes three parameters: `ctx`, `sender`, and `msg`. Within the function, `bob` logs an informational message using the `ctx.logger.info()` method, indicating the receipt of a payment request from the sender agent, `bob`, and displaying the `msg` object.

Next, the code performs a payment transaction using the `ctx.ledger.send_tokens()` method. It takes the wallet address (`msg.wallet_address`), amount (`msg.amount`), denomination (`msg.denom`), and `bob.wallet()` as parameters. This method is responsible for sending the requested payment.

Once the transaction is completed, `bob` sends a message back to `alice` to inform her about the transaction, using `ctx.send()`. The message is created using the `TransactionInfo` model with the `tx_hash` obtained from the transaction response. The `ctx.send()` method is used to send this message to alice using her address (`alice.address`).

7.  We are now ready to use the Bureau class to create a `bureau` object and add both uAgents to it so for them to be run together:

     
    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
     
    if __name__ == "__main__":
        bureau.run()
     

The overall script for this example should look as follows:

     
    from uagents import Agent, Bureau, Context, Model
    from uagents.network import wait_for_tx_to_complete
    from uagents.setup import fund_agent_if_low
     
    class PaymentRequest(Model):
        wallet_address: str
        amount: int
        denom: str
     
    class TransactionInfo(Model):
        tx_hash: str
     
    AMOUNT = 100
    DENOM = "atestfet"
     
    alice = Agent(name="alice", seed="alice secret phrase", port=8000, endpoint=["http://127.0.0.1:8000/submit"])
    bob = Agent(name="bob", seed="bob secret phrase", port=8001, endpoint=["http://127.0.0.1:8001/submit"])
     
    fund_agent_if_low(bob.wallet.address(), min_balance=AMOUNT)
     
    @alice.on_interval(period=10.0)
    async def request_funds(ctx: Context):
        await ctx.send(
            bob.address,
            PaymentRequest(
                wallet_address=str(alice.wallet.address()), amount=AMOUNT, denom=DENOM
            ),
        )
     
    @alice.on_message(model=TransactionInfo)
    async def confirm_transaction(ctx: Context, sender: str, msg: TransactionInfo):
        ctx.logger.info(f"Received transaction info from {sender}: {msg}")
        tx_resp = await wait_for_tx_to_complete(msg.tx_hash, ctx.ledger)
     
        coin_received = tx_resp.events["coin_received"]
        if (
                coin_received["receiver"] == str(alice.wallet.address())
                and coin_received["amount"] == f"{AMOUNT}{DENOM}"
        ):
            ctx.logger.info(f"Transaction was successful: {coin_received}")
     
    @bob.on_message(model=PaymentRequest, replies=TransactionInfo)
    async def send_payment(ctx: Context, sender: str, msg: PaymentRequest):
        ctx.logger.info(f"Received payment request from {sender}: {msg}")
     
        # send the payment
        transaction = ctx.ledger.send_tokens(
            msg.wallet_address, msg.amount, msg.denom, bob.wallet
        )
     
        # send the tx hash so alice can confirm
        await ctx.send(alice.address, TransactionInfo(tx_hash=transaction.tx_hash))
     
    bureau = Bureau()
    bureau.add(alice)
    bureau.add(bob)
     
    if __name__ == "__main__":
        bureau.run()
     

Run the script[](#run-the-script)
---------------------------------

On your terminal, make sure to have activated the virtual environment.

Run the script: `python sending_tokens.py`

The output should be as follows:

    WARNING:  [Alice]: No endpoints provided. Skipping registration: Agent won't be reachable.
    WARNING:  [  Bob]: No endpoints provided. Skipping registration: Agent won't be reachable.
    INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [  bob]: Received payment request from agent1qdp9j2ev86k3h5acaayjm8tpx36zv4mjxn05pa2kwesspstzj697xy5vk2a: wallet_address='fetch1967p3vkp0yngdfturv4ypq2p4g760ml705wcxy' amount=100 denom='atestfet'
    INFO:     [alice]: Received transaction info from agent1q2kxet3vh0scsf0sm7y2erzz33cve6tv5uk63x64upw5g68kr0chkv7hw50: tx_hash='DB662CCF415C7B0C9A02928967BE1817506D02A041AA05CA48DCE5CF87D5A638'
    INFO:     [alice]: Transaction was successful: {'receiver': 'fetch1967p3vkp0yngdfturv4ypq2p4g760ml705wcxy', 'amount': '100atestfet'}</content>
</page>

<page>
  <title>Agent Chat Protocol docs</title>
  <url>https://uagents.fetch.ai/docs/guides/chat_protocol</url>
  <content>This guide walks you through the implementation of agent-to-agent communication using protocols. It includes registering protocols in an [Almanac](https://network.fetch.ai/docs/introduction/almanac/introduction) contract and understanding their metadata, which is stored as manifests.

What is Protocol?[](#what-is-protocol)
--------------------------------------

A [protocol](https://uagents.fetch.ai/docs/guides/protocols) is a self-contained collection of message handlers. Its digest ensures that the protocol reliably supports the intended messages, serving as a unique identifier for the specific implementation.

### When to Use Protocols[](#when-to-use-protocols)

Protocols are designed for modular and reusable communication behavior. They are essential for scaling ecosystems by enabling interoperability.

*   **Reusable Communication**: Support predefined message structures to connect with existing systems effortlessly.
*   **Compatibility**: Following protocols ensures seamless communication between agents.
*   **Scalability**: Standardized interactions allow the ecosystem to grow and integrate new agents easily.

What Are Chat Protocols?[](#what-are-chat-protocols)
----------------------------------------------------

Agent chat protocols define the rules and structure for communication between Agents. They ensure that messages exchanged between Agents are well-structured, predictable, and interoperable. In the context of Agent-based systems, chat protocols specify:

*   The types of messages agents can send and receive.
    
*   The sequence of interactions between agents.
    
*   How messages are processed and responded to.
    
    üí°
    
    In a multi-agent system, Agents are identified by their interactive behavior ‚Äî what output they provide in response to given input. Code unrelated to interactions is irrelevant, as it does not affect observable behavior. Therefore, only protocols have manifests, not Agents!
    

Overview[](#overview)
---------------------

In this implementation, two Agents, `InitiatorAgent` and a `ResponderAgent`, communicate using predefined protocols. The Agents exchange messages, and their protocols and models are registered in an Almanac contract. The metadata is stored as a manifest describing the protocol, models, and interactions.

Protocols and Communication[](#protocols-and-communication)
-----------------------------------------------------------

### Message Models[](#message-models)

*   `RequestMessage`: Represents the request initiated by the sender.
    
*   `ResponseMessage`: Represents the response sent back by the receiver.
    
*   Both models ensure structured and predictable data exchange.
    
        class RequestMessage(Model):
            text: str
         
        class ResponseMessage(Model):
            text: str
    

### Initialize Agents[](#initialize-agents)

Two Agents, `InitiatorAgent` and ResponderAgent, are created with unique seeds for identity.

    initiator_agent = Agent(
        name="InitiatorAgent", 
        seed="initiator recovery phrase", 
    )
     
    responder_agent = Agent(
        name="ResponderAgent", 
        seed="responder recovery phrase", 
    )

### Define Chat Protocols[](#define-chat-protocols)

Protocols specify how Agents interact. The `SimpleProtocol_Initiator` is for the initiator, and `SimpleProtocol_Responder` is for the responder.

    initiator_protocol = Protocol(name="SimpleProtocol_Initiator", version="0.1.0")
    responder_protocol = Protocol(name="SimpleProtocol_Responder", version="0.1.0")

### Implement Protocol Handlers[](#implement-protocol-handlers)

[Handlers](https://uagents.fetch.ai/docs/guides/handlers) define the interaction logic:

1.  Initiator sends a message periodically:
    
        @initiator_protocol.on_interval(period=3.0)
        async def initiator_send_message(ctx: Context):
            await ctx.send(responder_agent.address, RequestMessage(text="Hello there from Initiator!"))
    
2.  Responder handles the request and replies:
    
        @responder_protocol.on_message(RequestMessage, replies=ResponseMessage)
        async def responder_handle_message(ctx: Context, sender: str, msg: RequestMessage):
            ctx.logger.info(f"Received message from {sender}: {msg.text}")
            await ctx.send(sender, ResponseMessage(text="Hello there from Responder!"))
    
3.  Initiator handles the response:
    
        @initiator_protocol.on_message(model=ResponseMessage)
        async def initiator_handle_response(ctx: Context, sender: str, msg: ResponseMessage):
            ctx.logger.info(f"Received response from {sender}: {msg.text}")
    

### Bureau Initialization[](#bureau-initialization)

The `Bureau` facilitates the Agents‚Äô execution and connects them via an endpoint.

    bureau = Bureau(endpoint=["http://127.0.0.1:8000/submit"])
    bureau.add(initiator_agent)
    bureau.add(responder_agent)

### Main Function[](#main-function)

Agents include their respective protocols and register their metadata manifest with the Almanac contract:

    if __name__ == '__main__':
        initiator_agent.include(initiator_protocol, publish_manifest=True)
        responder_agent.include(responder_protocol, publish_manifest=True)
        bureau.run()

Metadata Manifest[](#metadata-manifest)
---------------------------------------

This is a registered manifest for Agents in the Almanac system, defining communication protocols between the initiator and responder. It specifies message models for both requests and responses.

When protocols are registered, metadata is stored in the Almanac as a manifest. The published protocol manifest would look something like this:

*   for `initiator_agent` published manifest looks like:
    
        {
          "version": "1.0",
          "metadata": {
            "name": "SimpleProtocol_Initiator",
            "version": "0.1.0",
            "digest": "proto:2a34b5504c58f43b2932cdd73358cebe0b668ea10e6796abba3dec8a4c50f25b"
          },
          "models": [
            {
              "digest": "model:465d2d900b616bb4082d4d7fcd9cc558643bb1b9b45660a7f546d5b5b5c0aba5",
              "schema": {
                "properties": {
                  "text": {
                    "title": "Text",
                    "type": "string"
                  }
                },
                "required": [
                  "text"
                ],
                "title": "ResponseMessage",
                "type": "object"
              }
            }
          ],
          "interactions": []
        }
    
*   for `responder_agent` published manifest looks like:
    
        {
          "version": "1.0",
          "metadata": {
            "name": "SimpleProtocol_Responder",
            "version": "0.1.0",
            "digest": "proto:c93ed21a1091272c178c4f6b05619405204e6458294b4a6ee080299bf20e619a"
          },
          "models": [
            {
              "digest": "model:ae2de187153cc7a80641a52927aa2852a820cd56bbbdb8671a0d1e643472f9b7",
              "schema": {
                "properties": {
                  "text": {
                    "title": "Text",
                    "type": "string"
                  }
                },
                "required": [
                  "text"
                ],
                "title": "RequestMessage",
                "type": "object"
              }
            },
            {
              "digest": "model:465d2d900b616bb4082d4d7fcd9cc558643bb1b9b45660a7f546d5b5b5c0aba5",
              "schema": {
                "properties": {
                  "text": {
                    "title": "Text",
                    "type": "string"
                  }
                },
                "required": [
                  "text"
                ],
                "title": "ResponseMessage",
                "type": "object"
              }
            }
          ],
          "interactions": [
            {
              "type": "normal",
              "request": "model:ae2de187153cc7a80641a52927aa2852a820cd56bbbdb8671a0d1e643472f9b7",
              "responses": [
                "model:465d2d900b616bb4082d4d7fcd9cc558643bb1b9b45660a7f546d5b5b5c0aba5"
              ]
            }
          ]
        }</content>
</page>

<page>
  <title>Using Jupyter notebook to build an Agent docs</title>
  <url>https://uagents.fetch.ai/docs/examples/jupyter-agent</url>
  <content>**Jupyter notebook** natively supports asyncio, and as [Agents](https://uagents.fetch.ai/docs/quickstart) are asynchronous by design, Jupyter and Agents work together with ease.

We‚Äôre using [poetry](https://python-poetry.org/) to manage our application, but it is not super essential for you. Just be sure to have the following libraries installed on your system:

        python = "3.11"
        uagents = "^0.17.1"
        notebook = "^7.2.2"
        jupyter = "^1.1.1"

Are you new to Agents? To understand the agent in this example, please read [communicating with agents](https://uagents.fetch.ai/docs/guides/communication).

agent\_in\_notebook.ipynb?short\_path=9c85396

     
    {
     "cells": [
      {
       "cell_type": "code",
       "execution_count": 34,
       "id": "790cab08-020a-4903-80f5-10392785944a",
       "metadata": {},
       "outputs": [],
       "source": [
        "from uagents import Agent, Context, Model\n",
        "from uagents.setup import fund_agent_if_low\n",
        "import os\n",
        "import asyncio\n",
        "import contextlib"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 35,
       "id": "ff526b8f-5e08-47c9-af87-80cdd6eba972",
       "metadata": {},
       "outputs": [],
       "source": [
        "# comment "
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 36,
       "id": "85aae090-2724-4bde-9f7c-e593135a410f",
       "metadata": {},
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "<_UnixSelectorEventLoop running=True closed=False debug=False>\n"
         ]
        }
       ],
       "source": [
        "loop = asyncio.get_event_loop()\n",
        "print (loop)"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 37,
       "id": "a09b9f72-5b41-486f-95df-900233a2742a",
       "metadata": {},
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n"
         ]
        }
       ],
       "source": [
        "agent = Agent(\n",
        "    name=\"first_agent\",\n",
        "    seed=\"AGENT_1_SEED\",\n",
        "    endpoint=[\"http://127.0.0.1:8005/submit\"],\n",
        "    port=8005)\n",
        "\n",
        "SECOND_AGENT_ADDRESS = (\n",
        "    \"agent1qdceynp4t0lel3cfdlvlezjva8tf6fww8jd97vs9ym2h3g678e65vjj8vjh\"\n",
        ")\n",
        "\n",
        "print (agent.address)\n"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 38,
       "id": "15182730-93b4-41a5-878b-674be50c240e",
       "metadata": {},
       "outputs": [],
       "source": [
        "class ResponseMessage(Model):\n",
        "    text: str\n"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 39,
       "id": "e83d7f83-58a5-4e54-995d-30aca419128f",
       "metadata": {},
       "outputs": [],
       "source": [
        "@agent.on_event(\"startup\")\n",
        "async def on_startup(ctx: Context):\n",
        "    message = ResponseMessage(text=\"Hello from first agent\")\n",
        "    await ctx.send(SECOND_AGENT_ADDRESS, message)\n",
        "\n",
        "\n",
        "@agent.on_message(model=ResponseMessage)\n",
        "async def handle_message(ctx: Context, sender: str, msg: ResponseMessage):\n",
        "    ctx.logger.info(f\"Received message from {sender}: {msg.text}\")\n",
        "    "
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 40,
       "id": "a685d22f-f8b0-4026-812c-855ecdcf87ea",
       "metadata": {},
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "<uagents.agent.Agent object at 0x11282ea90>\n"
         ]
        }
       ],
       "source": [
        "print(agent)"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 41,
       "id": "ba14c679-f6a5-4ccf-9023-62e1de12b806",
       "metadata": {},
       "outputs": [
        {
         "data": {
          "text/plain": [
           "<Task pending name='Task-39' coro=<Agent.run_async() running at /Users/joshuacroft/Library/Caches/pypoetry/virtualenvs/jp-FhiL5LrG-py3.11/lib/python3.11/site-packages/uagents/agent.py:1170>>"
          ]
         },
         "execution_count": 41,
         "metadata": {},
         "output_type": "execute_result"
        },
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Registration on Almanac API successful\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "INFO:     [first_agent]: Almanac contract registration is up to date!\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "ERROR:    [first_agent]: Unable to resolve destination endpoint\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n",
          "INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent\n"
         ]
        }
       ],
       "source": [
        "loop.create_task(agent.run_async())"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": null,
       "id": "7a62d5e8-71f4-4a11-9e7c-f37ee6777891",
       "metadata": {},
       "outputs": [],
       "source": []
      },
      {
       "cell_type": "code",
       "execution_count": null,
       "id": "a483bc10-4861-4472-abc8-197db30a4b02",
       "metadata": {},
       "outputs": [],
       "source": []
      }
     ],
     "metadata": {
      "kernelspec": {
       "display_name": "Python 3 (ipykernel)",
       "language": "python",
       "name": "python3"
      },
      "language_info": {
       "codemirror_mode": {
        "name": "ipython",
        "version": 3
       },
       "file_extension": ".py",
       "mimetype": "text/x-python",
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
       "version": "3.11.0"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 5
    }
     

    poetry run jupyter notebook

    INFO:     [first_agent]: Registration on Almanac API successful
    INFO:     [first_agent]: Registering on almanac contract... 
    INFO:     [first_agent]: Registering on almanac contract...complete
    ERROR:    [first_agent]: Unable to resolve destination endpoint
    INFO:     [first_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8005&address=agent1qdwgulp6q2jw93u3yhh9teectdjaxvrmmwl900cs33vz4skkawstg3q74n4
    INFO:     [first_agent]: Starting server on http://0.0.0.0:8005 (Press CTRL+C to quit)
    INFO:     [first_agent]: Received message from agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt: Hello from first agent

    INFO:     [jupyter_test_agent]: Registration on Almanac API successful
    INFO:     [jupyter_test_agent]: Registering on almanac contract... 
    INFO:     [jupyter_test_agent]: Registering on almanac contract...complete
    INFO:     [jupyter_test_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8009&address=agent1qgdefk0mewtn88dj5nu05lkwtxd3jedn9g8lw7jttrkz9c09l37lqnhs5zt
    INFO:     [jupyter_test_agent]: Starting server on http://0.0.0.0:8009 (Press CTRL+C to quit)</content>
</page>

<page>
  <title>LangGraph Adapter for uAgents docs</title>
  <url>https://uagents.fetch.ai/docs/guides/langchain_agent</url>
  <content>This example demonstrates how to integrate a LangGraph agent with the uAgents ecosystem using the uAgents Adapter package. LangGraph provides powerful orchestration capabilities for LLM applications through directed graphs.

Overview[](#overview)
---------------------

The LangGraph adapter allows you to:

1.  Wrap LangGraph agents as uAgents for seamless communication
2.  Enable LangGraph agents to participate in the Agentverse ecosystem
3.  Leverage advanced orchestration for complex reasoning while maintaining uAgent compatibility

Example Implementation[](#example-implementation)
-------------------------------------------------

Create an agent with file name `agent.py`:

    import os
    import time
    from dotenv import load_dotenv
     
    from langchain_openai import ChatOpenAI
    from langchain_community.tools.tavily_search import TavilySearchResults
    from langgraph.prebuilt import chat_agent_executor
    from langchain_core.messages import HumanMessage
     
    from uagents_adapter import LangchainRegisterTool, cleanup_uagent
     
    # Load environment variables
    load_dotenv()
     
    # Set your API keys - for production, use environment variables instead of hardcoding
    OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
    TAVILY_API_KEY = os.environ["TAVILY_API_KEY"]
     
    # Get API token for Agentverse
    API_TOKEN = os.environ["AGENTVERSE_API_KEY"]
     
    if not API_TOKEN:
        raise ValueError("Please set AGENTVERSE_API_KEY environment variable")
     
    # Set up tools and LLM
    tools = [TavilySearchResults(max_results=3)]
    model = ChatOpenAI(temperature=0)
     
    # LangGraph-based executor
    app = chat_agent_executor.create_tool_calling_executor(model, tools)
     
    # Wrap LangGraph agent into a function for UAgent
    def langgraph_agent_func(query):
        # Handle input if it's a dict with 'input' key
        if isinstance(query, dict) and 'input' in query:
            query = query['input']
        
        messages = {"messages": [HumanMessage(content=query)]}
        final = None
        for output in app.stream(messages):
            final = list(output.values())[0]  # Get latest
        return final["messages"][-1].content if final else "No response"
     
    # Register the LangGraph agent via uAgent
    tool = LangchainRegisterTool()
    agent_info = tool.invoke(
        {
            "agent_obj": langgraph_agent_func,
            "name": "langgraph_tavily_agent",
            "port": 8080,
            "description": "A LangGraph-based Tavily-powered search agent",
            "api_token": API_TOKEN,
            "mailbox": True
        }
    )
     
    print(f"‚úÖ Registered LangGraph agent: {agent_info}")
     
    # Keep the agent alive
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("üõë Shutting down LangGraph agent...")
        cleanup_uagent("langgraph_tavily_agent")
        print("‚úÖ Agent stopped.")

Key Components[](#key-components)
---------------------------------

1.  angGraph Setup:
    
    *   Creates a tool-calling executor using LangGraph‚Äôs prebuilt components
    *   Configures Tavily search as the tool for retrieving information
    *   Uses OpenAI‚Äôs ChatGPT for LLM capabilities
2.  Function Wrapper:
    
    *   Wraps the LangGraph app in a function that accepts queries
    *   Handles input format conversion
    *   Processes streaming output from LangGraph
3.  uAgent Registration:
    
    *   Uses UAgentRegisterTool to register the LangGraph function as a uAgent
    *   Configures a port, description, and mailbox for persistence
    *   Generates a unique address for agent communication

Sample requirements.txt[](#sample-requirementstxt)
--------------------------------------------------

Here‚Äôs a sample `requirements.txt` file you can use for this example:

    uagents==0.22.3
    uagents-adapter==0.2.1
    langchain-openai==0.3.14
    langchain-community==0.3.21
    langgraph==0.3.31
    dotenv==0.9.9

Interacting with the Agent[](#interacting-with-the-agent)
---------------------------------------------------------

You can interact with this LangGraph agent through any uAgent using the chat protocol. Here‚Äôs a client implementation:

    from datetime import datetime
    from uuid import uuid4
    from uagents import Agent, Protocol, Context
    
    #import the necessary components from the chat protocol
    from uagents_core.contrib.protocols.chat import (
        ChatAcknowledgement,
        ChatMessage,
        TextContent,
        chat_protocol_spec,
    )
    # Initialise agent2
    agent2 = Agent(name="client_agent",
                   port = 8082,
                   mailbox=True,
                   seed="client agent testing seed"
                   )
    
    # Initialize the chat protocol
    chat_proto = Protocol(spec=chat_protocol_spec)
    
    langgraph_agent_address = "agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t" # Update with your Langgraph Agent's address
    
    # Startup Handler - Print agent details
    @agent2.on_event("startup")
    async def startup_handler(ctx: Context):
        # Print agent details
        ctx.logger.info(f"My name is {ctx.agent.name} and my address is {ctx.agent.address}")
    
        # Send initial message to agent2
        initial_message = ChatMessage(
            timestamp=datetime.utcnow(),
            msg_id=uuid4(),
            content=[TextContent(type="text", text="I want to send query to tavily agent that Give me a list of latest agentic AI trends")]
        )
        await ctx.send(langgraph_agent_address, initial_message)
    
    # Message Handler - Process received messages and send acknowledgements
    @chat_proto.on_message(ChatMessage)
    async def handle_message(ctx: Context, sender: str, msg: ChatMessage):
        for item in msg.content:
            if isinstance(item, TextContent):
                # Log received message
                ctx.logger.info(f"Received message from {sender}: {item.text}")
                
                # Send acknowledgment
                ack = ChatAcknowledgement(
                    timestamp=datetime.utcnow(),
                    acknowledged_msg_id=msg.msg_id
                )
                await ctx.send(sender, ack)
                
    
    # Acknowledgement Handler - Process received acknowledgements
    @chat_proto.on_message(ChatAcknowledgement)
    async def handle_acknowledgement(ctx: Context, sender: str, msg: ChatAcknowledgement):
        ctx.logger.info(f"Received acknowledgement from {sender} for message: {msg.acknowledged_msg_id}")
    
    # Include the protocol in the agent to enable the chat functionality
    # This allows the agent to send/receive messages and handle acknowledgements using the chat protocol
    agent2.include(chat_proto, publish_manifest=True)
    
    if __name__ == '__main__':
        agent2.run()

Why Use LangGraph with uAgents?[](#why-use-langgraph-with-uagents)
------------------------------------------------------------------

LangGraph offers several advantages when combined with uAgents:

*   Advanced Orchestration: Create complex reasoning flows using directed graphs
*   State Management: Handle complex multi-turn conversations with state persistence
*   Tool Integration: Easily connect to external services and APIs
*   Debugging Capabilities: Inspect and debug agent reasoning processes

By wrapping LangGraph with the uAgents adapter, you get the best of both worlds: sophisticated LLM orchestration with the decentralized communication capabilities of uAgents.

Getting Started[](#getting-started)
-----------------------------------

1.  In a directory get both the agents above `agent.py` and `agent_client.py`.
    
2.  Install required packages:
    
        pip install uagents>=0.22.3 uagents-adapter>=0.2.1 langchain-openai>=0.3.14 langchain-community>=0.3.21 langgraph>=0.3.31  dotenv>=0.9.9
    
3.  Set up your environment variables in `.env` file:
    
        OPENAI_API_KEY=your_openai_key
        TAVILY_API_KEY=your_tavily_key  
        AGENTVERSE_API_KEY=your_agentverse_key
    
4.  Run the LangGraph agent:
    
5.  In a separate terminal, run the client agent:
    

Expected Outputs[](#expected-outputs)
-------------------------------------

When running the examples, you should expect to see outputs similar to these:

### LangGraph Agent[](#langgraph-agent)

When running the LangGraph agent:

    (venv) Fetchs-MacBook-Pro test examples % python3 agent.py 
    INFO:     [langgraph_tavily_agent]: Starting agent with address: agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t
    INFO:     [langgraph_tavily_agent]: Agent 'langgraph_tavily_agent' started with address: agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t
    INFO:     [langgraph_tavily_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8080&address=agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t
    INFO:     [langgraph_tavily_agent]: Starting server on http://0.0.0.0:8080 (Press CTRL+C to quit)
    INFO:     [langgraph_tavily_agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [langgraph_tavily_agent]: Mailbox access token acquired
    INFO:     [langgraph_tavily_agent]: Received structured output response from agent1qtlpfshtlcxekgrfcpmv7m9zpajuwu7d5jfyachvpa4u3dkt6k0uwwp2lct: Hello, Tavily Agent. Could you please provide a list of the latest trends in agentic AI? I am interested in understanding how agent-based artificial intelligence is evolving and what innovations or developments stand out in this field. Thank you!
    INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    ‚úÖ Registered LangGraph agent: Created uAgent 'langgraph_tavily_agent' with address agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t on port 8080
    INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:     [langgraph_tavily_agent]: Got a message from agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [langgraph_tavily_agent]: Got a text message from agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49: I want to send query to tavily agent that Give me a list of latest agentic AI trends
    INFO:     [langgraph_tavily_agent]: Sending structured output prompt to {'title': 'QueryMessage', 'type': 'object', 'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query']}
    INFO:     [langgraph_tavily_agent]: Sent structured output prompt to agent1qtlpfshtlcxekgrfcpmv7m9zpajuwu7d5jfyachvpa4u3dkt6k0uwwp2lct
    INFO:     [langgraph_tavily_agent]: Got an acknowledgement from agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49 for 451f41aa-be41-471f-bddc-276caffb7d94
    Connecting agent 'langgraph_tavily_agent' to Agentverse...
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    Successfully connected agent 'langgraph_tavily_agent' to Agentverse
    Updating agent 'langgraph_tavily_agent' README on Agentverse...
    Successfully updated agent 'langgraph_tavily_agent' README on Agentverse
    INFO:     [langgraph_tavily_agent]: Received structured output response from agent1qtlpfshtlcxekgrfcpmv7m9zpajuwu7d5jfyachvpa4u3dkt6k0uwwp2lct: Subject: Request for Information on Latest Agentic AI Trends
    
    Hi Tavily Agent,
    
    I hope this message finds you well. I am reaching out to inquire about the latest trends in agentic AI technology. As this area is rapidly evolving, I am keen to stay updated on the most recent developments and innovations.
    
    Could you please provide me with a comprehensive list of the latest trends in agentic AI? I'm particularly interested in understanding how these trends might impact various industries and potential future applications.
    
    Thank you for your assistance. I look forward to your response.
    ---
    INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"

### Client Agent[](#client-agent)

When running the client agent:

    (venv) Fetchs-MacBook-Pro test examples % python3 agent_client.py
    INFO:     [client_agent]: Starting agent with address: agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: My name is client_agent and my address is agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8082&address=agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: Starting server on http://0.0.0.0:8082 (Press CTRL+C to quit)
    INFO:     [client_agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Almanac contract registration is up to date!
    INFO:     [client_agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [client_agent]: Mailbox access token acquired
    INFO:     [client_agent]: Received message from agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t: Here are some of the latest trends in agentic AI:
    
    1. **The Next Frontier: The Rise of Agentic AI - Adams Street Partners**
       - **Link:** [The Next Frontier: The Rise of Agentic AI - Adams Street Partners](https://www.adamsstreetpartners.com/insights/the-next-frontier-the-rise-of-agentic-ai/)
       - **Summary:** Several converging trends have set the stage for agentic AI, including advances in Large Language Models, improved reasoning, planning, and multistep processes.
    
    2. **7 Agentic AI Trends To Watch for 2025 - ServiceNow**
       - **Link:** [7 Agentic AI Trends To Watch for 2025 - ServiceNow](https://www.servicenow.com/products/ai-agents/agentic-ai-trends.html)
       - **Summary:** Explore the latest agentic AI trends shaping the future of work, from hyperautomation to decision intelligence, and how it can transform businesses.
    
    3. **Agentic AI: Three themes to watch for 2025 - Constellation Research**
       - **Link:** [Agentic AI: Three themes to watch for 2025 - Constellation Research](https://www.constellationr.com/blog-news/insights/agentic-ai-three-themes-watch-2025)
       - **Summary:** This article discusses three themes to watch in agentic AI for 2025, including horizontal approaches vs. platform-specific strategies and the proliferation of agentic AI launches by various vendors.
    
    These sources provide insights into the evolving landscape of agentic AI and the key trends that are shaping the future of this field.
    INFO:     [client_agent]: Received acknowledgement from agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t for message: 1cdda4bd-4597-42a9-b6f1-13c6ca67a0ea
    INFO:     [client_agent]: Received message from agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t: ### Latest Trends in Agentic AI Technology:
    
    1. **[7 Agentic AI Trends To Watch for 2025 - ServiceNow](https://www.servicenow.com/products/ai-agents/agentic-ai-trends.html)**
       - Explore the latest agentic AI trends shaping the future of work, from hyperautomation to decision intelligence, and how it can transform your business.
    
    2. **[Agentic AI: Three themes to watch for 2025 - Constellation Research](https://www.constellationr.com/blog-news/insights/agentic-ai-three-themes-watch-2025)**
       - Three themes to watch in agentic AI, including horizontal approaches vs. platform-specific trends and the proliferation of agentic AI platforms across various vendors.
    
    3. **[The Top Customer Service Trends and Technologies for 2025](https://www.destinationcrm.com/Articles/Editorial/Magazine-Features/The-Top-Customer-Service-Trends-and-Technologies-for-2025-Agentic-AI-Is-Poised-to-Remake-Self-Service-168751.aspx)**
       - Agentic AI is poised to remake self-service in customer service, with predictions that by 2030, 50% of service requests will be initiated by machine customers powered by agentic AI systems.
    
    4. **[Future Trends in Agentic AI Development: What's Next for Intelligent Automation](https://www.imbrace.co/future-trends-in-agentic-ai-development-whats-next-for-intelligent-automation/)**
       - Trends include providing clear insights into decision-making, ensuring alignment with ethical guidelines, expanded applications across industries like logistics and healthcare, and the integration of Explainable AI (XAI).
    
    5. **[5 Reasons Why Agentic AI Will Transform Industries by 2030](https://hyperight.com/5-reasons-why-agentic-ai-will-transform-industries-by-2030/)**
       - Agentic AI is expected to enhance productivity and efficiency, reshape industries by 2030, and be incorporated into 33% of enterprise software applications by 2028.
    
    6. **[Agentic AI Trends - What to expect in the near future - Atera](https://www.atera.com/blog/agentic-ai-trends/)**
       - Agentic AI is set to revolutionize customer service, with researchers predicting a significant impact on customer service operations.
    
    These trends highlight the advancements and potential impacts of agentic AI technology across various industries and applications.

Try different queries to see how the LangGraph agent processes them and returns search-enhanced responses through the uAgents ecosystem!</content>
</page>

<page>
  <title>Utilize the PostgreSQL database with the Agent docs</title>
  <url>https://uagents.fetch.ai/docs/examples/postgres</url>
  <content>Introduction[](#introduction)
-----------------------------

In this documentation example, we demonstrate how to use the uAgent library to create agents that interact with PostgreSQL data within a Docker Compose setup. In this scenario, one agent handles the insertion of employee data into the PostgreSQL database, while another agent retrieves this data. This example illustrates the seamless integration between agents, PostgreSQL, and Docker, showcasing how to manage data flow and communication in a distributed system.

Project Structure[](#project-structure)
---------------------------------------

    .postgres-database-with-an-agent
    ‚îú‚îÄ‚îÄ docker-compose.yml
    ‚îú‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ README.md
    ‚îî‚îÄ‚îÄ src
        ‚îú‚îÄ‚îÄ constants.py
        ‚îú‚îÄ‚îÄ db
        ‚îÇ   ‚îú‚îÄ‚îÄ db_connection.py
        ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
        ‚îÇ   ‚îú‚îÄ‚îÄ models
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
        ‚îÇ   ‚îî‚îÄ‚îÄ schemas
        ‚îÇ       ‚îî‚îÄ‚îÄ employees.sql
        ‚îî‚îÄ‚îÄ main.py

Agent with PostgreSQL database[](#agent-with-postgresql-database)
-----------------------------------------------------------------

### Set up the PostgreSQL connection with Docker using Docker Compose[](#set-up-the-postgresql-connection-with-docker-using-docker-compose)

This section details the files involved in setting up the PostgreSQL connection within your project.

**`db_connection.py`**: Contains the functions to establish and close the connection to the PostgreSQL database using the psycopg2 library. The `create_connection` function connects to the database with provided credentials, while the `close_connection` function ensures the connection is safely terminated.

    import psycopg2
    from psycopg2 import OperationalError
     
    def create_connection(dbname, user, password, host="localhost", port="5432"):
        """
        Create a connection to the PostgreSQL database.
     
        :param dbname: Name of the database
        :param user: Database user
        :param password: User's password
        :param host: Database host
        :param port: Database port
        :return: Connection object or None if connection fails
        """
        try:
            conn = psycopg2.connect(
                dbname=dbname, user=user, password=password, host=host, port=port
            )
            print("Connection successful")
            return conn
        except OperationalError as error:
            print(f"Error connecting to PostgreSQL database: {error}")
            return None
     
    def close_connection(conn):
        if conn:
            conn.close()
            print("Connection closed")

**`docker-compose.yml`**: Configures the Docker services, including the PostgreSQL database and the application. It defines the environment variables for the database connection and maps the database schema from the host to the container.

    version: "3.8"
    services:
      db:
        container_name: postgres_container
        image: postgres
        restart: always
        environment:
          POSTGRES_USER: ${DB_USER}
          POSTGRES_PASSWORD: ${DB_PASSWORD}
          POSTGRES_DB: ${DB_NAME}
        volumes:
          - "postgres:/var/lib/postgresql/data"
          - ./src/db/schemas/employees.sql:/docker-entrypoint-initdb.d/employees.sql
        ports:
          - "5432:5432"
        networks:
          - agent_network
      app:
        build: ..
        container_name: poetry_app
        volumes:
          - .:/app
        ports:
          - "8000:8000"
        depends_on:
          - db
        networks:
          - agent_network
        environment:
          DB_USER: ${DB_USER}
          DB_PASSWORD: ${DB_PASSWORD}
          DB_NAME: ${DB_NAME}
        command: poetry run python ./src/main.py
     
    volumes:
      postgres:
     
    networks:
      agent_network:
        driver: bridge

**`Dockerfile`**: Builds the application container, installing dependencies via Poetry and setting up the environment to run the application. The container exposes port 8000 for the application service.

    FROM python:3.12-slim
    ENV PATH="$PATH:/root/.local/bin"
     
    RUN apt-get update && \
        apt-get install -y curl gcc && \
        curl -sSL https://install.python-poetry.org/ | python3 -
     
    WORKDIR /app
    ADD pyproject.toml poetry.lock /app/
    RUN poetry install
    ADD . /app
    EXPOSE 8000
     
    ENTRYPOINT ["poetry", "run"]
    CMD ["python", "main.py"]

### Defining the Employees Database Schema and Model[](#defining-the-employees-database-schema-and-model)

The `Employees` class defines a model representing employee data as a dictionary. The `GetEmployees` class represents a model used to request employee information, with a flag indicating whether a response is expected.

The `employees.sql` script defines a schema for an Employees table in a PostgreSQL database, if it doesn‚Äôt already exist. This table includes columns for employee ID, first name, last name, birth date, and salary.

    from uagents import Model
     
    class Employees(Model):
        employees_data: dict
     
    class GetEmployees(Model):
        reply_back: bool

employees.sql

    CREATE TABLE IF NOT EXISTS Employees (
        EmployeeID INT PRIMARY KEY,
        FirstName VARCHAR(50),
        LastName VARCHAR(50),
        BirthDate DATE,
        Salary DECIMAL(10, 2)
    );

### Postgres data with agent[](#postgres-data-with-agent)

This script sets up and runs two agents, `db_insert_agent` and `db_fetch_agent`, which interact with a PostgreSQL database to manage employee data. The agents use asynchronous event handling to fetch and insert employee information into the database.

#### Database Connection[](#database-connection)

*   The `create_connection` function is used to establish a connection to the PostgreSQL database using parameters defined in `db_params`.

#### Agents[](#agents)

*   **`db_insert_agent`**: Responsible for inserting employee data into the database.
*   **`db_fetch_agent`**: Responsible for fetching and reporting employee data from the database.

#### Event Handlers[](#event-handlers)

*   **`on_startup` (db\_fetch\_agent)**:
    
    *   Triggered when `db_fetch_agent` starts.
    *   Retrieves and logs the PostgreSQL database version.
    *   Sends employee data to `db_insert_agent` if the version retrieval is successful.
*   **`handle_employee_data` (db\_insert\_agent)**:
    
    *   Handles messages with employee data.
    *   Inserts the received employee data into the `Employees` table in the database.
*   **`fetch_all_employee_details` (db\_fetch\_agent)**:
    
    *   Handles messages requesting all employee details.
    *   Retrieves all employee records from the `Employees` table and logs the data.

#### Database Operations[](#database-operations)

*   **Fetching Database Version**: Uses the query `SELECT version();` to get the PostgreSQL version.
*   **Inserting Employee Data**: Executes an `INSERT` query to add employee records to the `Employees` table.
*   **Fetching Employee Details**: Executes a `SELECT * FROM Employees` query to retrieve all employee records.

#### Execution[](#execution)

*   Initializes a `Bureau` instance.
*   Adds both agents (`db_insert_agent` and `db_fetch_agent`) to the bureau.
*   Runs the bureau, which starts the agents and their event handlers.

#### Usage[](#usage)

1.  **Startup**: On startup, `db_fetch_agent` will log the database version and send employee data to `db_insert_agent`.
2.  **Inserting Data**: `db_insert_agent` will insert received employee data into the database.
3.  **Fetching Data**: `db_fetch_agent` will fetch and log all employee details upon request.

    from db.db_connection import create_connection
    from uagents import Agent, Context, Bureau
    from db.models.models import Employees, GetEmployees
    from constants import employees_data
    from constants import db_params, DB_FETCH_AGENT_ADDRESS
     
    def get_db_version():
        """
        Retrieves the PostgreSQL database version.
     
        :return: Database version string or None if retrieval fails
        """
        conn = create_connection(**db_params)
        if conn:
            try:
                cursor = conn.cursor()
                cursor.execute("SELECT version();")
                db_version = cursor.fetchone()
                cursor.close()
                return db_version
            except Exception as error:
                print(f"Error executing query: {error}")
                return None
     
    db_insert_agent = Agent(name="db_inserter", seed="db_inserter_seed_phrase")
    db_fetch_agent = Agent(name="db_fetcher", seed="db_fetcher_seed_phrase")
     
    DB_FETCH_AGENT_ADDRESS = DB_FETCH_AGENT_ADDRESS
     
    @db_fetch_agent.on_event("startup")
    async def on_startup(ctx: Context):
        """
        Event handler triggered on agent startup to fetch database version and send employee data.
     
        :param ctx: Context object for handling agent events
        """
        db_version = get_db_version()
        if db_version:
            ctx.logger.info(
                f"Hello, I'm agent {db_insert_agent.name} and my address is {db_insert_agent.address}. PostgreSQL database version: {db_version[0]}"
            )
            await ctx.send(DB_FETCH_AGENT_ADDRESS, Employees(employees_data=employees_data))
        else:
            ctx.logger.info(
                f"Hello, I'm agent {db_insert_agent.name} and my address is {db_insert_agent.address}. Could not retrieve the database version."
            )
     
    @db_insert_agent.on_message(model=Employees, replies=GetEmployees)
    async def handle_employee_data(ctx: Context, sender: str, msg: Employees):
        """
        Handler for inserting employee data into the database.
     
        :param ctx: Context object for handling agent events
        :param sender: Sender of the message
        :param msg: Message containing employee data
        """
        ctx.logger.info(f"Received request from {sender} {msg.dict()}")
        employee_data = msg.employees_data
        conn = create_connection(**db_params)
        if conn:
            try:
                cursor = conn.cursor()
                insert_query = """
                INSERT INTO Employees (EmployeeID, FirstName, LastName, BirthDate, Salary)
                VALUES (%s, %s, %s, TO_DATE(%s, 'DD-MM-YYYY'), %s)
                """
                cursor.execute(
                    insert_query,
                    (
                        employee_data["EmployeeID"],
                        employee_data["FirstName"],
                        employee_data["LastName"],
                        employee_data["BirthDate"],
                        employee_data["Salary"],
                    ),
                )
                REPLY_BACK = True
                conn.commit()
                cursor.close()
                ctx.logger.info(f"Inserted employee data: {employee_data}")
                await ctx.send(sender, GetEmployees(reply_back=REPLY_BACK))
            except Exception as error:
                ctx.logger.error(f"Error inserting employee data: {error}")
        else:
            ctx.logger.error("Could not connect to the database.")
     
    @db_fetch_agent.on_message(model=GetEmployees)
    async def fetch_all_employee_details(ctx: Context, sender: str, msg: GetEmployees):
        """
        Handler for fetching all employee details from the database.
     
        :param ctx: Context object for handling agent events
        :param sender: Sender of the message
        :param msg: Message triggering the fetch operation
        """
        if msg.reply_back:
            conn = create_connection(**db_params)
            if conn:
                try:
                    cursor = conn.cursor()
                    query = "SELECT * FROM Employees"
                    cursor.execute(query)
                    all_employees = cursor.fetchall()
                    cursor.close()
     
                    employees_list = []
                    for employee in all_employees:
                        employee_info = {
                            "EmployeeID": employee[0],
                            "FirstName": employee[1],
                            "LastName": employee[2],
                            "BirthDate": employee[3].strftime("%d-%m-%Y"),
                            "Salary": employee[4],
                        }
                        employees_list.append(employee_info)
                    ctx.logger.info(f"Retrieved all employee data: {employees_list}")
                except Exception as error:
                    ctx.logger.error(f"Error retrieving employee data: {error}")
            else:
                ctx.logger.error("Could not connect to the database.")
     
    bureau = Bureau()
    bureau.add(db_insert_agent)
    bureau.add(db_fetch_agent)
     
    if __name__ == "__main__":
        bureau.run()
     

This constant file initializes a dictionary for storing employee data and configures the database connection parameters using environment variables. It also defines a constant for the address of the database fetch agent.

    import os
     
    employees_data = {
        "EmployeeID": "",
        "FirstName": "",
        "LastName": "",
        "BirthDate": "",
        "Salary": 0,
    }
     
    db_params = {
        "dbname": os.getenv("DB_NAME"),
        "user": os.getenv("DB_USER"),
        "password": os.getenv("DB_PASSWORD"),
        "host": "db",
        "port": "5432",
    }
     
    DB_FETCH_AGENT_ADDRESS = (
        "agent1qwg0h3gx2kvqmwadlg0j4r258r7amcfskx2mudz92ztjmtfdclygxrh5esu"
    )
     

Poetry Dependencies[](#poetry-dependencies)
-------------------------------------------

pyproject.toml

    [tool.poetry.dependencies]
    python = "^3.10"
    psycopg2-binary = "^2.9.9"
    uagents = { version = "^0.13.0", python = ">=3.10,<3.13" }

How to Run This Example[](#how-to-run-this-example)
---------------------------------------------------

#### Update the Required environment variables[](#update-the-required-environment-variables)

.env.example

    DB_USER=
    DB_PASSWORD=
    DB_NAME=

#### Instructions to execute the example.[](#instructions-to-execute-the-example)

*   Navigate to the root Folder of Example.
*   Update the constant file with new entries to store in the database
*   Run `docker-compose build`
*   Run `docker-compose up`

Expected Output[](#expected-output)
-----------------------------------

    poetry_app | Connection successful
    poetry_app | INFO:     [db_fetcher]: Hello, I'm agent db_inserter and my address is agent1qwg0h3gx2kvqmwadlg0j4r258r7amcfskx2mudz92ztjmtfdclygxrh5esu. PostgreSQL database version: PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
    poetry_app | INFO:     [db_inserter]: Received request from agent1qv470qn3vfgn3dwe5z90m8u6qvtn6chrgm4urfzdg2v9qyagln6sgnh4wwg {'employees_data': {'EmployeeID': '0', 'FirstName': 'john', 'LastName': 'wick', 'BirthDate': '29-08-1999', 'Salary': 50000}}
    poetry_app | Connection successful
    poetry_app | INFO:     [db_inserter]: Inserted employee data: {'EmployeeID': '0', 'FirstName': 'john', 'LastName': 'wick', 'BirthDate': '29-08-1999', 'Salary': 50000}
    poetry_app | Connection successful
    poetry_app | INFO:     [db_fetcher]: Retrieved all employee data: [{'EmployeeID': 0, 'FirstName': 'john', 'LastName': 'wick', 'BirthDate': '29-08-1999', 'Salary': Decimal('50000.00')}]
    poetry_app | INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)</content>
</page>

<page>
  <title>Query Agents using proxy API docs</title>
  <url>https://uagents.fetch.ai/docs/examples/on_query_proxy</url>
  <content>Overview[](#overview)
---------------------

This file can be run on any platform supporting Python, with the necessary install permissions.

This example shows how to query an Agent using a proxy API.

### The Agent[](#the-agent)

     
    from uagents import Agent, Context, Model
     
     
    class TestRequest(Model):
        message: str
     
     
    class Response(Model):
        text: str
     
     
    agent = Agent(
        name="your_agent_name_here",
        seed="your_agent_seed_here",
        port=8001,
        endpoint="http://localhost:8001/submit",
    )
     
     
    @agent.on_event("startup")
    async def startup(ctx: Context):
        ctx.logger.info(f"Starting up {agent.name}")
        ctx.logger.info(f"With address: {agent.address}")
        ctx.logger.info(f"And wallet address: {agent.wallet.address()}")
     
     
    @agent.on_query(model=TestRequest, replies={Response})
    async def query_handler(ctx: Context, sender: str, _query: TestRequest):
        ctx.logger.info("Query received")
        try:
            # do something here
            await ctx.send(sender, Response(text="success"))
        except Exception:
            await ctx.send(sender, Response(text="fail"))
     
     
    if __name__ == "__main__":
        agent.run()
     

The Agent is created using the `Agent` class from `uagents` library. It is initialized with a `name`, `seed`, `port`, and `endpoint`. It defines an `on_event` handler for the `"startup"` event, where it logs information about the Agent‚Äôs initialization. It defines an `on_query` handler for handling queries of type `TestRequest`. Upon receiving a query, it processes it and sends back a `Response`. The Agent is then set to run. For additional information on Agents‚Äô handlers, check out this [resource](https://uagents.fetch.ai/docs/guides/handlers).

### Proxy[](#proxy)

    import json
     
    from fastapi import FastAPI, Request
     
    from uagents import Model
    from uagents.envelope import Envelope
    from uagents.query import query
     
    AGENT_ADDRESS = "address_of_your_agent_to_be_queried_here"
     
     
    class TestRequest(Model):
        message: str
     
     
    async def agent_query(req):
        response = await query(destination=AGENT_ADDRESS, message=req, timeout=15)
        if isinstance(response, Envelope):
            data = json.loads(response.decode_payload())
            return data["text"]
        return response
     
     
    app = FastAPI()
     
     
    @app.get("/")
    def read_root():
        return "Hello from the Agent controller"
     
     
    @app.post("/endpoint")
    async def make_agent_call(req: Request):
        model = TestRequest.parse_obj(await req.json())
        try:
            res = await agent_query(model)
            return f"successful call - agent response: {res}"
        except Exception:
            return "unsuccessful agent call"

The proxy is implemented using `FastAPI`. It sets up two routes: `"/"` for a simple root message and `"/endpoint"` for receiving requests. When a `POST` request is made to `"/endpoint"` with a JSON payload containing a `TestRequest`, it triggers the `make_agent_call` function. Inside `make_agent_call`, it calls `agent_query` to communicate with the Agent. The `agent` receives the query, processes it, and sends back a response. The proxy receives the response from the Agent and sends back a success message along with the response text.

#### Run the example[](#run-the-example)

In separate terminals:

1.  Run the FastAPI proxy: `uvicorn proxy:app`
    
2.  Run the agent: `python agent.py`
    
3.  Query the agent via the proxy: `curl -d '{"message": "test"}' -H "Content-Type: application/json" -X POST http://localhost:8000/endpoint`
    

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>React app with agents 'on_query' decorator docs</title>
  <url>https://uagents.fetch.ai/docs/examples/react-web</url>
  <content>Introduction[](#introduction)
-----------------------------

This example shows how to build a React application integrated with a flask backend, using various Agents to perform tasks such as fetching news, scrapping webpage data and also getting the sentiment of news using hugging face FinBERT model of [HF inference API](https://huggingface.co/docs/api-inference/en/index).

Please check out the example code in our [examples repo](https://github.com/fetchai/uAgent-Examples/tree/main/3-applications/react-web-with-flask-and-agents) to run this locally.

Pre-requisites[](#pre-requisites)
---------------------------------

*   **Node.js :** Download and install from [Node.js official website](https://nodejs.org/en).
*   **Python :** Download and install from [Python official website](https://www.python.org/downloads/).
*   **Flask :** Install via pip

    pip install Flask flask-cors

*   **React :** Setup a news project

    npx create-react-app finbert-news-sentiment-analysis
    cd finbert-news-sentiment-analysis
    npm start

Project Structure[](#project-structure)
---------------------------------------

Outline of basic structure of the project:

    finbert-news-sentiment-analysis/
    ‚îú‚îÄ‚îÄ frontend/
    ‚îÇ   ‚îú‚îÄ‚îÄ public/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
    ‚îÇ   ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NewsFeed.jsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SearchComponent.jsx
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SearchComponent.css
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.css
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js
    ‚îÇ   ‚îú‚îÄ‚îÄ package.json
    ‚îÇ   ‚îî‚îÄ‚îÄ package-lock.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ backend/
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py   # Flask application
    ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ agents/
    ‚îÇ       ‚îú‚îÄ‚îÄ news_agent.py  # Handles fetching news
    ‚îÇ       ‚îú‚îÄ‚îÄ scraper_agent.py  # Handles URL extraction
    ‚îÇ       ‚îî‚îÄ‚îÄ sentiment_agent.py  # Handles sentiment analysis
    ‚îÇ
    ‚îî‚îÄ‚îÄ README.md  # Project documentation
    

Backend Setup[](#backend-setup)
-------------------------------

In this section we will set up Agents and as well as flask app which will respond to different endpoints.

1.  Flask Application (‚Äòapp.py‚Äô):
    
    *   Define routes for fetching news\_urls, scrapping news content and get FinBERT sentiments.
    *   Utilize Agents to handle specific tasks.
    
        from flask import Flask
        from flask_cors import CORS
        from uagents.query import query
        from uagents import Model
        import json
         
        # Define Request Data Model classes for interacting with different agents
        class NewsRequest(Model):
            company_name: str
         
        class UrlRequest(Model):
            company_name: str
         
        class wrapRequest(Model):
            url : str
         
        class SentimentRequest(Model):
            news : str
         
        # Initialize Flask application
        app = Flask(__name__)
        CORS(app)  # Enables CORS for all domains on all routes
         
        # Define agent addresses
        news_agent_address = "agent1q2e9kfdrxfa5dxn6zeyw47287ca36cdur9xevhmdzzfmf4cwlmahv73mpev"
        news_content_agent_address = "agent1qvumqq9xju7musr82l6ulqsvgka7d7z77jvvdrkyyr7n5s0u0lfdvse6k4t"
        sentiment_agent_address = "agent1q2pm392d2uux3wjsydatd4zhagrtq0lrwfgw4s8pv4x0090sfzk9qpgztaz"
         
        @app.route('/')
        def home():
            return "Welcome to the Company Analyzer API!"
         
        # Define an asynchronous endpoint to get news for a given company
        @app.route('/api/news/<string:company_name>', methods=['GET'])
        async def get_news(company_name):
            response = await query(destination=news_agent_address, message=NewsRequest(company_name=company_name), timeout=15.0)
            data = json.loads(response.decode_payload())
            print(data)
            return data["news_list"]
         
        # Define an asynchronous endpoint to analyse sentiment for a given company
        @app.route('/api/sentiment/<string:company_name>', methods=['GET'])
        async def get_sentiment(company_name):
            urls = await query(destination=news_agent_address, message=UrlRequest(company_name=company_name), timeout=15.0)
            data = json.loads(urls.decode_payload())
            sentiments = []
            content_list = []
            sentiment_scores = {}
            url_list = data.get("url_list", [])
         
            # For each URL, query for content and perform sentiment analysis
            for url in url_list:
                content = await query(destination=news_content_agent_address, message=wrapRequest(url=url), timeout=15.0)
                news_summary = json.loads(content.decode_payload())
                summary_text = news_summary.get('summary', '')
                cleaned_text = summary_text.replace('\u00a0', ' ')
                if len(cleaned_text) > 100:
                    content_list.append(cleaned_text)
            for content in content_list:
                sentiment = await query(destination=sentiment_agent_address, message=SentimentRequest(news=content), timeout=15.0)
                data = json.loads(sentiment.decode_payload())
                sentiment = data.get("sentiment", [])
                sentiments.append(sentiment)
            for sentiment in sentiments:
                label,score = sentiment.split(',')
                score = float(score)
                if label in sentiment_scores:
                    sentiment_scores[label].append(score)
                else:
                    sentiment_scores[label] = [score]
                sentiment_means = {label: sum(scores) / len(scores) for label, scores in sentiment_scores.items() if scores}
         
            # Calculate average sentiment scores and determine the predominant sentiment
            if sentiment_means:
                max_sentiment = max(sentiment_means, key=sentiment_means.get)
                final_sentiment = str(max_sentiment) + ' : ' +str(round(sentiment_means[max_sentiment],2))
                return final_sentiment
            else:
                return None, None
         
        # Start the Flask application in debug mode
        if __name__ == '__main__':
            app.run(debug=True)
    
2.  Agents:
    
    *   **News and URL agent:** Fetches news articles titles and url for them as well.

    # Import Required libraries
    import requests
    import os
    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
     
    # Define Request and Response Models
    class NewsRequest(Model):
        company_name: str
     
    class UrlRequest(Model):
        company_name: str
     
    class NewsResponse(Model):
        news_list : list
     
    class UrlResponse(Model):
        url_list: list
     
    class ErrorResponse(Model):
        error : str
     
    ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')
    GNEWS_API_KEY = os.getenv('GNEWS_API_KEY')
     
    # Define function to get ticker symbol for given company name
    async def fetch_symbol(company_name):
        url = f"https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords={company_name}&apikey={ALPHA_VANTAGE_API_KEY}"
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            # Typically, the best match will be the first item in the bestMatches list
            if data.get('bestMatches') and len(data['bestMatches']) > 0:
                Symbol = data['bestMatches'][0]['1. symbol'] # Return the symbol of the best match
                return Symbol
            else:
                return 'No Symbol found'
        else:
            return 'No Symbol found'
     
    async def fetch_news(company_name): # get news urls and description for the given news company or ticker
        url = f"https://gnews.io/api/v4/search?q={company_name}&token={GNEWS_API_KEY}&lang=en"
        response = requests.get(url)
        articles = response.json().get('articles', [])
        # Return a list of titles and descriptions with hyperlinks
        news_list = []
        for article in articles:
            article_url = article.get('url', 'No url')
            description = article.get("description", "No Description")
            # Create a hyperlink using HTML anchor tag
            hyperlink = {"url": article_url,
                         "title": description}
            news_list.append(hyperlink)
        return news_list
     
    async def fetch_url(company_name): # Get the news url's for given company name or symbol
        url = f"https://gnews.io/api/v4/search?q={company_name}&token={GNEWS_API_KEY}&lang=en"
        response = requests.get(url)
        articles = response.json().get('articles', [])
        # Return a list of titles and descriptions with hyperlinks
        url_list = []
        for article in articles:
            article_url = article.get('url', 'No url')
            url_list.append(article_url)
        return url_list
     
    # Define News Agent
    NewsAgent = Agent(
        name="NewsAgent",
        port=8000,
        seed="News Agent secret phrase",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     
    # Registering agent on Almanac and funding it.
    fund_agent_if_low(NewsAgent.wallet.address())
     
    # On agent startup printing address
    @NewsAgent.on_event('startup')
    async def agent_details(ctx: Context):
        ctx.logger.info(f'Search Agent Address is {NewsAgent.address}')
     
    # On_query handler for news request
    @NewsAgent.on_query(model=NewsRequest, replies={NewsResponse})
    async def query_handler(ctx: Context, sender: str, msg: NewsRequest):
        try:
            ctx.logger.info(f'Fetching news details for company_name: {msg.company_name}')
            symbol = await fetch_symbol(msg.company_name)
            ctx.logger.info(f' Symbol for company provided is {symbol}')
            if symbol  != None: #if company symbol fetch successfully getting news using ticker symbol else using the company name itself.
                news_list = await fetch_news(symbol)
            else:
                news_list = await fetch_news(msg.company_name)
                ctx.logger.info(str(news_list))
            await ctx.send(sender, NewsResponse(news_list=news_list))
     
        except Exception as e:
            error_message = f"Error fetching job details: {str(e)}"
            ctx.logger.error(error_message)
            # Ensure the error message is sent as a string
            await ctx.send(sender, ErrorResponse(error=str(error_message)))
     
    # On_query handler for news_url request
    @NewsAgent.on_query(model=UrlRequest, replies={UrlResponse})
    async def query_handler(ctx: Context, sender: str, msg: UrlRequest):
        try:
            ctx.logger.info(f'Fetching news url details for company_name: {msg.company_name}')
            symbol = await fetch_symbol(msg.company_name)
            ctx.logger.info(f' Symbol for company provided is {symbol}')
            if symbol  != None:
                url_list = await fetch_url(symbol)
            else:
                url_list = await fetch_url(msg.company_name)
            ctx.logger.info(str(url_list))
            await ctx.send(sender, UrlResponse(url_list=url_list))
        except Exception as e:
            error_message = f"Error fetching job details: {str(e)}"
            ctx.logger.error(error_message)
            # Ensure the error message is sent as a string
            await ctx.send(sender, ErrorResponse(error=str(error_message)))
     
    if __name__ == "__main__":
        NewsAgent.run() 

‚ÑπÔ∏è

Get your [Alphavantage](https://www.alphavantage.co/) and [Gnews](https://gnews.io/) API keys and update it in the virtual environment.

*   **WebScraper Agent:** Scraps the webpage content for the given URL.

    # Import Required libraries
    import requests
    import aiohttp
    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
    from bs4 import BeautifulSoup
    import time
     
    # Define data Models to handle request
    class wrapRequest(Model):
        url : str
     
    class Message(Model):
        message : str
     
    class wrapResponse(Model):
        summary : str
     
    class ErrorResponse(Model):
        error : str
     
    # Define webscraper Agent
    webScraperAgent = Agent(
        name="Web Scraper Agent",
        port=8001,
        seed="Web Scraper Agent secret phrase",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    # Define function to scrap webpage and get paragraph content.
    async def get_webpage_content(url):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        response_text = await response.text()
                        soup = BeautifulSoup(response_text, 'html.parser')
     
                        for script_or_style in soup(["script", "style", "header", "footer", "nav", "aside"]):
                            script_or_style.decompose()
     
                        text_blocks = soup.find_all('p')
                        text_content = ' '.join(block.get_text(strip=True) for block in text_blocks if block.get_text(strip=True))
     
                        words = text_content.split()
                        limited_text = ' '.join(words[:500])  # Limit to first 500 words for faster response of sentiment agent.
                        return limited_text
                    else:
                        return "Error: Unable to fetch content."
        except Exception as e:
            return f"Error encountered: {str(e)}"
     
    # On agent startup printing address
    @webScraperAgent.on_event('startup')
    async def agent_details(ctx: Context):
        ctx.logger.info(f'Search Agent Address is {webScraperAgent.address}')
     
    # On_query handler to handle webpage wrapping
    @webScraperAgent.on_query(model=wrapRequest, replies={wrapResponse})
    async def query_handler(ctx: Context, sender: str, msg: wrapRequest):
        try:
            ctx.logger.info(f'URL wrapper for request : {msg.url}')
            news_content = await get_webpage_content(msg.url)
            ctx.logger.info(news_content)
            if "Error" not in news_content:
                await ctx.send(sender, wrapResponse(summary = news_content))
            else:
                await ctx.send(sender, ErrorResponse(error = "ERROR" + news_content))
        except Exception as e:
            error_message = f"Error fetching job details: {str(e)}"
            ctx.logger.error(error_message)
            # Ensure the error message is sent as a string
            await ctx.send(sender, ErrorResponse(error=str(error_message)))
     
    if __name__ == "__main__":
        webScraperAgent.run()

*   **Sentiment Agent:** Provides sentiment of news content provided using HF API and FinBERT model.

    # Import Required libraries
    import requests
    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
    import time
    import asyncio
    import aiohttp
    import json
     
    # Define Request and Response Data Models
    class SentimentRequest(Model):
        news : str
     
    class SentimentResponse(Model):
        sentiment : str
     
    class ErrorResponse(Model):
        error : str
     
    # Define Sentiment analysis Agent
    SentimentAgent = Agent(
        name="Sentiment Agent",
        port=8002,
        seed="Sentiment Agent secret phrase",
        endpoint=["http://127.0.0.1:8002/submit"],
    )
     
    # Registering agent on Almanac and funding it.
    fund_agent_if_low(SentimentAgent.wallet.address())
     
    # Define function to provide sentiment for given content
    async def sentiment_analysis(news):
        API_URL = "https://api-inference.huggingface.co/models/ProsusAI/finbert"
        headers = {"Authorization": "Bearer <Hugging face API>"}
     
        payload = {"inputs": news}
     
        async with aiohttp.ClientSession() as session:
            async with session.post(API_URL, headers=headers, json=payload) as response:
                if response.status == 200:
                    sentiments = await response.json()
                    await asyncio.sleep(5)  # Proper async sleep
                    # Flatten the list of dicts to a single list
                    flattened_sentiments = [item for sublist in sentiments for item in sublist]
                    max_sentiment = max(flattened_sentiments, key=lambda s: s['score'])
                    max_label = str(max_sentiment['label'])
                    max_score = str(round(max_sentiment['score'], 3))
                    return f"{max_label},{max_score}"
                else:
                    return "Error: Failed to fetch data from API"
     
    # On agent startup printing address
    @SentimentAgent.on_event('startup')
    async def agent_details(ctx: Context):
        ctx.logger.info(f'Search Agent Address is {SentimentAgent.address}')
     
    # On_query handler for processing sentiment request
    @SentimentAgent.on_query(model=SentimentRequest, replies={SentimentResponse})
    async def query_handler(ctx: Context, sender: str, msg: SentimentRequest):
        try:
            sentiment = await sentiment_analysis(msg.news)
            if sentiment == "Error: Failed to fetch data from API":
                sentiment = await sentiment_analysis(msg.news[:500]) # if model is not ale to perform sentiment request we will just take string with 500 characters
                ctx.logger.info(msg.news[:300])
            ctx.logger.info(sentiment)
            await ctx.send(sender, SentimentResponse(sentiment = sentiment))
        except Exception as e:
            error_message = f"Error fetching job details: {str(e)}"
            ctx.logger.error(error_message)
            # Ensure the error message is sent as a string
            await ctx.send(sender, ErrorResponse(error=str(error_message)))
     
    if __name__ == "__main__":
        SentimentAgent.run()

3.  requirements.txt:
    
        aiohttp==3.9.5
        aiosignal==1.3.1
        beautifulsoup4==4.12.3
        bs4==0.0.2
        cosmpy==0.9.2
        grpcio==1.63.0
        jsonschema==4.22.0
        msgpack==1.0.8
        multidict==6.0.5
        packaging==24.0
        requests==2.31.0
        uagents==0.11.1
        urllib3==2.2.1
        uvicorn==0.20.0
        websockets==10.4
        yarl==1.9.4
    
    *   Activate virtual environment using `source venv/bin/activate`.
    *   Install libraries using `pip install -r requirements.txt` in your terminal.

Frontend Setup[](#frontend-setup)
---------------------------------

1.  Components:
    
    *   `NewsFeed.jsx`:
    
        import React from 'react';
         
        function NewsFeed({ news }) {
            return (
                <div className="news-feed">
                    <h2>News Titles</h2>
                    {news.length > 0 ? (
                        <ul>
                            {news.map((item, index) => (
                            <li key={index}>
                                <a href={item.url} target="_blank" rel="noopener noreferrer">{item.title}</a>
                                </li>
                                ))}
                        </ul>
                    ) : (
                        <p>No news found.</p>
                    )}
                </div>
                );
                }
        export default NewsFeed;
    
    *   `SearchComponent.jsx`:
    
        import React, { useState } from 'react';
        import './SearchComponent.css'; // Importing CSS for styling
        
        function SearchComponent({ onSearch }) {
            const [searchTerm, setSearchTerm] = useState('');
            const handleSubmit = (event) => {
            event.preventDefault();
            onSearch(searchTerm); // This function would be passed down from the parent component or defined here to handle the search logic
            };
        
            return (
                <div className="search-area">
                    <form onSubmit={handleSubmit}>
                        <input 
                            type="text" 
                            placeholder="Enter Company Name" 
                            value={searchTerm} 
                            onChange={(e) => setSearchTerm(e.target.value)} 
                        />
                        <button type="submit">Search</button>
                    </form>
                </div>
            );
            }
        export default SearchComponent;
        
    
    *   `SearchComponent.css`:
    
            .search-area {
                display: flex;
                justify-content: center;
                align-items: center;
                height: 100px; /* Approx 1 inch */
                background-color: #007BFF; /* Blue background */
                }
        
            .search-area form {
                display: flex;
                gap: 20px;
                }
        
            .search-area input {
                padding: 8px;
                border-radius: 4px;
                border: 1px solid #ccc;
                }
        
            .search-area button {
                background-color: #0056b3;
                color: white;
                border: none;
                border-radius: 4px;
                padding: 8px 16px;
                cursor: pointer;
                }
        
            .search-area button:hover {
                background-color: #004494;
                }
    
2.  `app.css`:
    
            .App {
                text-align: center;
                }
        
            .search-container, .news-feed, .stock-info {
                margin: 20px;
                padding: 10px;
                }
        
            input[type="text"] {
                margin-right: 10px;
                }
        
            .news-feed div {
                margin: 5px;
                }
        
            button {
                background-color: red;
                color: white;
                border: none;
                padding: 10px 20px;
                cursor: pointer;
                }
        
            button:hover {
                opacity: 0.8;
                }
        
            .news-feed {
                margin-top: 20px;
                padding: 10px;
                background-color: #f4f4f4;
                border-radius: 5px;
                color: black;
                text-decoration: none;
                }
        
            .news-feed a:hover {
                color: black; 
                text-decoration: underline;
                } 
        
            .news-feed ul {
                list-style-type: none;
                padding: 0;
                }
        
            .news-feed li {
                margin-bottom: 10px;
                padding: 5px;
                background-color: #fff;
                border-radius: 4px;
                color: black; /* Black color for text */
                text-align: left;
                }
        
            .sentiment-block {
                margin-top: 30px;
                padding: 10px;
                background-color: #dff0d8; 
                color: #3c763d; 
                border-radius: 5px;
                font-size: 20px;
                text-align: center;
                }
        
            .sentiment-block.neutral {
                background-color: #fcf8e3;
                color: #8a6d3b; 
                }
        
            .sentiment-block.negative {
                background-color: #f2dede; 
                color: #a94442; 
                }
        
            .title-bar {
                background-color: #007BFF; 
                color: white;
                padding: 10px 0;
                font-size: 24px;
                }
    
3.  `app.js`:
    
            // Import necessary React libraries and components
            import React, { useState } from 'react';
            import SearchComponent from './components/SearchComponent';
            import NewsFeed from './components/NewsFeed';
            import './App.css';  // Import CSS for styling
        
            // Define the main React functional component
            function App() {
              // State hooks to manage news data, sentiment, and type of sentiment
              const [news, setNews] = useState([]);
              const [sentiment, setSentiment] = useState('');
              const [sentimentType, setSentimentType] = useState('');
        
              // Function to handle search operations
              const handleSearch = async (searchTerm) => {
                try {
                  // API request to fetch news based on a search term
                  const newsResponse = await fetch(`http://127.0.0.1:5000/api/news/${searchTerm}`);
                  const newsData = await newsResponse.json();  // Convert response to JSON
                  setNews(newsData);  // Update the news state
                  console.log('Fetched news:', newsData);  // Log the fetched news data
        
                  // API request to fetch sentiment analysis for the search term
                  const sentimentResponse = await fetch(`http://127.0.0.1:5000/api/sentiment/${searchTerm}`);
                  const sentimentData = await sentimentResponse.text();  // Get response as text
                  console.log('Fetched sentiment:', sentimentData);  // Log the fetched sentiment
                  processSentiment(sentimentData);  // Process the fetched sentiment text
                } catch (error) {
                  console.error('Failed to fetch data:', error);  // Log any errors
                  setNews([]);  // Reset news state on error
                  setSentiment('');  // Reset sentiment state on error
                  setSentimentType('');  // Reset sentiment type state on error
                }
              };
        
              // Helper function to process the sentiment text and update state
              const processSentiment = (sentimentText) => {
                const parts = sentimentText.split(':');  // Split sentiment text by colon
                const sentimentValue = parts[0].trim().toLowerCase();  // Extract sentiment label and normalize it
                setSentiment(sentimentText);  // Update sentiment state
                setSentimentType(sentimentValue);  // Update sentiment type state
              };
        
              // Render the application UI
              return (
                <div className="App">
                  <SearchComponent onSearch={handleSearch} />  // Search component with search handler
                  <NewsFeed news={news} />  // News feed component to display news
                  {sentiment && <div className={`sentiment-block ${sentimentType}`}>{sentiment}</div>}  // Conditionally render sentiment block
                </div>
              );
            }
        
            export default App;  // Export the App component for use in other parts of the application
    

Setup and Running the application[](#setup-and-running-the-application)
-----------------------------------------------------------------------

### Backend Setup (Flask and Agents)[](#backend-setup-flask-and-agents)

1.  Setup virtual environment:
    
    *   Navigate to your project‚Äôs backend directory:
    
    *   Create a virtual environment:
    
    *   Activate the virtual environment:
    
        # For Windows
        venv\Scripts\activate
        # For MacOS/Linux
        source venv/bin/activate
    
2.  Install Dependencies:
    
    *   Ensure `requirements.txt` is in the backend directory and contains all the necessary packages.
    *   Install the required packages:
    
        pip install -r requirements.txt
    
3.  Start the Flask Application:
    
    *   Make sure the Flask app (`app.py`) is configured correctly with routes and agent interactions.
    *   Run the Flask app:
4.  Run the Agents:
    
    *   Ensure each agent script (e.g., `news_agent.py`, `scraper_agent.py`, `sentiment_agent.py`) is ready and configured.
    *   Start each agent in a separate terminal or command prompt to handle specific tasks:
    
        python news_agent.py
        python scraper_agent.py
        python sentiment_agent.py
    

### Frontend Setup (React)[](#frontend-setup-react)

1.  Navigate to the Frontend Directory:
    
    *   Change into your project‚Äôs frontend directory where the React app is located.
2.  Install Dependencies:
    
    *   Install the required node modules specified in `package.json`:
3.  Start the React Development Server:
    
    *   Run the following command to start the React development server:
    
    *   This typically starts the React application on `http://localhost:3000`.

### Accessing the Application[](#accessing-the-application)

*   Open your web browser and go to `http://localhost:3000`. You should see your React application‚Äôs interface.
*   Use the search component to input a company name and fetch news and sentiment data, which will be displayed accordingly.

Last updated on

July 1, 2025

[Introduction](https://uagents.fetch.ai/docs "Introduction")</content>
</page>

<page>
  <title>Integration of uAgents with Anthropic's Computer Use Demo docs</title>
  <url>https://uagents.fetch.ai/docs/examples/anthropic</url>
  <content>This guide demonstrates how to integrate the uAgents library with **Anthropic**‚Äôs computer use demo. By combining the capabilities of [Agents](https://uagents.fetch.ai/docs/quickstart) with Anthropic‚Äôs advanced computer-use features, you can create an intelligent Agent system that handles real-time messages and executes tasks within a controlled environment. This integration offers an easy way to simulate user-agent interactions and enhance your application with advanced AI functionalities while ensuring safety and control over internet interactions.

Let‚Äôs get started!

### Supporting documentation[](#supporting-documentation)

### Set Up the Agent to Handle Incoming Messages[](#set-up-the-agent-to-handle-incoming-messages)

The Agent‚Äôs backend will already be set up with a REST API endpoint that listens to incoming POST requests at `/rendering_messages`. This handler will receive the message from the Streamlit app and perform the necessary actions.

Here‚Äôs an example of how the `receiver_agent` REST handler (`/rendering_messages`) might look:

    import logging
    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
    from computer_use_demo.streamlit import _render_message
    import requests
     
    # Logging setup
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
     
    # Define the request and response models
    class Request(Model):
        text: str
     
    class Response(Model):
        text: str
     
    # Initialize the receiver agent
    receiver_agent = Agent(
        name="receiver_agent",
        seed="receiver_agent recovery phrase",
        port=8000,
        endpoint="https://localhost:8000/submit"
    )
     
    # Fund the agent if the balance is low
    fund_agent_if_low(receiver_agent.wallet.address())
     
    # Log the agent's address for reference
    logging.info(f"Receiver Agent Address: {receiver_agent.address}")
     
    # Define the POST request handler for rendering messages
    @receiver_agent.on_rest_post("/rendering_messages", Request, Response)
    async def handle_post(ctx: Context, req: Request) -> Response:
        logging.info(f"Received message by agent : {receiver_agent.address} from user: {req.text}")
     
        # Process the message and render it
        if req.text:
            logging.info(f"Rendering message: {req.text}")
            _render_message(Sender.USER, req.text)  # Assuming this renders the message (UI/logic)
     
        return Response(text=f"Received and processed message: {req.text}")
     
    # Run the receiver agent
    if __name__ == "__main__":
        receiver_agent.run()
     

### Explanation of the Agent Backend[](#explanation-of-the-agent-backend)

*   **Request and Response Models**: the `Request` model captures the message text, while the `Response` model defines the message that will be sent back to Streamlit.
*   **POST Endpoint**: The `@receiver_agent.on_rest_post("/rendering_messages", Request, Response)` decorator listens for POST requests and processes the incoming messages.
*   **Message Processing**: The incoming message is logged, processed (through `_render_message()`), and a response is sent back, acknowledging the message.

### Rendering Messages in Streamlit[](#rendering-messages-in-streamlit)

The `_render_message` function takes a message from the user or the agent and renders it in Streamlit‚Äôs chat interface. It handles different message types such as plain text, tool results, and errors.

    def _render_message(
        sender: Sender,
        message: str | BetaContentBlockParam | ToolResult,
    ):
        """Convert input from the user or output from the agent to a streamlit message."""
        # streamlit's hotreloading breaks isinstance checks, so we need to check for class names
        is_tool_result = not isinstance(message, str | dict)
        if not message or (
            is_tool_result
            and st.session_state.hide_images
            and not hasattr(message, "error")
            and not hasattr(message, "output")
        ):
            return
        with st.chat_message(sender):
            if is_tool_result:
                message = cast(ToolResult, message)
                if message.output:
                    if message.__class__.__name__ == "CLIResult":
                        st.code(message.output)
                    else:
                        st.markdown(message.output)
                if message.error:
                    st.error(message.error)
                if message.base64_image and not st.session_state.hide_images:
                    st.image(base64.b64decode(message.base64_image))
            elif isinstance(message, dict):
                if message["type"] == "text":
                    st.write(message["text"])
                elif message["type"] == "tool_use":
                    st.code(f'Tool Use: {message["name"]}\nInput: {message["input"]}')
                else:
                    # only expected return types are text and tool_use
                    raise Exception(f'Unexpected response type {message["type"]}')
            else:
                st.markdown(message)

Streamlit AI Assistant Interface[](#streamlit-ai-assistant-interface)
---------------------------------------------------------------------

This code sets up a **Streamlit interface** for interacting with a computer using various AI providers such as Anthropic, AWS Bedrock, and Google Vertex. The application enables sending messages to a virtual assistant, logging interactions, and using tools to control the system. Below are the key components of the setup:

### 1\. State Management (`setup_state`)[](#1-state-management-setup_state)

The `setup_state` function initializes the session state, such as storing API keys, model names, tool states, and user settings (e.g., how many recent images to send, custom system prompts, etc.).

### 2\. API Key Handling[](#2-api-key-handling)

The API key for authentication with AI services is either loaded from a file or environment variable (e.g., `ANTHROPIC_API_KEY`).

Get your anthropic API key from here [API KEY](https://console.anthropic.com/login?returnTo=%2F%3F).

### 3\. UI Components[](#3-ui-components)

The sidebar allows users to:

*   Select the API provider.
*   Input the model name.
*   Enter an API key.
*   Manage settings like the number of images sent or hide screenshots.

The main area displays the chat interface where users can:

*   Type messages.
*   Receive responses from the assistant.
*   View logs of HTTP exchanges and tool outputs.

### 4\. Asynchronous Processing (`initializing_messages`)[](#4-asynchronous-processing-initializing_messages)

The `initializing_messages` function handles user interactions. It processes new messages by appending them to the session state and sends them to the server for processing. The BOT‚Äôs response is retrieved and displayed using the `sampling_loop`.

#### Sending Messages to uagents via REST[](#sending-messages-to-uagents-via-rest)

This part of the code sends user messages from Streamlit to the uAgents Framework via a REST API. When a new message is provided, it is sent as a `POST` request to the `/rendering_messages` endpoint of the Agent‚Äôs backend.

    if new_message:
        data = {"text": new_message}
        response = requests.post("http://localhost:8000/rendering_messages", json=data)
        if response.status_code == 200:
            logging.info("Success:", response.json())
        else:
            logging.error("Failed:", response.status_code, response.text)

### 5\. API Call Handling (`_api_response_callback`)[](#5-api-call-handling-_api_response_callback)

This function stores the API response and displays it in the HTTP logs. It handles errors, such as rate-limiting, and formats the response for better readability.

### 6\. Error Handling (`_render_error`)[](#6-error-handling-_render_error)

Errors are captured and displayed, including rate-limiting errors, and detailed stack traces are shown in the UI for debugging.

### 7\. Tool Outputs and Message Rendering (`_tool_output_callback`, `_render_message`)[](#7-tool-outputs-and-message-rendering-_tool_output_callback-_render_message)

The system processes tool outputs (e.g., from external APIs or actions) and renders them in the chat interface.

### 8\. Authentication (`validate_auth`)[](#8-authentication-validate_auth)

This function validates the provided credentials for each API provider (e.g., checking if the AWS or Google Cloud credentials are set up for Bedrock and Vertex).

### 9\. File Operations (`load_from_storage`, `save_to_storage`)[](#9-file-operations-load_from_storage-save_to_storage)

Functions for loading and saving configuration data (like the API key or custom system prompts) to a file in the storage directory.

### 10\. UI Layout[](#10-ui-layout)

The app uses Streamlit‚Äôs layout components like:

*   `st.radio`
*   `st.text_input`
*   `st.chat_input`

These components build an interactive interface, dynamically updating the UI based on user input and the assistant‚Äôs responses.

EntryPoint for Streamlit
------------------------

This file is the entry point for running the Streamlit app. It serves as a user interface for interacting with the `Claude Computer Use Demo`.

Code Overview[](#code-overview)
-------------------------------

The application uses Streamlit, `httpx`, and `requests` to create an interactive UI where agent can communicate with the bot, view the HTTP exchange logs, and control a computer via various APIs.

    """
    Entrypoint for streamlit, see https://docs.streamlit.io/
    """
     
    import asyncio
    import base64
    import os
    import subprocess
    import traceback
    from datetime import datetime, timedelta
    from enum import StrEnum
    from functools import partial
    from pathlib import PosixPath
    from typing import cast
    from uagents import Model
    import requests
     
    from uagents import Agent, Context, Model
     
    import httpx
    import streamlit as st
    from anthropic import RateLimitError
    from anthropic.types.beta import (
        BetaContentBlockParam,
        BetaTextBlockParam,
    )
    from streamlit.delta_generator import DeltaGenerator
     
    from computer_use_demo.loop import (
        PROVIDER_TO_DEFAULT_MODEL_NAME,
        APIProvider,
        sampling_loop,
    )
    from computer_use_demo.tools import ToolResult
    import logging
     
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )
     
    CONFIG_DIR = PosixPath("~/.anthropic").expanduser()
    API_KEY_FILE = CONFIG_DIR / "api_key"
    STREAMLIT_STYLE = """
    <style>
        /* Hide chat input while agent loop is running */
        .stApp[data-teststate=running] .stChatInput textarea,
        .stApp[data-test-script-state=running] .stChatInput textarea {
            display: none;
        }
         /* Hide the streamlit deploy button */
        .stAppDeployButton {
            visibility: hidden;
        }
    </style>
    """
     
    WARNING_TEXT = "‚ö†Ô∏è Security Alert: Never provide access to sensitive accounts or data, as malicious web content can hijack Claude's behavior"
     
    class Sender(StrEnum):
        USER = "user"
        BOT = "assistant"
        TOOL = "tool"
     
    class Request(Model):
        text: str
     
    class Response(Model):
        text: str
     
    def setup_state():
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "api_key" not in st.session_state:
            # Try to load API key from file first, then environment
            st.session_state.api_key = load_from_storage("api_key") or os.getenv(
                "ANTHROPIC_API_KEY", ""
            )
        if "provider" not in st.session_state:
            st.session_state.provider = (
                os.getenv("API_PROVIDER", "anthropic") or APIProvider.ANTHROPIC
            )
        if "provider_radio" not in st.session_state:
            st.session_state.provider_radio = st.session_state.provider
        if "model" not in st.session_state:
            _reset_model()
        if "auth_validated" not in st.session_state:
            st.session_state.auth_validated = False
        if "responses" not in st.session_state:
            st.session_state.responses = {}
        if "tools" not in st.session_state:
            st.session_state.tools = {}
        if "only_n_most_recent_images" not in st.session_state:
            st.session_state.only_n_most_recent_images = 10
        if "custom_system_prompt" not in st.session_state:
            st.session_state.custom_system_prompt = load_from_storage("system_prompt") or ""
        if "hide_images" not in st.session_state:
            st.session_state.hide_images = False
     
    def _reset_model():
        st.session_state.model = PROVIDER_TO_DEFAULT_MODEL_NAME[
            cast(APIProvider, st.session_state.provider)
        ]
     
    async def initializing_messages(st, new_message):
        chat, http_logs = st.tabs(["Chat", "HTTP Exchange Logs"])
        # Render past chats
        with chat:
            for message in st.session_state.messages:
                if isinstance(message["content"], str):
                    _render_message(message["role"], message["content"])
                elif isinstance(message["content"], list):
                    for block in message["content"]:
                        # The tool result we send back to the Anthropic API isn't sufficient to render all details,
                        # so we store the tool use responses
                        if isinstance(block, dict) and block["type"] == "tool_result":
                            _render_message(
                                Sender.TOOL, st.session_state.tools[block["tool_use_id"]]
                            )
                        else:
                            _render_message(
                                message["role"],
                                cast(BetaContentBlockParam | ToolResult, block),
                            )
     
            # Render past HTTP exchanges
            for identity, (request, response) in st.session_state.responses.items():
                _render_api_response(request, response, identity, http_logs)
     
            # Process new message
            if new_message:
                st.session_state.messages.append(
                    {
                        "role": Sender.USER,
                        "content": [BetaTextBlockParam(type="text", text=new_message)],
                    }
                )
                data = {"text": new_message}
     
                logging.info(f"new_message {new_message}")
                response = requests.post("http://localhost:8000/rendering_messages", json=data)
     
                if response.status_code == 200:
                    logging.info("Success:", response.json())
                else:
                    logging.info("Failed:", response.status_code, response.text)
     
                logging.info(f"User message logged: {new_message}")
     
            try:
                most_recent_message = st.session_state["messages"][-1]
            except IndexError:
                return
     
            if most_recent_message["role"] is not Sender.USER:
                # We don't have a user message to respond to, exit early
                return
     
            with st.spinner("Running Agent..."):
                # Run the agent sampling loop with the newest message
                st.session_state.messages = await sampling_loop(
                    system_prompt_suffix=st.session_state.custom_system_prompt,
                    model=st.session_state.model,
                    provider=st.session_state.provider,
                    messages=st.session_state.messages,
                    output_callback=partial(_render_message, Sender.BOT),
                    tool_output_callback=partial(
                        _tool_output_callback, tool_state=st.session_state.tools
                    ),
                    api_response_callback=partial(
                        _api_response_callback,
                        tab=http_logs,
                        response_state=st.session_state.responses,
                    ),
                    api_key=st.session_state.api_key,
                    only_n_most_recent_images=st.session_state.only_n_most_recent_images,
                )
     
                if st.session_state.messages:
                    bot_response = st.session_state.messages[-1]
                    logging.info(f"Bot response logged: {bot_response}")
     
    async def main():
        """Render loop for streamlit"""
        setup_state()
     
        st.markdown(STREAMLIT_STYLE, unsafe_allow_html=True)
     
        st.title("Claude Computer Use Demo")
     
        if not os.getenv("HIDE_WARNING", False):
            st.warning(WARNING_TEXT)
     
        with st.sidebar:
     
            def _reset_api_provider():
                if st.session_state.provider_radio != st.session_state.provider:
                    _reset_model()
                    st.session_state.provider = st.session_state.provider_radio
                    st.session_state.auth_validated = False
     
            provider_options = [option.value for option in APIProvider]
            st.radio(
                "API Provider",
                options=provider_options,
                key="provider_radio",
                format_func=lambda x: x.title(),
                on_change=_reset_api_provider,
            )
     
            st.text_input("Model", key="model")
     
            if st.session_state.provider == APIProvider.ANTHROPIC:
                st.text_input(
                    "Anthropic API Key",
                    type="password",
                    key="api_key",
                    on_change=lambda: save_to_storage("api_key", st.session_state.api_key),
                )
     
            st.number_input(
                "Only send N most recent images",
                min_value=0,
                key="only_n_most_recent_images",
                help="To decrease the total tokens sent, remove older screenshots from the conversation",
            )
            st.text_area(
                "Custom System Prompt Suffix",
                key="custom_system_prompt",
                help="Additional instructions to append to the system prompt. see computer_use_demo/loop.py for the base system prompt.",
                on_change=lambda: save_to_storage(
                    "system_prompt", st.session_state.custom_system_prompt
                ),
            )
            st.checkbox("Hide screenshots", key="hide_images")
     
            if st.button("Reset", type="primary"):
                with st.spinner("Resetting..."):
                    st.session_state.clear()
                    setup_state()
     
                    subprocess.run("pkill Xvfb; pkill tint2", shell=True)  # noqa: ASYNC221
                    await asyncio.sleep(1)
                    subprocess.run("./start_all.sh", shell=True)  # noqa: ASYNC221
     
        if not st.session_state.auth_validated:
            if auth_error := validate_auth(
                st.session_state.provider, st.session_state.api_key
            ):
                st.warning(f"Please resolve the following auth issue:\n\n{auth_error}")
                return
            else:
                st.session_state.auth_validated = True
     
        new_message = st.chat_input(
            "Type a message to send to Claude to control the computer..."
        )
     
        await initializing_messages(st, new_message)
     
    def validate_auth(provider: APIProvider, api_key: str | None):
        if provider == APIProvider.ANTHROPIC:
            if not api_key:
                return "Enter your Anthropic API key in the sidebar to continue."
        if provider == APIProvider.BEDROCK:
            import boto3
     
            if not boto3.Session().get_credentials():
                return "You must have AWS credentials set up to use the Bedrock API."
        if provider == APIProvider.VERTEX:
            import google.auth
            from google.auth.exceptions import DefaultCredentialsError
     
            if not os.environ.get("CLOUD_ML_REGION"):
                return "Set the CLOUD_ML_REGION environment variable to use the Vertex API."
            try:
                google.auth.default(
                    scopes=["https://www.googleapis.com/auth/cloud-platform"],
                )
            except DefaultCredentialsError:
                return "Your google cloud credentials are not set up correctly."
     
    def load_from_storage(filename: str) -> str | None:
        """Load data from a file in the storage directory."""
        try:
            file_path = CONFIG_DIR / filename
            if file_path.exists():
                data = file_path.read_text().strip()
                if data:
                    return data
        except Exception as e:
            st.write(f"Debug: Error loading {filename}: {e}")
        return None
     
    def save_to_storage(filename: str, data: str) -> None:
        """Save data to a file in the storage directory."""
        try:
            CONFIG_DIR.mkdir(parents=True, exist_ok=True)
            file_path = CONFIG_DIR / filename
            file_path.write_text(data)
            # Ensure only user can read/write the file
            file_path.chmod(0o600)
        except Exception as e:
            st.write(f"Debug: Error saving {filename}: {e}")
     
    def _api_response_callback(
        request: httpx.Request,
        response: httpx.Response | object | None,
        error: Exception | None,
        tab: DeltaGenerator,
        response_state: dict[str, tuple[httpx.Request, httpx.Response | object | None]],
    ):
        """
        Handle an API response by storing it to state and rendering it.
        """
        response_id = datetime.now().isoformat()
        response_state[response_id] = (request, response)
        if error:
            _render_error(error)
        _render_api_response(request, response, response_id, tab)
     
    def _tool_output_callback(
        tool_output: ToolResult, tool_id: str, tool_state: dict[str, ToolResult]
    ):
        """Handle a tool output by storing it to state and rendering it."""
        tool_state[tool_id] = tool_output
        _render_message(Sender.TOOL, tool_output)
     
    def _render_api_response(
        request: httpx.Request,
        response: httpx.Response | object | None,
        response_id: str,
        tab: DeltaGenerator,
    ):
        """Render an API response to a streamlit tab"""
        with tab:
            with st.expander(f"Request/Response ({response_id})"):
                newline = "\n\n"
                st.markdown(
                    f"`{request.method} {request.url}`{newline}{newline.join(f'`{k}: {v}`' for k, v in request.headers.items())}"
                )
                st.json(request.read().decode())
                st.markdown("---")
                if isinstance(response, httpx.Response):
                    st.markdown(
                        f"`{response.status_code}`{newline}{newline.join(f'`{k}: {v}`' for k, v in response.headers.items())}"
                    )
                    st.json(response.text)
                else:
                    st.write(response)
     
    def _render_error(error: Exception):
        if isinstance(error, RateLimitError):
            body = "You have been rate limited."
            if retry_after := error.response.headers.get("retry-after"):
                body += f" **Retry after {str(timedelta(seconds=int(retry_after)))} (HH:MM:SS).** See our API [documentation](https://docs.anthropic.com/en/api/rate-limits) for more details."
            body += f"\n\n{error.message}"
        else:
            body = str(error)
            body += "\n\n**Traceback:**"
            lines = "\n".join(traceback.format_exception(error))
            body += f"\n\n```{lines}```"
        save_to_storage(f"error_{datetime.now().timestamp()}.md", body)
        st.error(f"**{error.__class__.__name__}**\n\n{body}", icon=":material/error:")
     
    def _render_message(
        sender: Sender,
        message: str | BetaContentBlockParam | ToolResult,
    ):
        """Convert input from the user or output from the agent to a streamlit message."""
        # streamlit's hotreloading breaks isinstance checks, so we need to check for class names
        is_tool_result = not isinstance(message, str | dict)
        if not message or (
            is_tool_result
            and st.session_state.hide_images
            and not hasattr(message, "error")
            and not hasattr(message, "output")
        ):
            return
        with st.chat_message(sender):
            if is_tool_result:
                message = cast(ToolResult, message)
                if message.output:
                    if message.__class__.__name__ == "CLIResult":
                        st.code(message.output)
                    else:
                        st.markdown(message.output)
                if message.error:
                    st.error(message.error)
                if message.base64_image and not st.session_state.hide_images:
                    st.image(base64.b64decode(message.base64_image))
            elif isinstance(message, dict):
                if message["type"] == "text":
                    st.write(message["text"])
                elif message["type"] == "tool_use":
                    st.code(f'Tool Use: {message["name"]}\nInput: {message["input"]}')
                else:
                    # only expected return types are text and tool_use
                    raise Exception(f'Unexpected response type {message["type"]}')
            else:
                st.markdown(message)
     
    if __name__ == "__main__":
        asyncio.run(main())
     

### Expected output[](#expected-output)

    Xvfb started successfully on display :1
    Xvfb PID: 9
    starting tint2 on display :1 ...
    starting mutter
    starting vnc
    PORT=5900
    starting noVNC
    noVNC started successfully
    INFO:     [reciver_agent]: Registration on Almanac API successful
    INFO:     [reciver_agent]: Almanac contract registration is up to date!
    INFO:     [reciver_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1q29t34ag4fjgsj5xv4l0kp6sf0m8vd7ssl7hh87lsq5rztm2fqv96x7vle8
    INFO:     [reciver_agent]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:root:new_message open terminal
    INFO:root:Request received by agent : agent1q29t34ag4fjgsj5xv4l0kp6sf0m8vd7ssl7hh87lsq5rztm2fqv96x7vle8 with message: open terminal
    INFO:root:Rendering message: open terminal
    INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true "HTTP/1.1 200 OK"
    INFO:root:Bot response logged: {'role': 'assistant', 'content': [{'type': 'text', 'text': "Great! An xterm terminal window has been opened and is ready for use. You can now proceed with any terminal commands you'd like to run. What would you like to do next?"}]}</content>
</page>

<page>
  <title>Getting started with Fetch.ai and Swarm docs</title>
  <url>https://uagents.fetch.ai/docs/examples/openai/swarm</url>
  <content>Fetch.ai creates a dynamic communication layer that allows you to abstract away components into individual [Agents](https://uagents.fetch.ai/docs/quickstart). Agents are microservices programmed to communicate with other agents, and or humans. Written in python, agents are designed to run independently across many and any device.

By using **Agents** to integrate with **Swarm**, you add a layer which can control a narrative and introduce Swarm Agents to a wider ecosystem.

Let‚Äôs take a look at a simple Swarm example, then see how we can extend this with the uAgents Framework and the `Bureau` class.

A simple Swarm example[](#a-simple-swarm-example)
-------------------------------------------------

### Installation[](#installation)

`pip install git+ssh://[[email¬†protected]](https://uagents.fetch.ai/cdn-cgi/l/email-protection)/openai/swarm.git`

### Code[](#code)

From the Swarm docs, we are going to extend their example:

    from swarm import Swarm, Agent
     
    client = Swarm()
     
    def transfer_to_agent_b():
        return agent_b
     
    agent_a = Agent(
        name="Agent A",
        instructions="You are a helpful agent.",
        functions=[transfer_to_agent_b],
    )
     
    agent_b = Agent(
        name="Agent B",
        instructions="Only speak in Haikus.",
    )
     
    response = client.run(
        agent=agent_a,
        messages=[{"role": "user", "content": "I want to talk to agent B."}],
    )
     
    print(response.messages[-1]["content"])
     

There‚Äôs a few really nice concepts here, `functions` and `instructions`. **Functions** allow the Agent to call another function or act on the data being sent in `client.run()`, this function can also return an agent which passes the message chat to that new agent. **Instructions** are the prompts; we‚Äôll use Agents to update these in the future.

A simple communication with Agents[](#a-simple-communication-with-agents)
-------------------------------------------------------------------------

In many other places in our documentation, we have Agent examples for creation, communication and beginner guides. If you‚Äôve never built using the uAgents Framework before, please have a look at these guides to get yourself started:

You can read more about Agents and Agent communication in our guides.

The integration with Swarm below is quite simple, so we can skip over a lot of Agents information, for brevity.

Swarm x uAgents Framework[](#swarm-x-uagents-framework)
-------------------------------------------------------

We use `Bureau` for this example, our multi-agent runner that works very similarly to Swarm loop examples. For us, `Bureau` is a great way of running many Agents on one single device. Our plan here is fairly simple, we want Agents to control the narrative of the Swarm by creating the questions best suited to the response.

So let‚Äôs extend it.

     
    from swarm import Swarm, Agent
    from swarm import Agent as SwarmAgent
    from uagents import Agent, Model, Bureau, Context
     
    client = Swarm()
     
     
    def transfer_to_agent_b():
        return swarm_agent_b
     
     
    def transfer_to_agent_c():
        return swarm_agent_c
     
     
    def helpful(context_variables):
        resp = "You are a quizzical agent. Answer their question in a riddle. Do not answer in a Haiku."
        ctx = context_variables["personality"] if context_variables["personality"] else ""
        print(ctx)
        if "friendly" in ctx:
            return f"{resp} be sure to give them lots of clues, make the riddle not too difficult to answer"
        else:
            return f"{resp}"
     
     
    swarm_agent_a = SwarmAgent(
        name="Agent A",
        instructions="You are a helpful agent.",
        functions=[transfer_to_agent_b],
    )
     
    swarm_agent_b = SwarmAgent(
        name="Agent B",
        instructions="Only speak in Haikus. Find out what they want",
        functions=[transfer_to_agent_c]
    )
     
    swarm_agent_c = SwarmAgent(
        name="Agent C",
        instructions=helpful,
    )
     
    swarm_agent_d = SwarmAgent(
        name="Question generator",
        instructions="Create a random question to ask someone about any animal"
    )
     
     
    class Request(Model):
        text: str
     
     
    class Response(Model):
        text: str
     
     
    class QuestionCreation(Model):
        text: str
     
     
    class QuestionCreated(Model):
        text: str
     
     
    swarm_uagent = Agent(name='Swarm')
    trigger_uagent = Agent(name='Trigger')
    question_uagent = Agent(name='Question')
     
     
    @swarm_uagent.on_message(Request)
    async def handle_request(ctx: Context, sender: str, request: Request):
        response = client.run(
            agent=swarm_agent_a,
            messages=[{"role": "user", "content": request.text}],
        )
     
        await ctx.send(sender, Response(text=response.messages[-1]["content"]))
     
     
    @trigger_uagent.on_event('startup')
    async def trigger_request(ctx: Context):
        await ctx.send(swarm_uagent.address, Request(text="I want to talk to agent B."))
     
     
    @trigger_uagent.on_message(Response)
    async def handle_response(ctx: Context, sender: str, response: Response):
        print(f"Response from on_message : {response.text}")
        await ctx.send(question_uagent.address, QuestionCreation(text=""))
     
     
    @trigger_uagent.on_message(QuestionCreated)
    async def handle_response(ctx: Context, sender: str, response: Response):
        print(f"Response from on_message :", response.text)
     
        response = client.run(
            agent=swarm_agent_c,
            messages=[{"role": "user", "content": response.text}],
            context_variables={"user": "Jessica", "personality": "friendly, kind"}
        )
     
        print(response.messages[-1]["content"])
     
     
    @question_uagent.on_message(QuestionCreation)
    async def create_question(ctx: Context, sender: str, question: QuestionCreation):
        print("creating question...")
     
        response = client.run(
            agent=swarm_agent_d,
            messages=[{"role": "user", "content": "Create a random question about any animal"}],
        )
     
        print(response.messages[-1]["content"])
     
        await ctx.send(sender, QuestionCreated(text=response.messages[-1]["content"]))
     
     
    bureau = Bureau()
    bureau.add(swarm_uagent)
    bureau.add(trigger_uagent)
    bureau.add(question_uagent)
    bureau.run()
     

There‚Äôs a lot of code there, but so let‚Äôs cover the Agent specific bits first:

We imported `uagents` first:

     
    from uagents import Agent, Model, Bureau, Context
     
     

We defined our message structures:

     
    class Request(Model):
        text: str
     
     
    class Response(Model):
        text: str
     
     
    class QuestionCreation(Model):
        text: str
     
     
    class QuestionCreated(Model):
        text: str
     
     

Within the uAgents Framework this is pretty important, and can be much more complex than the above. We treat `Message` classes as our rules of communication, generally in a Request/Response format. It also enforces type that helps keep Agents resilient. For additional information on how Agents do communicate, have a look at the following [resource](https://uagents.fetch.ai/docs/guides/communication).

Next, we instantiate our Agents and create [message handling functions](https://uagents.fetch.ai/docs/guides/handlers#handle-messages-using-the-on_message-handler):

     
    swarm_uagent = Agent(name='Swarm')
    trigger_uagent = Agent(name='Trigger')
    question_uagent = Agent(name='Question')
     
     
    @swarm_uagent.on_message(Request)
    async def handle_request(ctx: Context, sender: str, request: Request):
        response = client.run(
            agent=swarm_agent_a,
            messages=[{"role": "user", "content": request.text}],
        )
     
        await ctx.send(sender, Response(text=response.messages[-1]["content"]))
     
     
    @trigger_uagent.on_event('startup')
    async def trigger_request(ctx: Context):
        await ctx.send(swarm_uagent.address, Request(text="I want to talk to agent B."))
     
     
    @trigger_uagent.on_message(Response)
    async def handle_response(ctx: Context, sender: str, response: Response):
        print(f"Response from on_message : {response.text}")
        await ctx.send(question_uagent.address, QuestionCreation(text=""))
     
     
    @trigger_uagent.on_message(QuestionCreated)
    async def handle_response(ctx: Context, sender: str, response: Response):
        print(f"Response from on_message :", response.text)
     
        response = client.run(
            agent=swarm_agent_c,
            messages=[{"role": "user", "content": response.text}],
            context_variables={"user": "Jessica", "personality": "friendly, kind"}
        )
     
        print(response.messages[-1]["content"])
     
     
    @question_uagent.on_message(QuestionCreation)
    async def create_question(ctx: Context, sender: str, question: QuestionCreation):
        print("creating question...")
     
        response = client.run(
            agent=swarm_agent_d,
            messages=[{"role": "user", "content": "Create a random question about any animal"}],
        )
     
        print(response.messages[-1]["content"])
     
        await ctx.send(sender, QuestionCreated(text=response.messages[-1]["content"]))
     
     
    bureau = Bureau()
    bureau.add(swarm_uagent)
    bureau.add(trigger_uagent)
    bureau.add(question_uagent)
    bureau.run()
     

The important thing to note is that Agents have specific functions to handle different message objects being received; the uAgents library in the background calls the correct function based on decorator and args. When an Agent calls `await ctx.send(sender, Message())` that effectively calls another Agent‚Äôs function to act on the sent data.

We have extended the Swarm example slightly; we want to use context variables but also use an Agent to generate the question on our behalf.

     
     
    def helpful(context_variables):
        resp = "You are a quizzical agent. Answer their question in a riddle. Do not answer in a Haiku."
        ctx = context_variables["personality"] if context_variables["personality"] else ""
        print(ctx)
        if "friendly" in ctx:
            return f"{resp} be sure to give them lots of clues, make the riddle not too difficult to answer"
        else:
            return f"{resp}"
     

     
    swarm_agent_c = SwarmAgent(
        name="Agent C",
        instructions=helpful,
    )
     
    swarm_agent_d = SwarmAgent(
        name="Question generator",
        instructions="Create a random question to ask someone about any animal"
    )
     

The `context_variable` was set in an Agent message handler:

     
    @trigger_uagent.on_message(QuestionCreated)
    async def handle_response(ctx: Context, sender: str, response: Response):
        print(f"Response from on_message :", response.text)
     
        response = client.run(
            agent=swarm_agent_c,
            messages=[{"role": "user", "content": response.text}],
            context_variables={"user": "Jessica", "personality": "friendly, kind"}
        )
     
        print(response.messages[-1]["content"])
     

Let‚Äôs now recap the flow:

### Expected Output[](#expected-output)

Run `poetry run python langchain_agent_two.py` first and then `poetry run python langchain_agent_one.py`.

You should get something similar to the following for the bureau:

    	INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    	Response from on_message : To have a chat with Agent B,  
    	Look to the hive with golden key.  
    	If none can find, then change the tone,  
    	And talk to shadows made of stone.
    	creating question...
    	INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    	If you could transform into any animal for a day, which one would you choose and why?
    	INFO:     [bureau]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    	Response from on_message : If you could transform into any animal for a day, which one would you choose and why?
    	friendly, kind
    	INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    	In the sky so high, I soar with might,  
    	With wings so vast, I dance with light.  
    	I see the world in colors bright,  
    	A fish below, a mouse in flight.  
    	Majestic, noble, called king of skies,  
    	Which creature would I be in disguise?  
    

Next steps[](#next-steps)
-------------------------

This has been a brief introduction into **Swarm** and **Fetch.ai**.

For further reading on how and where we use other OpenAI, technology take a look at the following resource for [RAG Agents](https://uagents.fetch.ai/docs/guides/langchain_agent).</content>
</page>

<page>
  <title>CrewAI Adapter for uAgents docs</title>
  <url>https://uagents.fetch.ai/docs/examples/crewai</url>
  <content>This example demonstrates how to integrate a CrewAI multi-agent system with the uAgents ecosystem using the uAgents Adapter package. CrewAI allows you to create collaborative teams of AI agents working together to accomplish complex tasks.

Overview[](#overview)
---------------------

The CrewAI adapter enables:

*   Creating specialized agent teams with distinct roles and responsibilities
*   Orchestrating complex workflows between different Agents
*   Exposing CrewAI teams as uAgents for seamless communication with the broader agent ecosystem
*   Deploying CrewAI applications to the Agentverse network

Trip Planner Example[](#trip-planner-example)
---------------------------------------------

Let‚Äôs look at a real-world example of a trip planning system with multiple specialized agents working together to create a complete travel itinerary. We‚Äôll compare the standard CrewAI implementation with the uAgents-integrated version.

### Standard CrewAI Implementation[](#standard-crewai-implementation)

First, let‚Äôs look at how a standard CrewAI system is implemented without uAgents integration:

    # Standard main.py
    from textwrap import dedent
     
    from crewai import Crew
    from dotenv import load_dotenv
     
    from trip_agents import TripAgents
    from trip_tasks import TripTasks
     
    load_dotenv()
     
     
    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range
     
        def run(self):
            agents = TripAgents()
            tasks = TripTasks()
     
            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()
            travel_concierge_agent = agents.travel_concierge()
     
            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(local_expert_agent, self.origin, self.interests, self.date_range)
            plan_task = tasks.plan_task(travel_concierge_agent, self.origin, self.interests, self.date_range)
     
            crew = Crew(
                agents=[city_selector_agent, local_expert_agent, travel_concierge_agent],
                tasks=[identify_task, gather_task, plan_task],
                verbose=True,
            )
     
            result = crew.kickoff()
            return result
     
     
    if __name__ == "__main__":
        print("## Welcome to Trip Planner Crew")
        print("-------------------------------")
        location = input(
            dedent("""
          From where will you be traveling from?
        """)
        )
        cities = input(
            dedent("""
          What are the cities options you are interested in visiting?
        """)
        )
        date_range = input(
            dedent("""
          What is the date range you are interested in traveling?
        """)
        )
        interests = input(
            dedent("""
          What are some of your high level interests and hobbies?
        """)
        )
     
        trip_crew = TripCrew(location, cities, date_range, interests)
        result = trip_crew.run()
        print("\n\n########################")
        print("## Here is you Trip Plan")
        print("########################\n")
        print(result)

### uAgents Integration[](#uagents-integration)

Now, let‚Äôs see how we can integrate this same CrewAI system with uAgents to enable network communication:

    #!/usr/bin/env python3
    """Trip Planner script using CrewAI adapter for uAgents."""
     
    import os
     
    from crewai import Crew
    from dotenv import load_dotenv
    from uagents_adapter import CrewaiRegisterTool
     
    from trip_agents import TripAgents
    from trip_tasks import TripTasks
     
     
    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range
     
        def run(self):
            agents = TripAgents()
            tasks = TripTasks()
     
            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()
            travel_concierge_agent = agents.travel_concierge()
     
            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(local_expert_agent, self.origin, self.interests, self.date_range)
            plan_task = tasks.plan_task(travel_concierge_agent, self.origin, self.interests, self.date_range)
     
            crew = Crew(
                agents=[city_selector_agent, local_expert_agent, travel_concierge_agent],
                tasks=[identify_task, gather_task, plan_task],
                verbose=True,
            )
     
            result = crew.kickoff()
            return result
     
        def kickoff(self, inputs=None):
            """
            Compatibility method for uAgents integration.
            Accepts a dictionary of inputs and calls run() with them.
            """
            if inputs:
                self.origin = inputs.get("origin", self.origin)
                self.cities = inputs.get("cities", self.cities)
                self.date_range = inputs.get("date_range", self.date_range)
                self.interests = inputs.get("interests", self.interests)
     
            return self.run()
     
     
    def main():
        """Main function to demonstrate Trip Planner with CrewAI adapter."""
     
        # Load API key from environment
        load_dotenv()
        api_key = os.getenv("AGENTVERSE_API_KEY")
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("Error: AGENTVERSE_API_KEY not found in environment")
            return
     
        if not openai_api_key:
            print("Error: OPENAI_API_KEY not found in environment")
            return
     
        # Set OpenAI API key in environment
        os.environ["OPENAI_API_KEY"] = openai_api_key
     
        # Create an instance of TripCrew with default empty values
        trip_crew = TripCrew("", "", "", "")
     
        # Create tool for registering the crew with Agentverse
        register_tool = CrewaiRegisterTool()
     
        # Define parameters schema for the trip planner
        query_params = {
            "origin": {"type": "str", "required": True},
            "cities": {"type": "str", "required": True},
            "date_range": {"type": "str", "required": True},
            "interests": {"type": "str", "required": True},
        }
     
        # Register the crew with parameter schema
        result = register_tool.run(
            tool_input={
                "crew_obj": trip_crew,
                "name": "Trip Planner Crew AI Agent adapters",
                "port": 8080,
                "description": "A CrewAI agent that helps plan trips based on preferences",
                "api_token": api_key,
                "mailbox": True,
                "query_params": query_params,
                "example_query": "Plan a trip from New York to Paris in June, I'm interested in art and history other than museums.",
            }
        )
     
        # Get the agent address from the result
        if isinstance(result, dict) and "address" in result:
            result["address"]
     
        print(f"\nCrewAI agent registration result: {result}")
     
        # Keep the program running
        try:
            while True:
                import time
     
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nExiting...")
     
     
    if __name__ == "__main__":
        main()

Key Differences in uAgents Integration[](#key-differences-in-uagents-integration)
---------------------------------------------------------------------------------

When integrating a CrewAI system with uAgents, there are several important differences:

1.  CrewaiRegisterTool:
    
    *   Uses the specialized `CrewaiRegisterTool` instead of the generic `UAgentRegisterTool`.
    *   This tool is specifically designed to handle CrewAI‚Äôs collaborative agent structure.
2.  Kickoff Method:
    
    *   The `TripCrew` class has an additional kickoff method that serves as an adapter between uAgents messages and the CrewAI system.
    *   It extracts parameters from the input dictionary and passes them to the actual execution method.
3.  Parameter Schema:
    
    *   A `query_params` schema is defined to validate and structure inputs to the CrewAI system.
    *   This allows for better error handling and client guidance when using the agent.
4.  Example Query:
    
    *   An example query is provided to help users understand the expected input format.
    *   This improves usability when interacting with the agent through chat protocols.

Specialized Agents in the Trip Planner[](#specialized-agents-in-the-trip-planner)
---------------------------------------------------------------------------------

The trip planning system uses three specialized agents, defined in `trip_agents`.py:

1.  **City Selection Agent**: Analyzes client preferences to select the optimal city to visit
2.  **Local Expert**: Identifies authentic local experiences and hidden gems
3.  **Travel Concierge**: Creates detailed itineraries and plans logistics

Each agent is assigned specific tasks through the `trip_tasks.py` file:

1.  **Identify Task**: Determines the best city based on client preferences
2.  **Gather Task**: Collects detailed information about activities and attractions
3.  **Plan Task**: Creates a comprehensive itinerary with transportation details

Interacting with the Trip Planner[](#interacting-with-the-trip-planner)
-----------------------------------------------------------------------

Once registered as a uAgent, you can interact with the CrewAI trip planner using any uAgent client:

    from datetime import datetime, timezone
    from uuid import uuid4
    from uagents import Agent, Protocol, Context
     
    #import the necessary components from the chat protocol
    from uagents_core.contrib.protocols.chat import (
        ChatAcknowledgement,
        ChatMessage,
        TextContent,
        chat_protocol_spec,
    )
    # Initialise agent2
    agent2 = Agent(name="client_agent",
                   port = 8082,
                   mailbox=True,
                   seed="client agent testing seed"
                   )
     
    # Initialize the chat protocol
    chat_proto = Protocol(spec=chat_protocol_spec)
     
    langgraph_agent_address = "agent1q0zyxrneyaury3f5c7aj67hfa5w65cykzplxkst5f5mnyf4y3em3kplxn4t"
     
    # Startup Handler - Print agent details
    @agent2.on_event("startup")
    async def startup_handler(ctx: Context):
        # Print agent details
        ctx.logger.info(f"My name is {ctx.agent.name} and my address is {ctx.agent.address}")
     
        # Send initial message to agent2
        initial_message = ChatMessage(
            timestamp=datetime.now(timezone.utc),
            msg_id=uuid4(),
            content=[TextContent(type="text", text="Plan a trip for me from london to paris starting on 22nd of April 2025 and I am interested in a mountains beaches and history")]
        )
        await ctx.send(langgraph_agent_address, initial_message)
     
    # Message Handler - Process received messages and send acknowledgements
    @chat_proto.on_message(ChatMessage)
    async def handle_message(ctx: Context, sender: str, msg: ChatMessage):
        for item in msg.content:
            if isinstance(item, TextContent):
                # Log received message
                ctx.logger.info(f"Received message from {sender}: {item.text}")
                
                # Send acknowledgment
                ack = ChatAcknowledgement(
                    timestamp=datetime.now(timezone.utc),
                    acknowledged_msg_id=msg.msg_id
                )
                await ctx.send(sender, ack)
                
     
    # Acknowledgement Handler - Process received acknowledgements
    @chat_proto.on_message(ChatAcknowledgement)
    async def handle_acknowledgement(ctx: Context, sender: str, msg: ChatAcknowledgement):
        ctx.logger.info(f"Received acknowledgement from {sender} for message: {msg.acknowledged_msg_id}")
     
    # Include the protocol in the agent to enable the chat functionality
    # This allows the agent to send/receive messages and handle acknowledgements using the chat protocol
    agent2.include(chat_proto, publish_manifest=True)
     
    if __name__ == '__main__':
        agent2.run()

Benefits of the uAgents Integration[](#benefits-of-the-uagents-integration)
---------------------------------------------------------------------------

Integrating CrewAI with uAgents provides several significant advantages:

1.  **Network Communication**: Enables remote access to your CrewAI system over networks
2.  **Structured Inputs**: Validates inputs through a defined parameter schema
3.  **Persistent Mailbox**: Allows asynchronous communication with message storage
4.  **Agentverse Integration**: Makes your CrewAI system discoverable in the agent ecosystem
5.  **NL Processing**: Optional AI agent integration for processing natural language queries

Getting Started[](#getting-started)
-----------------------------------

Clone the [Trip Planner repository](https://github.com/abhifetch/crewai-example/tree/main/trip_planner).

1.  Install dependencies:
    
        pip install uagents==0.22.3 "crewai[tools]"==0.105.0 uagents-adapter==0.2.1 python-dotenv==1.0.0 langchain_openai==0.2.13
    
2.  Or use the provided requirements.txt:
    
        pip install -r requirements.txt
    
3.  Set up your environment variables:
    
        OPENAI_API_KEY=your_openai_key
        AGENTVERSE_API_KEY=your_agentverse_key
        AGENT_SEED=your_agent_seed_phrase
    
4.  Run the CrewAI trip planner with uAgents adapter:
    
        cd crewai-example/trip_planner
        python main_uagents.py
    
5.  In a separate terminal, run a client agent to interact with it:
    
        cd crewai-example
        python client_agent.py
    

Expected Outputs[](#expected-outputs)
-------------------------------------

When running the examples, you should expect to see outputs similar to these:

### Standard CrewAI (`main.py`)[](#standard-crewai-mainpy)

    ## Welcome to Trip Planner Crew
    -------------------------------
    From where will you be traveling from?
    > New York
    
    What are the cities options you are interested in visiting?
    > Paris, Rome, Barcelona
    
    What is the date range you are interested in traveling?
    > June 10-20, 2023
    
    What are some of your high level interests and hobbies?
    > Food, art, architecture, and history
    
    [City Selection Specialist] I'll analyze which city would be the best fit based on the traveler's preferences...
    
    Working on: Analyze the traveler's preferences and determine which city from the options would be the best fit...
    
    [... search and reasoning details ...]
    
    ########################
    ## Here is you Trip Plan
    ########################
    
    # PARIS: 3-DAY FOOD & ART JOURNEY
    *A curated itinerary for experiencing the best of Parisian cuisine and artistic treasures*
    
    ## RECOMMENDED ACCOMMODATIONS
    Le Marais district or Saint-Germain-des-Pr√©s would be ideal locations, offering central positioning with charming atmosphere and proximity to key attractions.
    
    [... detailed itinerary continues ...]

### uAgents Integration (`main_uagents.py`)[](#uagents-integration-main_uagentspy)

First terminal:

    (venv) abhi@Fetchs-MacBook-Pro test examples % python3 trip_planner/main_uagents.py
    INFO:     [Trip Planner Crew AI Agent adapters]: Starting agent with address: agent1q2sgs58jzw70e8vvsrlx8k3yukdqc9gwkhp8p7q6tslcxhy0eqtxyq4fv07
    INFO:     [Trip Planner Crew AI Agent adapters]: Agent 'Trip Planner Crew AI Agent adapters' started with address: agent1q2sgs58jzw70e8vvsrlx8k3yukdqc9gwkhp8p7q6tslcxhy0eqtxyq4fv07
    INFO:     [Trip Planner Crew AI Agent adapters]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8080&address=agent1q2sgs58jzw70e8vvsrlx8k3yukdqc9gwkhp8p7q6tslcxhy0eqtxyq4fv07
    INFO:     [Trip Planner Crew AI Agent adapters]: Starting server on http://0.0.0.0:8080 (Press CTRL+C to quit)
    INFO:     [Trip Planner Crew AI Agent adapters]: Starting mailbox client for https://agentverse.ai
    INFO:     [Trip Planner Crew AI Agent adapters]: Mailbox access token acquired
    Connecting agent 'Trip Planner Crew AI Agent adapters' to Agentverse...
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    Successfully connected agent 'Trip Planner Crew AI Agent adapters' to Agentverse
    Updating agent 'Trip Planner Crew AI Agent adapters' README on Agentverse...
    Successfully updated agent 'Trip Planner Crew AI Agent adapters' README on Agentverse
    
    CrewAI agent registration result: Agent 'Trip Planner Crew AI Agent adapters' registered with address: agent1q2sgs58jzw70e8vvsrlx8k3yukdqc9gwkhp8p7q6tslcxhy0eqtxyq4fv07 with mailbox (Parameters: origin, cities, date_range, interests)
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    INFO:     [Trip Planner Crew AI Agent adapters]: Got a message from agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [Trip Planner Crew AI Agent adapters]: Received message model digest: timestamp=datetime.datetime(2025, 4, 21, 10, 13, 39, 989489, tzinfo=datetime.timezone.utc) msg_id=UUID('7930acf1-b16e-4b20-896b-7d801763eaa6') content=[TextContent(type='text', text='Plan a trip for me from london to paris starting on 22nd of April 2025 and I am interested in a mountains beaches and history')]
    INFO:     [Trip Planner Crew AI Agent adapters]: Got a text message from agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49: Plan a trip for me from london to paris starting on 22nd of April 2025 and I am interested in a mountains beaches and history
    INFO:     [Trip Planner Crew AI Agent adapters]: Using crew object: <__main__.TripCrew object at 0x12c1f79d0>
    INFO:     [Trip Planner Crew AI Agent adapters]: Extracting parameters using keys: ['origin', 'cities', 'date_range', 'interests']
    INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:     [Trip Planner Crew AI Agent adapters]: Extracted parameters: {'origin': 'london', 'cities': 'paris', 'date_range': '22nd of April 2025', 'interests': 'mountains beaches and history'}
    INFO:     [Trip Planner Crew AI Agent adapters]: Running crew with extracted parameters
    ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crew Execution Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
    ‚îÇ                                                                                                                                      ‚îÇ
    ‚îÇ  Crew Execution Started                                                                                                              ‚îÇ
    ‚îÇ  Name: crew                                                                                                                          ‚îÇ
    ‚îÇ  ID: 1462f3ae-5ce4-4ea3-b1af-5639aac04dd2                                                                                            ‚îÇ
    ‚îÇ                                                                                                                                      ‚îÇ
    ‚îÇ                                                                                                                                      ‚îÇ
    ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
    
    üöÄ Crew: crew
    ‚îî‚îÄ‚îÄ üìã Task: c181e31b-6b7f-4471-ab8f-fa5f06078365
           Status: Executing Task...
    [... crew execution continues ...]

### Client Agent (client\_agent.py)[](#client-agent-client_agentpy)

Second terminal:

    (venv) abhi@Fetchs-MacBook-Pro crewai-example % python3 trip_planner/client_agent.py 
    INFO:     [client_agent]: Starting agent with address: agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: My name is client_agent and my address is agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8082&address=agent1qwwng5d939vyaa6d2trnllyltgrndtfd6z44h8ey8a56hf4dcatsytgzm49
    INFO:     [client_agent]: Starting server on http://0.0.0.0:8082 (Press CTRL+C to quit)
    INFO:     [client_agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [client_agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [client_agent]: Mailbox access token acquired
    INFO:     [client_agent]: Received acknowledgement from agent1q2sgs58jzw70e8vvsrlx8k3yukdqc9gwkhp8p7q6tslcxhy0eqtxyq4fv07 for message: 7930acf1-b16e-4b20-896b-7d801763eaa6
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Almanac contract registration is up to date!
    
    [... detailed itinerary continues ...]

This example demonstrates how uAgents adapters can bring collaborative AI agent systems into a networked environment, making complex workflows accessible through standardized messaging protocols.</content>
</page>

<page>
  <title>Getting started with Fetch.ai x Langchain docs</title>
  <url>https://uagents.fetch.ai/docs/examples/langchain</url>
  <content>Fetch.ai creates a dynamic communication layer that allows you to abstract away components into individual [Agents](https://uagents.fetch.ai/docs/quickstart). Agents are micro-services that are programmed to communicate with other agents, and or humans. By using **Agents** to represent different parts of your **Langchain** program you give your project the option to be used by [other parties](https://uagents.fetch.ai/docs/guides/communication) for economic benefit.

Let‚Äôs take a look at a simple Langchain example, then see how we can extend this with agents.

A simple langchain example[](#a-simple-langchain-example)
---------------------------------------------------------

Let‚Äôs create a simple script that can find any information in a PDF. Using a document loader from Langchain, and FAISS vector store along with OpenAI, we can load the PDF, use `FAISS` to create a vector store, `open_ai` to create embeddings on the documents, and then use `FAISS` to do a similarity search. Quite complicated for a small example, but it is only a handful of lines of code:

    from langchain_community.document_loaders import PyPDFLoader
    import os
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings
     
    openai_api_key = os.environ['OPENAI_API_KEY']
     
    loader = PyPDFLoader("./your-pdf.pdf")
    pages = loader.load_and_split()
     
    faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))
     
    docs = faiss_index.similarity_search("what problem does fetch solve?", k=2)
    for doc in docs:
        print(str(doc.metadata["page"]) + ":", doc.page_content[:600])
     

However, there is a lot of smaller bits happening there. If we use agents for each step, then other agents can use those pieces of code üí°.

A simple communication with agents[](#a-simple-communication-with-agents)
-------------------------------------------------------------------------

Fetch.ai has the concept of an agent which at a base level an agent cannot do what Langchain does, however an agent is the component that links them together.

You can read more about agents communication in our [guides](https://uagents.fetch.ai/docs/guides/communication).

Let‚Äôs install what we need:

    poetry init
    poetry add uagents

Check out more detailed instructions for [installation](https://uagents.fetch.ai/docs/getting-started/install) of `uagents` library on your end.

### First Agent[](#first-agent)

Our first agent is simple; it sends a message every two seconds to a static address. When this agent receives a message, it prints that to log:

     
    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
     
     
    class Message(Model):
        message: str
     
     
    RECIPIENT_ADDRESS = "agent1qf4au6rzaauxhy2jze6v85rspgvredx9m42p0e0cukz0hv4dh2sqjuhujpp"
     
    agent = Agent(
        name="agent",
        port=8000,
        seed="",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     
    fund_agent_if_low(agent.wallet.address())
     
     
    @agent.on_interval(period=2.0)
    async def send_message(ctx: Context):
        await ctx.send(RECIPIENT_ADDRESS, Message(message="hello there"))
     
     
    @agent.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
     
    if __name__ == "__main__":
        agent.run()
     

This first agent introduces a few core concepts you will need to be aware of when creating any agent.

Agents are defined with the `Agent` class:

     
    agent = Agent(
        name="agent",
        port=8000,
        seed="",
        endpoint=["http://127.0.0.1:8000/submit"],
    )
     

A `seed` is a unique phrase which `uagents` library uses to create a unique private key pair for your agent. If you change your `seed` you may lose access to previous messages, and also, the agent‚Äôs address registered to the Almanac will change subsequently. The `port` allows us to define a local port for messages to be received. The `endpoint` defines the path to the in-built Rest API. The `name` defines the name of the agent.

There are more options for the `Agent` class; see [`Agent` Class](https://uagents.fetch.ai/refs/api/agent) for further reference.

We then need to define our communication model:

     
    class Message(Model):
        message: str
     

The `Model` defines the object sent from agent to agent and represents the type of messages the agent is able to handle. For explicit communication, both agents must handle the same `Model` class. `Model` is the base class that inherits from Pydantic BaseModel.

With the `fund_agent_if_low(agent.wallet.address())` function, agents will ultimately pay for discoverability as the economy of agents matures. There is a placeholder for registration here.

Finally, agents have two decorated functions.

The first one is the `agent.on_interval()` function. This one sends a message every 2 seconds. `ctx.send()` has the args of `destination_address` and `Message` which we defined earlier.

     
    @agent.on_interval(period=2.0)
    async def send_message(ctx: Context):
        await ctx.send(RECIPIENT_ADDRESS, Message(message="hello there"))
     

The second one is `agent.on_message()` which is a little different; when the agent receives a message at the `endpoint` we defined earlier, the `uagent` library unpacks the message and triggers any function which handles that message; in our case, the `agent.on_message()` function:

     
    @agent.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     

### Second Agent[](#second-agent)

Agent two doesn‚Äôt do anything different to agent one; it has different args for the Agent instantiation, and instead of sending a message `on_event("startup")`, agent two just logs its address to screen. Whenever agent two receives a message matching `Message` data model, it will send a response to the sender.

     
    from uagents.setup import fund_agent_if_low
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    agent = Agent(
        name="agent 2",
        port=8001,
        seed="",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    fund_agent_if_low(agent.wallet.address())
     
     
    @agent.on_event("startup")
    async def start(ctx: Context):
        ctx.logger.info(f"agent address is {agent.address}")
     
     
    @agent.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f"Received message from {sender}: {msg.message}")
     
        await ctx.send(sender, Message(message="hello there"))
     
     
    if __name__ == "__main__":
        agent.run()
     

Okay, let‚Äôs now run these agents.

### Running the agents[](#running-the-agents)

Let‚Äôs run the second agent‚Äôs script first using this command: `poetry run python second_agent.py`

**We must run the second agent first to get its unique address**. This is shown in output in the log. Let‚Äôs update `first_agent.py` script by filling the `RECIPIENT_ADDRESS` field with the address of the second agent from of the output we previously got by running `second_agent.py` script.

Updated `first_agent.py` script sample:

    from uagents import Agent, Context, Model
    from uagents.setup import fund_agent_if_low
     
    class Message(Model):
        message: bool
     
    RECIPIENT_ADDRESS="agent...."
     
    agent = Agent(
            ...

Then, let‚Äôs run the script for the first agent using this command: `poetry run python first_agent.py`

Great! You should now be seeing some log out output with our messages being displayed.

### Output[](#output)

*   **First Agent**:
    
        INFO:     [agent]: Registering on almanac contract...
        INFO:     [agent]: Registering on almanac contract...complete
        INFO:     [agent]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
        INFO:     [agent]: Received message from agent1qf4au6rzaauxhy2jze6v85rspgvredx9m42p0e0cukz0hv4dh2sqjuhujpp: hello there
        INFO:     [agent]: Received message from agent1qf4au6rzaauxhy2jze6v85rspgvredx9m42p0e0cukz0hv4dh2sqjuhujpp: hello there
        INFO:     [agent]: Received message from agent1qf4au6rzaauxhy2jze6v85rspgvredx9m42p0e0cukz0hv4dh2sqjuhujpp: hello there
    
*   **Second Agent**:
    
        INFO:     [agent 2]: Registering on almanac contract...
        INFO:     [agent 2]: Registering on almanac contract...complete
        INFO:     [agent 2]: agent address is agent1qf4au6rzaauxhy2jze6v85rspgvredx9m42p0e0cukz0hv4dh2sqjuhujpp
        INFO:     [agent 2]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    

Wrapping them together - Building a Function[](#wrapping-them-together---building-a-function)
---------------------------------------------------------------------------------------------

Let‚Äôs go further now and change our agents scripts by splitting the logic of the Langchain example above. Let‚Äôs have one agent that sends a PDF path and questions it wants to be answered about that PDF by the other agent. Conversely, the other agent returns information on the PDF based on the questions asked by using Langchain tools.

### Agent one: providing PDF and requesting information[](#agent-one-providing-pdf-and-requesting-information)

This agent sends `DocumentUnderstanding` model which contains a local path to a PDF, and a question that the other agent must answer about the PDF. It‚Äôs a small update on our first agent script.

However now, `.on_message(model=DocumentsResponse)` expects a `DocumentsResponse` object instead of a string.

To learn more about communication with other agents check out the following [Guide](https://uagents.fetch.ai/docs/guides/communication).

     
    from uagents import Agent, Context, Protocol, Model
    from typing import List
     
     
    class DocumentUnderstanding(Model):
        pdf_path: str
        question: str
     
     
    class DocumentsResponse(Model):
        learnings: List
     
     
    agent = Agent(
        name="find_in_pdf",
        seed="",
        port=8001,
        endpoint=["http://127.0.0.1:8001/submit"]
    )
     
    print("uAgent address: ", agent.address)
    summary_protocol = Protocol("Text Summarizer")
     
    RECIPIENT_PDF_AGENT = ""
     
     
    @agent.on_event("startup")
    async def on_startup(ctx: Context):
        await ctx.send(RECIPIENT_PDF_AGENT,
                       DocumentUnderstanding(pdf_path="../a-little-story.pdf", question="What's the synopsis?"))
     
     
    @agent.on_message(model=DocumentsResponse)
    async def document_load(ctx: Context, sender: str, msg: DocumentsResponse):
        ctx.logger.info(msg.learnings)
     
     
    agent.include(summary_protocol, publish_manifest=True)
    agent.run()
     

### Agent two: wrapping the Langchain bits[](#agent-two-wrapping-the-langchain-bits)

Agent two defines the same models as agent one, but this time, it wraps the logic for the Langchain PDF question in the `document_load()` function, which is decorated with `.on_message(model=DocumentUnderstanding, replies=DocumentsResponse)` . You can specify a `replies` argument in your `on_message` decorators; this is useful for being more explicit with communication.

     
    from langchain_community.document_loaders import PyPDFLoader
    import os
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings
    from uagents import Agent, Context, Protocol, Model
    from typing import List
     
     
    class DocumentUnderstanding(Model):
        pdf_path: str
        question: str
     
     
    class DocumentsResponse(Model):
        learnings: List
     
     
    pdf_questioning_agent = Agent(
        name="pdf_questioning_agent",
        seed="",
        port=8003,
        endpoint=["http://127.0.0.1:8003/submit"],
    )
     
    print("uAgent address: ", pdf_questioning_agent.address)
    pdf_loader_protocol = Protocol("Text Summariser")
     
     
    @pdf_questioning_agent.on_message(model=DocumentUnderstanding, replies=DocumentsResponse)
    async def document_load(ctx: Context, sender: str, msg: DocumentUnderstanding):
        loader = PyPDFLoader(msg.pdf_path)
        pages = loader.load_and_split()
        openai_api_key = os.environ['OPENAI_API_KEY']
        learnings = []
     
        faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))
     
        docs = faiss_index.similarity_search(msg.question, k=2)
     
        for doc in docs:
            learnings.append(str(doc.metadata["page"]) + ":" + doc.page_content[:600])
     
        await ctx.send(sender, DocumentsResponse(learnings=learnings))
     
     
    pdf_questioning_agent.include(pdf_loader_protocol, publish_manifest=True)
    pdf_questioning_agent.run()
     

With these agents now being defined, it is time to run them. Let‚Äôs run Agent two first to get its address and then update Agent one to send a message to it by filling the `RECIPIENT_PDF_AGENT` field in-line.

### Expected Output[](#expected-output)

Run `poetry run python langchain_agent_two.py` first and then `poetry run python langchain_agent_one.py`.

You should get something similar to the following for each agent:

*   **Langchain Agent 1**:
    
        uAgent address agent:  agent1qv9qmj3ug83vcrg774g2quz0urmlyqlmzh6a5t3r88q3neejlrffz405p7x
        INFO:     [find_in_pdf]: Manifest published successfully: Text Summarizer
        INFO:     [find_in_pdf]: Registration on Almanac API successful
        INFO:     [find_in_pdf]: Almanac contract registration is up to date!
        INFO:     [find_in_pdf]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
        INFO:     [find_in_pdf]: ['0: This is a simple story about two ... ]
    
*   **Langchain Agent 2**:
    
        uAgent address:  agent1qfwfpz6dpyzvz0f0tgxax58fpppaknnqm99fpggmm2wffjcxgqe8sn4cwx3
        INFO:     [pdf_questioning_agent]: Manifest published successfully: Text Summarizer
        INFO:     [pdf_questioning_agent]: Registration on Almanac API successful
        INFO:     [pdf_questioning_agent]: Almanac contract registration is up to date!
        INFO:     [pdf_questioning_agent]: Starting server on http://0.0.0.0:8003 (Press CTRL+C to quit)
        INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
        INFO:faiss.loader:Loading faiss with AVX2 support.
        INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
        INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"</content>
</page>

<page>
  <title>Local Agent Inspector docs</title>
  <url>https://uagents.fetch.ai/docs/agentverse/inspector</url>
  <content>The Local Agent Inspector is a developer tool on Agentverse designed to streamline debugging and monitoring for [Agents running on a local infrastructure](https://uagents.fetch.ai/docs/guides/types#local-agents). It helps developers track real-time Agents behavior, whether connected to Agentverse or not, offering detailed insights into performance and interactions.

Developers can view key details such as the local Agent‚Äôs address, endpoints, message types, and sender-recipient data. This visualization simplifies communication optimization and troubleshooting for Agents handling local processing or resource management.

The Inspector displays message data in a list, with options to view payloads, and provides an overview of all running Agents. Future updates will include support for Bureau-managed Agents and direct connections to Agentverse, further enhancing management and monitoring capabilities.

How to access the Local Agent Inspector[](#how-to-access-the-local-agent-inspector)
-----------------------------------------------------------------------------------

You can access the Local Agent Inspector by first coding and defining your Agent.

For instance, consider the following simple local Agent:

agent\_inspector\_example.py

     
    from uagents import Agent, Context, Model
     
    class Message(Model):
        message: str
     
     
    bob = Agent(
        name="Bob",
        port=8001,
        seed="BobSecretPhrase",
        endpoint=["http://127.0.0.1:8001/submit"],
    )
     
    print(f"Your agent's address is: {bob.address}")
     
     
    @bob.on_message(model=Message)
    async def message_handler(ctx: Context, sender: str, msg: Message):
        ctx.logger.info(f'Received message from {sender}: {msg.message}')
     
        await ctx.send(sender, Message(message="Hello There!"))
     
     
    if __name__ == "__main__":
        bob.run()
     

Once you successfully run your local Agent and register it into the Almanac (**Make sure your Agent has enough funds to do so!**), you will be able to access the Inspector via the terminal log, which provides a dedicated link to the Inspector page.

By running the above Agent, the output you get should be similar to the following:

    Your agent's address is: agent1qvrapvpxltu54tt3qnud5mlkul9y9d9tfn7xfpq4ec74cq4mkym6yl3jkdw
    INFO:     [  Bob]: Registration on Almanac API successful
    INFO:     [  Bob]: Registering on almanac contract...
    INFO:     [  Bob]: Registering on almanac contract...complete
    INFO:     [  Bob]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1q2kxet3vh0scsf0sm7y2erzz33cve6tv5uk63x64upw5g68kr0chkv7hw50
    INFO:     [  Bob]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)

By clicking on the dedicated link depicted here, you will then be redirected to the **Inspector Dashboard**. A pop-up message will appear saying that your Agent was connected successfully.

Here you can view all the information about your local Agent, including details about all messaged sent and received by the Agent. Additionally, you can connect you local Agent directly via the Inspector UI, by clicking the **Connect** button and following the steps required. For a better representation of the process, have a look at the following guide [here](https://uagents.fetch.ai/docs/agentverse/mailbox).</content>
</page>

<page>
  <title>Agent with Proxy docs</title>
  <url>https://uagents.fetch.ai/docs/agentverse/proxy</url>
  <content>Introduction[](#introduction)
-----------------------------

A Proxy serves as a bridge between your Agent and the Agentverse, allowing the Agent to publish interaction data without the need of a [Mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox). This setup is particularly beneficial for Agents requiring continuous operation and visibility in the Agentverse Marketplace.

The Agent setup[](#the-agent-setup)
-----------------------------------

An Agent connected via a Proxy uses the Agentverse as an intermediary to record interactions relevant to the [Agentverse Marketplace](https://docs.agentverse.ai/docs/marketplace), causing it to rank higher in the search index.

The following code demonstrates how to connect a local Agent to the Agentverse using a Proxy:

     
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    # Now your agent is ready to join the agentverse!
    agent = Agent(
        name="alice",
        seed="your_agent_seed_phrase",
        proxy=True,
    )
     
    # Copy the address shown below
    print(f"Your agent's address is: {agent.address}")
     
    if __name__ == "__main__":
        agent.run()
     

The Agent is initialized with multiple parameters: `name`, `seed` and `proxy`. Remember to correctly specify these parameters in order to successfully run the Agent. By running the above Agent code, you should be able to see the following output within your terminal:

    INFO:     [alice]: Starting agent with address: agent1qtx288pfqm9e5qausyzdy6zmmn65ytwygqdq2h7d4g0q00ft04rygg96jtt
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qtx288pfqm9e5qausyzdy6zmmn65ytwygqdq2h7d4g0q00ft04rygg96jtt
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete

Now, you are ready to connect the Agent using a Proxy. To connect your Agent using a Proxy, obtain the IP address where your Agent is accessible. Use the Agent Inspector URL from the terminal output to access the Inspector UI. **Log in** to the Agentverse and click the **Connect** button.

Then, select **Proxy** as your connection method, provide your Agent‚Äôs **public URL** or **IP address** followed by `/submit`. Once it is being validated, click **Next**.

Now, you will need to provide a **public URL** or **IP address** for your Agent.

_**Make sure you are running the latest [uagents package](https://pypi.org/project/uagents/) version on your end!**_

Once you do so, and the Agent‚Äôs public URL or IP address is verified, you will be asked to verify your Agent configuration and finalize the setup process.

Great! You successfully set up a proxy for your local Agent!

You should be able to see the following updated output in your terminal:

    INFO:     [alice]: Starting agent with address: agent1qtx288pfqm9e5qausyzdy6zmmn65ytwygqdq2h7d4g0q00ft04rygg96jtt
    INFO:     [alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1qtx288pfqm9e5qausyzdy6zmmn65ytwygqdq2h7d4g0q00ft04rygg96jtt
    INFO:     [alice]: Starting server on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     [alice]: Registration on Almanac API successful
    INFO:     [alice]: Registering on almanac contract...
    INFO:     [alice]: Registering on almanac contract...complete
    INFO:     [mailbox]: Successfully registered as proxy agent in Agentverse

Now that your Agent is connected through the Proxy to the Agentverse, it is able to receive messages from any other Agents.

Using a Proxy enables your Agent to seamlessly interact with the Agentverse, tracking interactions and displaying them on the [Marketplace](https://docs.agentverse.ai/docs/marketplace). These interactions are showcased on the Agent‚Äôs dedicated page within the [Agentverse: My Agents](https://docs.agentverse.ai/docs/quickstart) tab, providing visibility and engagement opportunities for users exploring the Marketplace.

A Proxy differs from a [Mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox) in key ways. While a Mailbox stores messages for offline Agents, a Proxy requires the Agent to be online to process incoming messages in real-time. Messages sent to an offline Proxy Agent are dropped, making it suitable for Agents that are continuously running and accessible through a public endpoint.

Setting up a Proxy benefits agents that require consistent operation and visibility in the Agentverse. It tracks interactions, showcases activity in the Marketplace, and ensures that Agents remain discoverable to other users, enhancing engagement and utility.</content>
</page>

<page>
  <title>Agent Mailboxes docs</title>
  <url>https://uagents.fetch.ai/docs/agentverse/mailbox</url>
  <content>Introduction[](#introduction)
-----------------------------

Agents can‚Äôt always be online; internet loss will cut your agent off from the network, or perhaps your agent is behind a firewall meaning you cannot accept inbound requests. To get around online requirements we created the **Mailbox** feature on [Agentverse](https://agentverse.ai/). A Mailbox is a middleman that acts as a mailbox for all communication to your agent. Messages are stored within the mailbox and your agents will collect them (calls for these in [uAgents library](https://github.com/fetchai/uAgents/blob/55fd0f1bd14d4d5fdaaa3dae82e4d6c6c5b9a3cd/python/src/uagents/mailbox.py#L65)) when they‚Äôre online again.

Let‚Äôs create a local Agent and connect it to the Agentverse via a Mailbox.

Local agent setup[](#local-agent-setup)
---------------------------------------

     
    from uagents import Agent, Context, Model
     
     
    class Message(Model):
        message: str
     
     
    SEED_PHRASE = "put_your_seed_phrase_here"
     
    # Now your agent is ready to join the agentverse!
    agent = Agent(
        name="alice",
        seed=SEED_PHRASE,
        port=8000,
        mailbox=True
    )
     
    # Copy the address shown below
    print(f"Your agent's address is: {agent.address}")
     
    if __name__ == "__main__":
        agent.run()

Importantly, you need to provide the `SEED_PHRASE`, `name`, `seed` and `port` parameters to correctly run this example. You also need to set `mailbox=True` to correctly connect your Agent to the Agentverse through the Mailbox.

You should get something similar within your terminal output:

    INFO:     [Alice]: Starting agent with address: agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
    INFO:     [Alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8002&address=agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
    INFO:     [Alice]: Starting server on http://0.0.0.0:8002 (Press CTRL+C to quit)
    INFO:     [Alice]: Starting mailbox client for https://agentverse.ai
    INFO:     [Alice]: Mailbox access token acquired
    INFO:     [Alice]: Registration on Almanac API successful
    INFO:     [Alice]: Registering on almanac contract...
    INFO:     [Alice]: Registering on almanac contract...complete
    

Create a Mailbox in Agentverse[](#create-a-mailbox-in-agentverse)
-----------------------------------------------------------------

Now that we defined our local Agent and have successfully run it, we can go on and connect it to the [Agentverse](https://agentverse.ai/) via a Mailbox. To do so, make sure your Agent is running. Then, click on the [Local Agent Inspector](https://uagents.fetch.ai/docs/agentverse/inspector) URL provided in your terminal output. You will be redirected towards the Inspector UI and will be able to see multiple details about this local Agent.

Here, click the **Connect** button.

You will be presented with 3 different choices: **Mailbox**, **Proxy** and **Custom**. Select **Mailbox**.

You will then see some code details available for the Agent. You do not need to do anything, just click on **Finish**.

You should now be able to see an additional line within your terminal output like shown below:

    INFO:     [Alice]: Starting agent with address: agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
    INFO:     [Alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8002&address=agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
    INFO:     [Alice]: Starting server on http://0.0.0.0:8002 (Press CTRL+C to quit)
    INFO:     [Alice]: Starting mailbox client for https://agentverse.ai
    INFO:     [Alice]: Mailbox access token acquired
    INFO:     [Alice]: Registration on Almanac API successful
    INFO:     [Alice]: Registering on almanac contract...
    INFO:     [Alice]: Registering on almanac contract...complete
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse

You can view your recently connected local Agent by heading to the **Agentverse My Agents** tab and by clicking on **Local Agents**. You will see a box for the local Agent recently connected.

Cool! You have correctly set up a mailbox for the Agent. You can additionally add some further details to the local Agent such as the `README.md` file. To do so, create a file in your local Agent folder and name it `README.md` (You can instead provide the path towards it if you wish). In the file, add all the needed details and save it. Then, add the following bits to your local Agent code:

     
    agent = Agent(
        name="Alice",
        seed=SEED_PHRASE,
        port=8000,
        mailbox=True,
        readme_path="README.md",
        publish_agent_details=True
    )
     

Then, run the Agent once again and head over to the Inspector UI and connect the Agent again through the Mailbox as we previously showed. Once you do so, you can the head over to the **Local Agents tab** under Agentverse My Agents page and click on the local Agent box. You should be able to see the `README.md` file opening up with the content you provided locally:

Creating a second Agent[](#creating-a-second-agent)
---------------------------------------------------

Let‚Äôs create and run a second Agent to message Alice every 3 seconds. You need to provide the `ALICE_ADDRESS`, `name` and `seed` parameters to correctly run this code:

     
    from uagents import Agent, Bureau, Context, Model
    from datetime import datetime
     
     
    class Message(Model):
        message: str
     
     
    agent_2 = Agent(name="agent_2", seed="agent_2 recovery phrase", port=8001, endpoint="http://localhost:8001/submit")
     
    ALICE_ADDRESS = "add_address_of_alice_agent"
     
     
    @agent_2.on_interval(period=3.0)
    async def send_message(ctx: Context):
        await ctx.send(ALICE_ADDRESS, Message(message=f"hello {datetime.today().date()}"))
     
     
    if __name__ == "__main__":
        agent_2.run()
     

Testing[](#testing)
-------------------

With both `alice` and `agent_2` running, stop `alice` and let `agent_2` run for a further 20 seconds, or so.

The output should be similar to the following, depending on the terminal window:

*   Alice:
    
        INFO:     [Alice]: Starting agent with address: agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
        INFO:     [Alice]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8002&address=agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
        INFO:     [Alice]: Starting server on http://0.0.0.0:8002 (Press CTRL+C to quit)
        INFO:     [Alice]: Starting mailbox client for https://agentverse.ai
        INFO:     [Alice]: Mailbox access token acquired
        INFO:     [Alice]: Registration on Almanac API successful
        INFO:     [Alice]: Registering on almanac contract...
        INFO:     [Alice]: Registering on almanac contract...complete
        INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
        INFO:     [Alice]: Received message from agent1qvzc3svtjv6dt9pql8ec7sfeuwfjmdg6ptafs9zc55ppvdwl5fe82j5m70v: hello 2024-12-18
        INFO:     [Alice]: Sending message to bob
        INFO:     [Alice]: Received message from agent1qvzc3svtjv6dt9pql8ec7sfeuwfjmdg6ptafs9zc55ppvdwl5fe82j5m70v: hello 2024-12-18
        INFO:     [Alice]: Sending message to bob
        INFO:     [Alice]: Received message from agent1qvzc3svtjv6dt9pql8ec7sfeuwfjmdg6ptafs9zc55ppvdwl5fe82j5m70v: hello 2024-12-18
        INFO:     [Alice]: Sending message to bob
    
*   Agent 2:
    
        2024-12-18 16:16:38	Info	System	Interval 0 period set to 5
        2024-12-18 16:16:38	Debug	System	Envelope sent to agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx
        2024-12-18 16:16:40	Debug	System	Processing envelope from agent1qw8jn3nfl2fyyhe7v4x8pfmsge4hs9zqrqw9eq7h7hluzmd0da8z7j0uacx...
    

**You can now restart your agent!**

You will see a bunch of messages being displayed by `alice` which are sent by `agent_2`.

‚ö†Ô∏è

Whenever working with mulitple local Agents, you need a different dedicated Mailbox for each one of them!

Now your Agent doesn‚Äôt need to be running all the time as messages will be waiting when it comes back online.

**Great! You correctly enrolled your local Agent on the Agentverse using the Mailbox feature!**</content>
</page>